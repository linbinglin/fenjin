import streamlit as st
from openai import OpenAI
import re
import pandas as pd

# --- é¡µé¢åŸºç¡€é…ç½® ---
st.set_page_config(
    page_title="å¯¼æ¼”å¼•æ“ V13 (è§†è§‰èšåˆç‰ˆ)",
    page_icon="ğŸ¬",
    layout="wide"
)

# --- è‡ªå®šä¹‰ CSS ---
st.markdown("""
<style>
    .metric-box { background-color: #f0f2f6; padding: 15px; border-radius: 8px; }
    /* ä¼˜åŒ–è¡¨æ ¼æ˜¾ç¤º */
    .stDataFrame { width: 100%; }
</style>
""", unsafe_allow_html=True)

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("âš™ï¸ å¯¼æ¼”å¼•æ“ V13")
    st.caption("ç‰ˆæœ¬ç‰¹æ€§ï¼šæ‹’ç»ç ´ç¢ï¼Œæ™ºèƒ½èšåˆ")
    
    api_key = st.text_input("API Key", type="password", placeholder="sk-...")
    base_url = st.text_input("æ¥å£åœ°å€", value="https://blog.tuiwen.xyz/v1")
    
    model_options = ["gpt-4o", "deepseek-chat", "claude-3-5-sonnet-20240620", "gpt-4-turbo", "gpt-3.5-turbo"]
    selected_model = st.selectbox("Model ID", model_options, index=0)
    
    if st.checkbox("è‡ªå®šä¹‰æ¨¡å‹ID"):
        model_id = st.text_input("è¾“å…¥ID", value=selected_model)
    else:
        model_id = selected_model

    st.divider()
    st.markdown("### ğŸ¬ V13 èšåˆé€»è¾‘")
    st.info("""
    1. **ä¼˜å…ˆåˆå¹¶**ï¼šåªè¦ä¸è¶…35å­—ï¼Œå°½é‡ä¸æ¢è¡Œã€‚
    2. **æ‹’ç»ç¢è¯**ï¼šä¸¥ç¦å‡ºç° "ç”¨åœ¨æˆ‘èº«ä¸Š" è¿™ç§5å­—çŸ­å¥å•ç‹¬æˆè¡Œï¼ˆé™¤éæ˜¯æç‰¹æ®Šçš„å¼ºè°ƒï¼‰ã€‚
    3. **é»„é‡‘æ—¶é•¿**ï¼šç›®æ ‡æ˜¯è®©æ¯è¡Œè½åœ¨ 20-35 å­—åŒºé—´ã€‚
    """)

# --- æ ¸å¿ƒé€»è¾‘ ---

def clean_text_for_ai(text):
    return text.replace("\n", "").replace("\r", "").strip()

def normalize_text_for_comparison(text):
    """ç”¨äºæ— æŸæ¯”å¯¹ï¼šå»æ ‡ç‚¹ã€å»ç©ºæ ¼ã€å»åºå·"""
    punctuation = r"""!"#$%&'()*+,-./:;<=>?@[\]^_`{|}~â€œâ€ï¼Ÿï¼Œï¼ã€ã€‘ï¼ˆï¼‰ã€ã€‚ï¼šï¼›â€™â€˜â€¦â€¦â€”â€”"""
    translator = str.maketrans('', '', punctuation)
    text = re.sub(r'\d+[.ã€]', '', text)
    text = re.sub(r'\s+', '', text)
    text = text.translate(translator)
    return text

def smart_split_text(text, chunk_size=1200):
    """
    ç¨å¾®å¢å¤§åˆ†å—å¤§å°ï¼Œè®©AIæœ‰æ›´å¤šçš„ä¸Šä¸‹æ–‡æ¥åˆ¤æ–­åˆå¹¶
    """
    sentences = re.split(r'([ã€‚ï¼ï¼Ÿ])', text)
    chunks = []
    current = ""
    
    temp = []
    for i in range(0, len(sentences)-1, 2):
        temp.append(sentences[i] + sentences[i+1])
    if len(sentences) % 2 == 1:
        temp.append(sentences[-1])
        
    for s in temp:
        if len(current) + len(s) > chunk_size:
            chunks.append(current)
            current = s
        else:
            current += s
    if current:
        chunks.append(current)
    return chunks

def parse_df(full_text):
    lines = full_text.split('\n')
    data = []
    for i, line in enumerate(lines):
        if not line.strip(): continue
        clean_content = re.sub(r'^\d+[.ã€]\s*', '', line)
        length = len(clean_content)
        
        # V13 è¯„åˆ†æ ‡å‡†è°ƒæ•´
        if length > 35: 
            status = "âš ï¸ å¤ªé•¿ (è¶…35)"
        elif length < 10: 
            status = "âš ï¸ å¤ªç¢ (å°‘äº10)" # æ–°å¢å¤ªçŸ­è­¦å‘Š
        elif 20 <= length <= 35:
            status = "âœ… é»„é‡‘æµ (20-35)"
        else:
            status = "ğŸ†— æ­£å¸¸ (10-20)"
        
        data.append({
            "åºå·": i+1,
            "åˆ†é•œå†…å®¹": clean_content,
            "å­—æ•°": length,
            "è§†è§‰çŠ¶æ€": status
        })
    return pd.DataFrame(data)

# --- ä¸»ç¨‹åº ---
st.title("ğŸ¬ å¯¼æ¼”å¼•æ“ V13 (æ™ºèƒ½èšåˆç‰ˆ)")
st.markdown("é’ˆå¯¹â€œåˆ†é•œå¤ªç¢â€é—®é¢˜æ·±åº¦ä¼˜åŒ–ã€‚æ ¸å¿ƒç­–ç•¥ï¼š**èƒ½åˆåˆ™åˆï¼Œéé•¿ä¸åˆ‡**ã€‚")

uploaded_file = st.file_uploader("ğŸ“‚ ä¸Šä¼  TXT", type=['txt'])

if uploaded_file:
    raw = uploaded_file.read().decode("utf-8")
    flat_input = clean_text_for_ai(raw)
    input_pure_len = len(normalize_text_for_comparison(flat_input))
    
    chunks = smart_split_text(flat_input)
    total_chunks = len(chunks)

    col1, col2 = st.columns(2)
    col1.metric("åŸæ–‡æ€»å­—æ•°", f"{len(flat_input)}")
    col2.metric("åˆ‡ç‰‡æ•°", f"{total_chunks}")
    
    st.markdown("---")
    if st.button("ğŸš€ å¯åŠ¨ V13 èšåˆå¼•æ“", type="primary"):
        if not api_key:
            st.error("è¯·å…ˆé…ç½® API Key")
        else:
            client = OpenAI(api_key=api_key, base_url=base_url)
            full_results = []
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            try:
                # --- V13 æ ¸å¿ƒ Prompt ä¿®æ”¹ ---
                # ç§»é™¤äº†æ‰€æœ‰é¼“åŠ±åˆ‡åˆ†çš„æŒ‡ä»¤ï¼Œå¢åŠ äº†â€œåˆå¹¶â€æŒ‡ä»¤
                system_prompt = """
                ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç”µå½±å‰ªè¾‘å¸ˆã€‚è¯·å°†æ–‡æ¡ˆå¤„ç†ä¸ºåˆ†é•œè„šæœ¬ã€‚
                
                ã€æœ€é«˜æŒ‡ä»¤ï¼šæ‹’ç»ç ´ç¢æ„Ÿã€‘
                1. **èšåˆåŸåˆ™**ï¼šåªè¦ä¸€å¥è¯ï¼ˆåŒ…å«é€—å·çš„çŸ­å¥ï¼‰åŠ èµ·æ¥ä¸è¶…è¿‡35ä¸ªå­—ï¼Œä¸”å±äºåŒä¸€åœºæ™¯ï¼Œ**å¿…é¡»åˆå¹¶åœ¨åŒä¸€è¡Œ**ã€‚
                2. **ç¦æ­¢ç¢è¯**ï¼šä¸¥ç¦å°†ä¸€ä¸ªå®Œæ•´çš„è°“è¯­æˆ–å®¾è¯­åˆ‡æ–­ã€‚
                   - âŒ é”™è¯¯ï¼š "å°†é‚£äº›ç”»ä¸Šçš„" (æ¢è¡Œ) "ç”¨åœ¨æˆ‘èº«ä¸Š"
                   - âœ… æ­£ç¡®ï¼š "å°†é‚£äº›ç”»ä¸Šçš„æ˜¥å®«åå…«å¼â€”â€”ç”¨åœ¨æˆ‘èº«ä¸Š" (åˆå¹¶)
                3. **ç¡¬æ€§é™åˆ¶**ï¼š
                   - å•è¡Œä¸Šé™ï¼š35å­—ï¼ˆè¶…è¿‡åˆ™å¿…é¡»åœ¨æ ‡ç‚¹å¤„åˆ‡å¼€ï¼‰ã€‚
                   - ç†æƒ³é•¿åº¦ï¼š20-35å­—ï¼ˆè¿™èƒ½ä¿è¯çº¦5ç§’çš„ç”»é¢åœç•™ï¼‰ã€‚
                4. **å¿…é¡»æ— æŸ**ï¼šä¸¥ç¦åˆ å­—ï¼Œä¸¥ç¦åŠ å­—ã€‚
                """

                for i, chunk in enumerate(chunks):
                    status_text.markdown(f"**ğŸ”„ æ­£åœ¨èšåˆå¤„ç†ç¬¬ {i+1}/{total_chunks} åŒºå—...**")
                    
                    response = client.chat.completions.create(
                        model=model_id,
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": f"è¯·å¯¹ä»¥ä¸‹æ–‡æ¡ˆè¿›è¡Œåˆ†é•œè§„åˆ’ï¼ˆæ³¨æ„åˆå¹¶çŸ­å¥ï¼‰ï¼š\n{chunk}"}
                        ],
                        temperature=0.1
                    )
                    
                    res_text = response.choices[0].message.content
                    full_results.append(res_text)
                    progress_bar.progress((i + 1) / total_chunks)

                # åˆæˆ
                combined = "\n".join(full_results)
                final_lines = [line.strip() for line in combined.split('\n') if line.strip()]
                
                # é‡å»ºè¾“å‡º
                final_output_text = ""
                raw_output_content = ""
                for idx, line in enumerate(final_lines):
                    clean = re.sub(r'^\d+[.ã€]\s*', '', line)
                    final_output_text += f"{idx+1}. {clean}\n"
                    raw_output_content += clean

                # --- ç»“æœåˆ†æ ---
                st.success("âœ¨ å¤„ç†å®Œæˆï¼ç ´ç¢æ„Ÿå·²ä¿®å¤ã€‚")
                
                output_pure_len = len(normalize_text_for_comparison(raw_output_content))
                diff = output_pure_len - input_pure_len
                
                # ç»Ÿè®¡
                m1, m2, m3, m4 = st.columns(4)
                m1.metric("ç”Ÿæˆåˆ†é•œç»„æ•°", f"{len(final_lines)} ç»„", 
                          help="ç»„æ•°è¶Šå°‘ï¼Œè¯´æ˜èšåˆæ•ˆæœè¶Šå¥½")
                m2.metric("å¹³å‡æ¯é•œå­—æ•°", f"{round(len(raw_output_content)/len(final_lines), 1)} å­—",
                          help="ç†æƒ³å€¼åº”åœ¨ 15-25 ä¹‹é—´")
                m3.metric("æ— æŸæ ¸éªŒ", f"{output_pure_len}", 
                          delta=f"{diff}", delta_color="inverse")
                
                if abs(diff) > 10:
                    st.warning("âš ï¸ æ³¨æ„ï¼šå­—æ•°å­˜åœ¨å·®å¼‚ï¼Œè¯·æ£€æŸ¥æ˜¯å¦å› åˆå¹¶å¯¼è‡´æ¼å­—ã€‚")

                # å†…å®¹å±•ç¤º
                c_left, c_right = st.columns([1.5, 1])
                
                with c_left:
                    st.subheader("ğŸ“ èšåˆåˆ†é•œè„šæœ¬")
                    st.text_area("å†…å®¹", value=final_output_text, height=600)
                    st.download_button("ğŸ“¥ ä¸‹è½½è„šæœ¬", data=final_output_text, file_name="èšåˆåˆ†é•œ.txt")

                with c_right:
                    st.subheader("ğŸ“Š è§†è§‰èŠ‚å¥è¡¨ (V13)")
                    df = parse_df(final_output_text)
                    st.dataframe(
                        df,
                        column_config={
                            "åºå·": st.column_config.NumberColumn(width="small"),
                            "åˆ†é•œå†…å®¹": st.column_config.TextColumn(width="large"),
                            "å­—æ•°": st.column_config.ProgressColumn(
                                "èŠ‚å¥æ¡", 
                                format="%d", 
                                min_value=0, 
                                max_value=40
                            ),
                            "è§†è§‰çŠ¶æ€": st.column_config.TextColumn(width="medium")
                        },
                        hide_index=True,
                        height=600
                    )

            except Exception as e:
                st.error(f"âŒ é”™è¯¯ï¼š{e}")
