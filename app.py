import streamlit as st
from openai import OpenAI
import json
import requests
import time
import base64

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="AI å£°éŸ³å…‹éš†å·¥ä½œå° (F5-TTS/IndexTTSç‰ˆ)", layout="wide", page_icon="ğŸ™ï¸")

# --- CSS æ ·å¼ä¼˜åŒ– ---
st.markdown("""
<style>
    .role-expander { border: 1px solid #e0e0e0; border-radius: 8px; margin-bottom: 10px; }
    .stSlider > div { padding-top: 0px; padding-bottom: 10px; }
    .emotion-label { font-size: 0.8rem; color: #666; }
</style>
""", unsafe_allow_html=True)

# --- ä¾§è¾¹æ é…ç½® ---
with st.sidebar:
    st.header("âš™ï¸ å…¨å±€è®¾ç½®")
    
    st.subheader("1. LLM è®¾ç½® (Yunwu.ai)")
    yunwu_key = st.text_input("API Key", type="password")
    base_url = "https://yunwu.ai/v1/"
    
    # æ¨¡å‹é€‰æ‹©
    st.markdown("**é€‰æ‹©æ ¸å¿ƒæ¨¡å‹:**")
    default_models = ["deepseek-chat", "gpt-4o", "claude-3-5-sonnet-20240620", "è‡ªå®šä¹‰è¾“å…¥"]
    selected_model = st.selectbox("æ¨¡å‹åˆ—è¡¨", default_models, label_visibility="collapsed")
    if selected_model == "è‡ªå®šä¹‰è¾“å…¥":
        model_name = st.text_input("è¾“å…¥æ¨¡å‹ ID", value="my-model")
    else:
        model_name = selected_model
    
    st.divider()
    
    st.subheader("2. å…‹éš†æ¥å£è®¾ç½®")
    tts_api_url = st.text_input("API åœ°å€ (URL)", value="http://xxxx.ngrok.app/v1/tts_clone", help="æŒ‡å‘æ”¯æŒå…‹éš†å‚æ•°çš„ API æ¥å£")
    global_speed = st.slider("å…¨å±€è¯­é€Ÿ", 0.5, 2.0, 1.0)
    
    st.info("æç¤ºï¼šè¯·ç¡®ä¿åç«¯ API æ”¯æŒ `ref_audio_path` æˆ– `emotion` å‚æ•°ï¼ˆå¦‚ F5-TTS, GPT-SoVITS å¢å¼ºç‰ˆï¼‰ã€‚")

# --- æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---

def analyze_script(text, api_key, model):
    """æ‹†è§£å‰§æœ¬ (ä¿æŒä¸å˜)"""
    client = OpenAI(api_key=api_key, base_url=base_url)
    prompt = f"""
    å°†ä»¥ä¸‹å°è¯´/å‰§æœ¬æ‹†è§£ä¸ºã€è§’è‰²ã€‘å’Œã€å°è¯ã€‘ã€‚
    æ‰€æœ‰éå¯¹è¯æå†™å½’ä¸º "æ—ç™½"ã€‚
    è¾“å‡ºçº¯ JSON åˆ—è¡¨ï¼Œæ—  Markdownã€‚
    æ ¼å¼ï¼š[{{"role": "æ—ç™½", "text": "..."}}, {{"role": "æå››", "text": "..."}}]
    æ–‡æœ¬ï¼š{text[:3000]}
    """
    try:
        response = client.chat.completions.create(model=model, messages=[{"role": "user", "content": prompt}], temperature=0.1)
        content = response.choices[0].message.content.replace("```json", "").replace("```", "").strip()
        return json.loads(content)
    except:
        return []

def generate_cloned_audio(text, config, api_url, speed):
    """
    é«˜çº§å…‹éš†åˆæˆå‡½æ•°
    config: åŒ…å«å‚è€ƒéŸ³é¢‘è·¯å¾„ã€æƒ…æ„Ÿå‘é‡çš„å­—å…¸
    """
    if not api_url: return None, "æ—  API åœ°å€"
    
    # --- æ„å»ºé«˜çº§ Payload (æ ¹æ® F5-TTS / SoVITS å¸¸è§ç»“æ„) ---
    # æ³¨æ„ï¼šä½ éœ€è¦æ ¹æ®ä½ è‡ªå·±åç«¯çš„å®é™… API æ–‡æ¡£è°ƒæ•´ key çš„åå­—
    payload = {
        "text": text,
        "text_language": "zh",
        "speed": speed,
        
        # 1. å£°éŸ³å…‹éš†å‚æ•°
        # ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·å¡«å†™çš„æœåŠ¡å™¨è·¯å¾„ï¼Œå…¶æ¬¡å°è¯•å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶(è¿™é‡Œç®€åŒ–ä¸ºè·¯å¾„é€»è¾‘)
        "ref_audio_path": config.get('ref_audio_path', ""), 
        "prompt_text": "", # å¦‚æœéœ€è¦å‚è€ƒéŸ³é¢‘å¯¹åº”çš„å­—å¹•ï¼Œå¯ä»¥åœ¨ UI å¢åŠ è¾“å…¥æ¡†
        
        # 2. æƒ…æ„Ÿæ§åˆ¶å‚æ•°
        "emotion_mode": config.get('emotion_mode', "same_as_ref"),
        
        # å°†æ»‘å—çš„å€¼ç»„åˆæˆå‘é‡æ•°ç»„ [happy, angry, sad, fear, disgust, surprise]
        "emotion_vector": [
            config.get('happy', 0),
            config.get('angry', 0),
            config.get('sad', 0),
            config.get('fear', 0),
            config.get('disgust', 0),
            config.get('surprise', 0)
        ],
        "format": "wav"
    }

    try:
        # å¦‚æœæ˜¯ä¸Šä¼ æ–¹å¼ï¼Œé€šå¸¸éœ€è¦ç”¨ multipart/form-dataï¼Œè¿™é‡Œä¸ºäº†é€šç”¨å±•ç¤º post json
        # å®é™…å¯¹æ¥æ—¶ï¼Œå¦‚æœæ­¤æ—¶ config['ref_file_bytes'] å­˜åœ¨ï¼Œä½ å¯èƒ½éœ€è¦è½¬æ¢æˆ base64 æ”¾åˆ° payload é‡Œ
        if config.get('ref_file_base64'):
             payload['ref_audio_base64'] = config['ref_file_base64']

        resp = requests.post(api_url, json=payload, timeout=60)
        if resp.status_code == 200:
            return resp.content, "success"
        else:
            return None, f"API é”™è¯¯ {resp.status_code}: {resp.text[:100]}"
    except Exception as e:
        return None, str(e)

# --- ä¸»ç•Œé¢ ---

st.title("ğŸ™ï¸ AI å£°éŸ³å…‹éš†ä¸æƒ…æ„Ÿæ§åˆ¶")

# 1. å‰§æœ¬åŠ è½½
uploaded_file = st.file_uploader("ğŸ“‚ ä¸Šä¼  TXT å‰§æœ¬", type=["txt"])
if uploaded_file and st.button("å¼€å§‹æ‹†è§£è§’è‰²"):
    st.session_state['script_data'] = analyze_script(uploaded_file.read().decode("utf-8"), yunwu_key, model_name)
    roles = list(set([d['role'] for d in st.session_state['script_data']]))
    if "æ—ç™½" in roles: roles.insert(0, roles.pop(roles.index("æ—ç™½")))
    st.session_state['roles_list'] = roles
    st.rerun()

# 2. æ ¸å¿ƒï¼šé«˜çº§é…éŸ³è®¾ç½®é¢æ¿ (æ¨¡ä»¿æˆªå›¾)
if 'roles_list' in st.session_state and st.session_state['roles_list']:
    st.divider()
    col_conf, col_preview = st.columns([5, 4])
    
    # å­˜å‚¨æ‰€æœ‰è§’è‰²çš„é…ç½®
    role_configs = {}
    
    with col_conf:
        st.subheader("ğŸ›ï¸ è§’è‰²éŸ³è‰²å…‹éš†é¢æ¿")
        st.caption("ä¸ºæ¯ä¸ªè§’è‰²é…ç½®ç‹¬ç«‹çš„å‚è€ƒéŸ³é¢‘å’Œæƒ…æ„Ÿå‚æ•°")
        
        # éå†æ‰€æœ‰è§’è‰²ç”Ÿæˆæ§åˆ¶é¢æ¿
        for role in st.session_state['roles_list']:
            # ä½¿ç”¨ expander æ¨¡ä»¿æˆªå›¾ä¸­çš„å¡ç‰‡æ•ˆæœ
            with st.expander(f"ğŸ‘¤ è§’è‰²é…ç½®ï¼š{role}", expanded=False):
                c1, c2 = st.columns([1, 1])
                
                # --- éƒ¨åˆ† 1: å‚è€ƒéŸ³é¢‘ (Clone) ---
                with c1:
                    st.markdown("##### 1. å‚è€ƒéŸ³é¢‘ (Reference)")
                    tab1, tab2 = st.tabs(["æœåŠ¡ç«¯è·¯å¾„", "ä¸Šä¼ æ–‡ä»¶"])
                    with tab1:
                        # æ¨¡ä»¿æˆªå›¾ä¸­ç›´æ¥å¡«å†™ç¡¬ç›˜è·¯å¾„ I:/F5tts/...
                        ref_path = st.text_input("éŸ³é¢‘è·¯å¾„", key=f"path_{role}", placeholder="ä¾‹å¦‚: /data/wavs/xiao_yan.wav")
                    with tab2:
                        ref_upload = st.file_uploader("é€‰æ‹©éŸ³é¢‘", key=f"up_{role}", type=['wav','mp3'])
                
                # --- éƒ¨åˆ† 2: æƒ…æ„Ÿæ§åˆ¶ (Emotion) ---
                with c2:
                    st.markdown("##### 2. æƒ…æ„Ÿæ§åˆ¶ (Emotion)")
                    # æƒ…æ„Ÿæ¨¡å¼ä¸‹æ‹‰æ¡†
                    emo_mode = st.selectbox(
                        "æƒ…æ„Ÿæ¨¡å¼", 
                        ["ä¸è¯­éŸ³å‚è€ƒç›¸åŒ (Default)", "ä½¿ç”¨æƒ…æ„Ÿå‘é‡ (Vector)", "æ–‡æœ¬æè¿° (Text)"], 
                        key=f"emo_mood_{role}"
                    )
                    
                    # æƒ…æ„Ÿå‘é‡æ»‘å— (åªæœ‰é€‰ä¸­ Vector æ—¶æ˜¾ç¤º)
                    emo_data = {}
                    if emo_mode == "ä½¿ç”¨æƒ…æ„Ÿå‘é‡ (Vector)":
                        st.markdown("**æƒ…æ„Ÿå‘é‡è°ƒèŠ‚**")
                        ec1, ec2 = st.columns(2)
                        with ec1:
                            emo_data['happy'] = st.slider("ğŸ˜† å¿«ä¹", 0.0, 1.0, 0.0, key=f"h_{role}")
                            emo_data['sad'] = st.slider("ğŸ˜­ æ‚²ä¼¤", 0.0, 1.0, 0.0, key=f"s_{role}")
                            emo_data['angry'] = st.slider("ğŸ˜¡ æ„¤æ€’", 0.0, 1.0, 0.0, key=f"a_{role}")
                        with ec2:
                            emo_data['fear'] = st.slider("ğŸ˜± ææƒ§", 0.0, 1.0, 0.0, key=f"f_{role}")
                            emo_data['disgust'] = st.slider("ğŸ¤¢ åŒæ¶", 0.0, 1.0, 0.0, key=f"d_{role}")
                            emo_data['surprise'] = st.slider("ğŸ˜² æƒŠè®¶", 0.0, 1.0, 0.0, key=f"su_{role}")
                
                # ä¿å­˜é…ç½®åˆ°å­—å…¸
                config = {
                    "ref_audio_path": ref_path,
                    "emotion_mode": emo_mode,
                    **emo_data # å±•å¼€æƒ…æ„Ÿæ•°æ®
                }
                
                # å¦‚æœæœ‰ä¸Šä¼ æ–‡ä»¶ï¼Œè½¬æˆ Base64 æ–¹ä¾¿ä¼ è¾“ (å¯é€‰)
                if ref_upload:
                    bytes_data = ref_upload.getvalue()
                    config['ref_file_base64'] = base64.b64encode(bytes_data).decode('utf-8')
                
                role_configs[role] = config

    with col_preview:
        st.subheader("ğŸ“œ åˆ†é•œé¢„è§ˆ")
        with st.container(height=600):
            for item in st.session_state.get('script_data', []):
                st.markdown(f"**[{item['role']}]**: {item['text']}")

    # 3. åˆæˆ
    st.divider()
    if st.button("ğŸš€ å¼€å§‹é«˜çº§åˆæˆ", type="primary"):
        st.write("æ­£åœ¨è¿æ¥å…‹éš†æœåŠ¡...")
        progress = st.progress(0)
        logs = st.expander("è¿è¡Œæ—¥å¿—", expanded=True)
        
        for i, item in enumerate(st.session_state['script_data']):
            role = item['role']
            text = item['text']
            
            # è·å–å½“å‰è§’è‰²çš„é…ç½®
            cfg = role_configs.get(role, {})
            
            # è°ƒç”¨
            audio, msg = generate_cloned_audio(text, cfg, tts_api_url, global_speed)
            
            if audio:
                st.audio(audio, format="audio/wav")
                st.caption(f"[{role}] {text[:20]}...")
            else:
                logs.error(f"[{role}] å¤±è´¥: {msg}")
            
            progress.progress((i+1)/len(st.session_state['script_data']))
