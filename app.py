import streamlit as st
from openai import OpenAI
import re
import pandas as pd

# ==========================================
# 1. æ ¸å¿ƒå·¥å…·å‡½æ•° (å¿…é¡»æ”¾åœ¨ä»£ç æœ€å‰é¢é˜²æ­¢ NameError)
# ==========================================

def get_pure_text(text):
    """æå–çº¯æ–‡æœ¬å†…å®¹ï¼Œç”¨äºç²¾ç¡®å¯¹è´¦"""
    if not text:
        return ""
    # ç§»é™¤è¡Œé¦–ç¼–å·ï¼ˆåŒ¹é… æ•°å­—. æˆ– æ•°å­—ã€ æˆ– æ•°å­— ï¼‰
    text = re.sub(r'^\s*\d+[\.ã€\s]\s*', '', text, flags=re.MULTILINE)
    # ç§»é™¤æ‰€æœ‰ç©ºç™½ç¬¦ã€æ¢è¡Œã€ç©ºæ ¼
    return "".join(text.split())

def reindex_text(text):
    """äººå·¥å¾®è°ƒåçš„åºå·è‡ªåŠ¨é‡æ’ç³»ç»Ÿ"""
    lines = text.split('\n')
    valid_lines = []
    count = 1
    for line in lines:
        # ç§»é™¤å·²æœ‰çš„ä»»ä½•åºå·æ ¼å¼
        content = re.sub(r'^\s*\d+[\.ã€\s]\s*', '', line).strip()
        if content:
            valid_lines.append(f"{count}.{content}")
            count += 1
    return "\n".join(valid_lines)

def smart_chunk_text(text, max_chars=1200):
    """æ™ºèƒ½è¯­ä¹‰æ‹†åˆ†ï¼Œé˜²æ­¢æ®µè½åˆ‡åœ¨å¥å­ä¸­é—´"""
    chunks = []
    while len(text) > max_chars:
        split_index = -1
        # ä¼˜å…ˆåœ¨å¥å·ã€æ„Ÿå¹å·ã€æ¢è¡Œå¤„åˆ‡å‰²
        for mark in ["\n", "ã€‚", "ï¼", "ï¼Ÿ"]:
            pos = text.rfind(mark, 0, max_chars)
            split_index = max(split_index, pos)
        
        if split_index == -1:
            split_index = max_chars
        else:
            split_index += 1 
            
        chunks.append(text[:split_index].strip())
        text = text[split_index:]
    if text:
        chunks.append(text.strip())
    return [c for c in chunks if c]

# ==========================================
# 2. é¡µé¢é…ç½®ä¸åˆå§‹åŒ–
# ==========================================

st.set_page_config(page_title="è§£è¯´åˆ†é•œ Pro V15", layout="wide")

if 'final_storyboard' not in st.session_state:
    st.session_state.final_storyboard = ""
if 'original_text_clean' not in st.session_state:
    st.session_state.original_text_clean = ""

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.title("âš™ï¸ å¯¼æ¼”å¼•æ“é…ç½®")
    api_key = st.text_input("1. API Key", type="password")
    base_url = st.text_input("2. æ¥å£åœ°å€", value="https://blog.tuiwen.xyz/v1")
    model_id = st.text_input("3. Model ID", value="gpt-4o")
    st.caption("æç¤ºï¼šå¦‚æœæŠ¥é”™ 503ï¼Œè¯·æ£€æŸ¥ä¸Šé¢çš„ Model ID æ˜¯å¦æ­£ç¡®ï¼ˆæ¨è gpt-4oï¼‰")
    st.divider()
    st.info("ğŸ’¡ V15 åä½œç‰ˆï¼š\n1. æ”¯æŒ 7000å­—+ é•¿æ–‡\n2. 0å­—æŸè€—æ ¡éªŒ\n3. æ‰‹åŠ¨ç¼–è¾‘åå¯ä¸€é”®é‡æ’åºå·")

# ==========================================
# 3. ä¸»ç•Œé¢é€»è¾‘
# ==========================================

st.title("ğŸ¬ ç”µå½±è§£è¯´Â·åƒç´ çº§åˆ†é•œç³»ç»Ÿ (V15)")
uploaded_file = st.file_uploader("ğŸ“‚ é€‰æ‹©æœ¬åœ°æ–‡æ¡ˆ TXT æ–‡ä»¶", type=['txt'])

if uploaded_file:
    raw_text = uploaded_file.getvalue().decode("utf-8")
    # é”å®šåŸå§‹æ•°æ®
    st.session_state.original_text_clean = "".join(raw_text.split())
    input_len = len(st.session_state.original_text_clean)

    # çœ‹æ¿
    st.subheader("ğŸ“Š é€»è¾‘ç¨½æ ¸é¢æ¿")
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("åŸæ–‡æ€»å­—æ•°", f"{input_len} å­—")

    if st.button("ğŸš€ å¯åŠ¨è‡ªåŠ¨åŒ–åˆ†é•œ"):
        if not api_key:
            st.error("è¯·å…ˆåœ¨å·¦ä¾§è¾“å…¥ API Key")
        else:
            try:
                # è§„èŒƒåŒ– URL
                client = OpenAI(api_key=api_key, base_url=base_url.split('/chat')[0].strip() + "/v1")
                
                # æ‰§è¡Œæ‹†åˆ†
                chunks = smart_chunk_text(st.session_state.original_text_clean)
                st.write(f"ğŸ“¦ æ–‡æœ¬å·²æ‹†åˆ†ä¸º {len(chunks)} ä¸ªä»»åŠ¡å—ï¼Œæ­£åœ¨å¤„ç†...")
                
                all_results = []
                current_idx = 1
                prog = st.progress(0)
                
                for i, chunk in enumerate(chunks):
                    with st.spinner(f"æ­£åœ¨å¤„ç†ç¬¬ {i+1} å—å†…å®¹..."):
                        prompt = f"""ä½ æ˜¯ä¸€ä¸ªè§£è¯´åˆ†é•œå¯¼æ¼”ã€‚
1. 1:1 åƒç´ çº§è¿˜åŸåŸæ–‡ï¼Œä¸å‡†æ¼å­—ï¼Œä¸å‡†å¤šå­—ã€‚
2. æ¯è¡Œå­—æ•°ä¸¥æ ¼åœ¨ 25-35 å­—ä¹‹é—´ï¼Œè¶…æ ‡å¿…åˆ‡æ–­ã€‚
3. åªè¦ä¸»è¯­åˆ‡æ¢æˆ–å°è¯ç»“æŸï¼Œå¿…é¡»æ¢è¡Œã€‚
4. ç¼–å·ä» {current_idx} å¼€å§‹ã€‚
å¾…å¤„ç†æ–‡æœ¬æµï¼š
{chunk}"""
                        
                        response = client.chat.completions.create(
                            model=model_id,
                            messages=[
                                {"role": "system", "content": "ä½ åªè¾“å‡ºå¸¦ç¼–å·çš„åˆ†é•œåˆ—è¡¨ï¼Œä¸¥ç¦åºŸè¯ã€‚"},
                                {"role": "user", "content": prompt}
                            ],
                            temperature=0
                        )
                        chunk_res = response.choices[0].message.content.strip()
                        all_results.append(chunk_res)
                        
                        # è·å–æœ€ååºå·ç”¨äºä¸‹ä¸€å—è¡”æ¥
                        nums = re.findall(r'(\d+)[\.ã€]', chunk_res)
                        if nums:
                            current_idx = int(nums[-1]) + 1
                        prog.progress((i+1)/len(chunks))
                
                st.session_state.final_storyboard = "\n".join(all_results)
                st.success("AI åˆ†é•œå¤„ç†å®Œæ¯•ï¼")
            except Exception as e:
                st.error(f"å¤„ç†å¤±è´¥: {str(e)}")

# ==========================================
# 4. ç¼–è¾‘ä¸æ ¡å‡†é¢æ¿
# ==========================================

if st.session_state.final_storyboard:
    st.divider()
    
    col_l, col_r = st.columns([2, 1])
    
    with col_l:
        st.subheader("âœï¸ å¯¼æ¼”ç²¾ä¿®ç¼–è¾‘å™¨")
        # ç›´æ¥ä½¿ç”¨ç»„ä»¶è¿”å›å€¼æ›´æ–°
        edited_text = st.text_area(
            "æ‰‹åŠ¨è°ƒæ•´å†…å®¹ (å›è½¦å¢åŠ åˆ†é•œï¼Œåˆ é™¤æ¢è¡Œåˆå¹¶)ï¼š",
            value=st.session_state.final_storyboard,
            height=600
        )
        
        c1, c2 = st.columns(2)
        if c1.button("ğŸ”¢ æ ¡å‡†æ‰€æœ‰åˆ†é•œåºå·"):
            st.session_state.final_storyboard = reindex_text(edited_text)
            st.rerun()
            
        c2.download_button("ğŸ’¾ ä¸‹è½½åˆ†é•œè„šæœ¬", st.session_state.final_storyboard, "storyboard.txt")

    with col_r:
        st.subheader("ğŸ“Š å®æ—¶èŠ‚å¥ç›‘æ§")
        # å®æ—¶å­—æ•°è®¡ç®—
        current_clean = get_pure_text(st.session_state.final_storyboard)
        curr_len = len(current_clean)
        diff = curr_len - len(st.session_state.original_text_clean)
        
        # æå–åˆ†é•œè¡Œ
        shot_lines = [l for l in st.session_state.final_storyboard.split('\n') if re.match(r'^\d+', l.strip())]
        
        st.metric("ç”Ÿæˆåˆ†é•œæ€»æ•°", f"{len(shot_lines)} ç»„")
        st.metric("å½“å‰è¿˜åŸå­—æ•°", f"{curr_len} å­—")
        
        if diff == 0:
            st.success("âœ… å­—æ•° 100% å¯¹é½")
        else:
            st.error(f"âŒ åå·®ï¼š{diff} å­—")
            st.caption("æ­£æ•°ä¸ºé‡å¤/å¤šå­—ï¼Œè´Ÿæ•°ä¸ºæ¼å­—ã€‚")

        # èŠ‚å¥åˆ†æè¡¨
        analysis = []
        for i, line in enumerate(shot_lines):
            txt = re.sub(r'^\d+[\.ã€\s]\s*', '', line)
            analysis.append({"é•œå¤´": i+1, "å­—æ•°": len(txt), "çŠ¶æ€": "âœ…" if len(txt) <= 35 else "âš ï¸è¿‡é•¿"})
        
        st.dataframe(pd.DataFrame(analysis), height=400, use_container_width=True)
