import streamlit as st
from openai import OpenAI
import io
import re
import pandas as pd

st.set_page_config(page_title="ç”µå½±è§£è¯´AIåˆ†é•œå¯¼æ¼”Pro", layout="wide")

# --- åˆå§‹åŒ–å…¨å±€çŠ¶æ€ç¼“å­˜ ---
if 'raw_text_stream' not in st.session_state: st.session_state.raw_text_stream = ""
if 'storyboard_data' not in st.session_state: st.session_state.storyboard_data = ""
if 'batch_descriptions' not in st.session_state: st.session_state.batch_descriptions = []
if 'batch_pointer' not in st.session_state: st.session_state.batch_pointer = 0

# --- ä¾§è¾¹æ  API é…ç½® ---
st.sidebar.title("âš™ï¸ å¯¼æ¼”å®¤é…ç½®")
api_key = st.sidebar.text_input("è¾“å…¥ API Key", type="password")
base_url = st.sidebar.text_input("ä¸­è½¬åœ°å€", value="https://blog.tuiwen.xyz/v1")
model_id = st.sidebar.text_input("æ¨¡å‹åç§°", value="gpt-4o")

st.title("ğŸ¬ ç”µå½±è§£è¯´å…¨æµç¨‹å¯¼æ¼”ç³»ç»Ÿ")
st.caption("ç‰ˆæœ¬ï¼š3.0 | æ ¸å¿ƒç›®æ ‡ï¼šæ— æŸåˆ‡å‰²ã€5ç§’èŠ‚å¥æ§åˆ¶ã€æ™ºèƒ½è¯­ä¹‰èšæ‹¢")

# ================= ç¬¬ä¸€é˜¶æ®µï¼šç‰©ç†ç²‰ç¢ä¸è¯­ä¹‰é‡æ„ =================
st.header("Step 1: æ–‡æ¡ˆè§£æ„ä¸åˆ†é•œæ‹†è§£")

uploaded_file = st.file_uploader("ä¸Šä¼ æ–‡æ¡ˆ (TXT)", type=['txt'])

if uploaded_file:
    # ã€ç‰©ç†ç²‰ç¢ã€‘å½»åº•å‰¥ç¦»åŸæ–‡æœ¬æ‰€æœ‰æ¢è¡Œï¼Œé˜²æ­¢AIå·æ‡’å‚è€ƒåŸç»“æ„
    raw_content = io.StringIO(uploaded_file.getvalue().decode("utf-8")).read()
    clean_stream = re.sub(r'[\s\n\r\t]+', '', raw_content).strip()
    st.session_state.raw_text_stream = clean_stream
    
    st.success(f"âœ… æ–‡æœ¬å·²è¿›å…¥â€˜æ— æŸç²‰ç¢â€™çŠ¶æ€ï¼Œå…±è®¡ {len(clean_stream)} å­—ç¬¦ã€‚AIå°†æ— æ³•çœ‹åˆ°åŸæ–‡æ®µè½ã€‚")

    if st.button("ğŸš€ å¯åŠ¨æ™ºèƒ½æ— æŸåˆ†é•œ"):
        if not api_key:
            st.error("è¯·é…ç½®API Key")
        else:
            try:
                client = OpenAI(api_key=api_key, base_url=base_url)
                
                # ã€å¼ºåŒ–å¯¼æ¼”æŒ‡ä»¤ã€‘
                segment_prompt = f"""ä½ æ˜¯ä¸€åèµ„æ·±ç”µå½±å‰ªè¾‘å¯¼æ¼”ã€‚ç°åœ¨æˆ‘ç»™ä½ ä¸€æ®µå®Œå…¨æ²¡æœ‰ä»»ä½•æ¢è¡Œå’Œæ®µè½çš„æ–‡å­—æµï¼Œè¯·å°†å…¶å¤„ç†ä¸ºåˆ†é•œè„šæœ¬ã€‚

### æ ¸å¿ƒé“å¾‹ï¼ˆè¿è€…é‡ç½šï¼‰ï¼š
1. **æ•°å­—åºå·**ï¼šæ¯ä¸€è¡Œåˆ†é•œå¿…é¡»ä»¥â€œæ•°å­—.â€å¼€å¤´ï¼Œä¾‹å¦‚ï¼š1.æ–‡æ¡ˆã€‚
2. **ç»å¯¹æ— æŸ**ï¼šä¸¥ç¦åˆ é™¤ã€ä¿®æ”¹ã€ç¼©å‡ã€æ·»åŠ åŸæ–‡ä¸­çš„ä»»ä½•ä¸€ä¸ªå­—ç¬¦ã€‚æ–‡æœ¬å¿…é¡» 100% å®Œæ•´ã€‚
3. **å­—æ•°çº¢çº¿ï¼ˆè§£å†³æ‹¥æŒ¤ï¼‰**ï¼šæ¯ä¸ªåˆ†é•œæ–‡æ¡ˆç†æƒ³é•¿åº¦ä¸º 25-35 å­—ç¬¦ã€‚ç»å¯¹ç¦æ­¢è¶…è¿‡ 40 å­—ç¬¦ï¼ˆå¯¹åº”5ç§’é…éŸ³æ—¶é•¿ï¼‰ã€‚
4. **è¯­ä¹‰èšæ‹¢ï¼ˆè§£å†³å¤ªç¢ï¼‰**ï¼šä¸è¦ä¸€å¥è¯åˆ†ä¸€ä¸ªé•œï¼å¦‚æœè¿ç»­çš„åŠ¨ä½œï¼ˆå¦‚ï¼šä»–ç¿»èº«ã€ä¸‹åºŠã€ç©¿é‹ï¼‰åœ¨ 35 å­—ä»¥å†…ï¼Œå¿…é¡»èšæ‹¢åœ¨ä¸€ä¸ªåˆ†é•œä¸­ã€‚
5. **åˆ†é•œåˆ‡åˆ†ç‚¹**ï¼šä»…åœ¨ä»¥ä¸‹æƒ…å†µå‰ªå¼€ï¼š
   - å­—æ•°å³å°†æ¥è¿‘ 35 å­—ã€‚
   - è§’è‰²åˆ‡æ¢ï¼ˆæ¢äººè¯´è¯ï¼‰ã€‚
   - åœºæ™¯çªå˜ã€‚

å¾…å¤„ç†æ–‡æœ¬æµï¼š
{clean_stream}"""

                with st.spinner("å¯¼æ¼”æ­£åœ¨æ„æ€åˆ†é•œèŠ‚å¥..."):
                    response = client.chat.completions.create(
                        model=model_id,
                        messages=[
                            {"role": "system", "content": "ä½ åªè¾“å‡ºå¸¦åºå·çš„åˆ†é•œåˆ—è¡¨ï¼Œä¸å‡†æœ‰ä»»ä½•è§£é‡Šã€‚"},
                            {"role": "user", "content": segment_prompt}
                        ],
                        temperature=0.1
                    )
                    st.session_state.storyboard_data = response.choices[0].message.content
                    st.session_state.batch_descriptions = []
                    st.session_state.batch_pointer = 0
            except Exception as e:
                st.error(f"åˆ†é•œç”ŸæˆæŠ¥é”™: {str(e)}")

# ç¬¬ä¸€é˜¶æ®µå®¡è®¡é¢æ¿
if st.session_state.storyboard_data:
    col_edit, col_audit = st.columns([3, 2])
    
    with col_edit:
        st.subheader("âœï¸ åˆ†é•œç¼–è¾‘åŒº (ç¡®è®¤åºå·ä¸å­—æ•°)")
        final_storyboard = st.text_area("åˆ†é•œæ–‡æ¡ˆè‰ç¨¿", value=st.session_state.storyboard_data, height=500)
        st.session_state.storyboard_data = final_storyboard

    with col_audit:
        st.subheader("ğŸ“Š å®æ—¶èŠ‚å¥ç›‘æ§")
        lines = [l.strip() for l in final_storyboard.split('\n') if l.strip()]
        
        # æ— æŸæ ¡éªŒé€»è¾‘
        recombined = "".join([re.sub(r'^\d+[\.ã€\s]+', '', l) for l in lines])
        orig_len = len(st.session_state.raw_text_stream)
        curr_len = len(recombined)
        
        if orig_len == curr_len:
            st.success(f"âœ… å†…å®¹æ ¡éªŒä¸€è‡´ (å…±{curr_len}å­—)")
        else:
            diff = orig_len - curr_len
            st.error(f"âš ï¸ ä¸¢å­—è­¦å‘Šï¼šåŸ{orig_len}å­—, ç°{curr_len}å­— (ç›¸å·®{diff}å­—)")

        # èŠ‚å¥è¯„ä¼°è¡¨æ ¼
        analysis = []
        for i, l in enumerate(lines):
            content = re.sub(r'^\d+[\.ã€\s]+', '', l)
            length = len(content)
            # è¿™é‡Œçš„è¯„ä¼°é€»è¾‘æ˜¯æ ¸å¿ƒ
            if length > 35: status = "ğŸ”´ å¤ªæŒ¤(è¶…35å­—)"
            elif length < 15: status = "ğŸŸ¡ ç•¥ç¢"
            else: status = "ğŸŸ¢ ç†æƒ³"
            analysis.append({"åˆ†é•œ": i+1, "å­—æ•°": length, "èŠ‚å¥": status})
        st.table(pd.DataFrame(analysis))

    st.divider()

    # ================= ç¬¬äºŒé˜¶æ®µï¼šå¯¼æ¼”æç¤ºè¯ç”Ÿæˆ =================
    st.header("Step 2: ç”Ÿæˆ AI ç”»é¢ä¸å³æ¢¦AIè§†é¢‘æè¿°")
    
    char_desc = st.text_area("1. å½•å…¥æ ¸å¿ƒè§’è‰²è®¾å®š", 
                            placeholder="è¯·æè¿°è§’è‰²çš„æ ·è²Œã€ç©¿ç€ã€‚ä¾‹å¦‚ï¼šæ—å‡¡ï¼šå‰‘çœ‰æ˜Ÿç›®ï¼Œé»‘è‰²æŠ«é£ï¼Œçœ¼ç¥å†·é…·ã€‚",
                            height=100)
    
    if char_desc:
        final_lines = [re.sub(r'^\d+[\.ã€\s]+', '', l.strip()) for l in st.session_state.storyboard_data.split('\n') if l.strip()]
        total_len = len(final_lines)
        p = st.session_state.batch_pointer
        batch_size = 20
        end_p = min(p + batch_size, total_len)

        if p < total_len:
            if st.button(f"ğŸ¬ ç”Ÿæˆç¬¬ {p+1} - {end_p} ç»„æ·±åº¦æè¿°"):
                try:
                    client = OpenAI(api_key=api_key, base_url=base_url)
                    batch_content = "\n".join([f"åˆ†é•œ{p+i+1}: {t}" for i, t in enumerate(final_lines[p:end_p])])
                    
                    desc_prompt = f"""ä½ ç°åœ¨æ˜¯è§†è§‰å¯¼æ¼”ï¼Œè´Ÿè´£ç”ŸæˆMidjourneyå’Œå³æ¢¦AIçš„æç¤ºè¯ã€‚

### è§’è‰²è®¾å®šï¼š
{char_desc}

### ä»»åŠ¡ï¼š
1. **ç”»é¢æè¿° (MJ)**ï¼šæè¿°é™æ€ã€‚åŒ…å«æ™¯åˆ«ã€åœºæ™¯ç»†èŠ‚ã€äººç‰©ç¥æ€ã€ç€è£…ç»†èŠ‚ã€å…‰æ•ˆã€‚ç¦æ­¢æè¿°ä»»ä½•åŠ¨ä½œã€‚
2. **è§†é¢‘ç”Ÿæˆ (å³æ¢¦AI)**ï¼šæè¿°åŠ¨æ€ã€‚æè¿°è¿™5ç§’å†…çš„åŠ¨ä½œæµã€‚é‡‡ç”¨çŸ­å¥å †ç Œã€‚å¿…é¡»åŒ…å«äººç‰©çš„ç¥æ€å˜åŒ–å’Œè‚¢ä½“ä½ç§»ã€‚
3. **å•ç„¦åŸåˆ™**ï¼šä¸€ä¸ªåˆ†é•œæè¿°ä¸€ä¸ªæ ¸å¿ƒè§†è§‰åŠ¨ä½œï¼Œç¡®ä¿å³æ¢¦AIèƒ½è¯†åˆ«ã€‚

å¾…å¤„ç†åˆ†é•œç»„ï¼š
{batch_content}"""

                    with st.spinner("AI æ­£åœ¨æ·±åº¦è§£æç”»é¢é€»è¾‘..."):
                        response = client.chat.completions.create(
                            model=model_id,
                            messages=[{"role": "user", "content": desc_prompt}]
                        )
                        st.session_state.batch_descriptions.append(response.choices[0].message.content)
                        st.session_state.batch_pointer = end_p
                        st.rerun()
                except Exception as e:
                    st.error(f"æè¿°ç”Ÿæˆå¤±è´¥: {e}")
        else:
            st.success("âœ… å…¨éƒ¨åˆ†é•œæè¿°å·²ç”Ÿæˆï¼")

        for res in st.session_state.batch_descriptions:
            st.markdown(res)
            st.divider()
