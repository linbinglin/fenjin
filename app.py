import streamlit as st
from openai import OpenAI
import io
import pandas as pd

st.set_page_config(page_title="AIå…¨æµç¨‹åˆ†é•œå¯¼æ¼”", layout="wide")

# åˆå§‹åŒ– Session State
if 'segments' not in st.session_state:
    st.session_state.segments = []
if 'batch_index' not in st.session_state:
    st.session_state.batch_index = 0
if 'final_results' not in st.session_state:
    st.session_state.final_results = []

# ä¾§è¾¹æ  API é…ç½®
st.sidebar.title("âš™ï¸ ç³»ç»Ÿé…ç½®")
api_key = st.sidebar.text_input("è¾“å…¥ API Key", type="password")
base_url = st.sidebar.text_input("æ¥å£åœ°å€", value="https://blog.tuiwen.xyz/v1")
model_id = st.sidebar.text_input("Model ID (å»ºè®®ä½¿ç”¨ Claude-3.5 æˆ– GPT-4o)", value="gpt-4o")

st.sidebar.info("ğŸ’¡ æç¤ºï¼šç¬¬ä¸€æ­¥åˆ†é•œå®Œæˆåï¼Œè¯·æ ¸å¯¹é¢„è§ˆé¢æ¿ä¸­çš„å­—æ•°æ˜¯å¦å‡åŒ€ï¼Œç¡®ä¿åŠ¨ä½œè¿è´¯ã€‚")

st.title("ğŸ¬ ç”µå½±è§£è¯´å…¨æµç¨‹åˆ†é•œå¯¼æ¼”ç³»ç»Ÿ")

# ================= ç¬¬ä¸€é˜¶æ®µï¼šæ™ºèƒ½åˆ†é•œæ‹†è§£ =================
st.header("Step 1: å‰§æƒ…æ‹†è§£ä¸åˆ†é•œé‡ç»„")
uploaded_file = st.file_uploader("ä¸Šä¼ æ–‡æ¡ˆ (TXT)", type=['txt'])

if uploaded_file:
    raw_content = io.StringIO(uploaded_file.getvalue().decode("utf-8")).read()
    # å½»åº•æŠ¹é™¤åŸæ®µè½é€»è¾‘
    scrubbed_content = raw_content.replace("\n", "").replace("\r", "").replace(" ", "").strip()
    
    if st.button("ğŸš€ å¼€å§‹æ™ºèƒ½åˆ†é•œå¤„ç†"):
        if not api_key:
            st.error("è¯·å…ˆè¾“å…¥ API Key")
        else:
            try:
                client = OpenAI(api_key=api_key, base_url=base_url)
                
                # å¢å¼ºçš„åˆ†é•œ Prompt
                seg_prompt = f"""ä½ æ˜¯ä¸€ä¸ªç”µå½±è§†è§‰å¯¼æ¼”ã€‚è¯·å°†ä»¥ä¸‹æ— æ®µè½æ–‡æœ¬é‡æ–°è¿›è¡Œåˆ†é•œæ‹†è§£ã€‚

ä½ çš„æ ¸å¿ƒä»»åŠ¡ï¼š
1. **å­—æ•°ä¸Šé™**ï¼šæ¯ä¸€ä¸ªåˆ†é•œæ–‡æ¡ˆä¸¥æ ¼æ§åˆ¶åœ¨ 30-40 å­—ç¬¦ä¹‹é—´ï¼ˆä¸ºäº†åŒ¹é…5ç§’éŸ³é¢‘ï¼‰ã€‚
2. **åŠ¨ä½œèšåˆ**ï¼šä¸è¦ç®€å•åœ°ä¸€å¥ä¸€åˆ†ã€‚å¦‚æœè¿ç»­çš„å¥å­åœ¨æè¿°åŒä¸€ä¸ªè§’è‰²çš„è¿è´¯åŠ¨ä½œæˆ–ç¥æ€ï¼Œä¸”å­—æ•°ç›¸åŠ ä¸è¶…è¿‡40å­—ï¼Œè¯·å°†å®ƒä»¬åˆå¹¶åœ¨ä¸€ä¸ªåˆ†é•œä¸­ã€‚è¿™æ ·ç”Ÿæˆçš„è§†é¢‘æ‰æœ‰åŠ¨ä½œè·¨åº¦ã€‚
3. **å¼ºåˆ¶åˆ†å‰²**ï¼šè‹¥é‡åˆ°åœºæ™¯åˆ‡æ¢ã€æ–°è§’è‰²å¼€å£è¯´è¯ã€æˆ–è€…å­—æ•°å³å°†è¶…æ ‡ï¼Œå¿…é¡»ç«‹å³åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªåˆ†é•œã€‚
4. **åŸå‘³ä¿æŒ**ï¼šä¸¥ç¦ä¿®æ”¹ã€æ·»åŠ æˆ–é—æ¼åŸæ–‡ä»»ä½•æ–‡å­—ã€‚

å¾…å¤„ç†æ–‡æœ¬ï¼š
{scrubbed_content}"""

                with st.spinner("æ­£åœ¨è¿›è¡Œæ·±åº¦å‰§æƒ…åˆ†æä¸åˆ†é•œé‡ç»„..."):
                    response = client.chat.completions.create(
                        model=model_id,
                        messages=[{"role": "user", "content": seg_prompt}],
                        temperature=0.3 # é™ä½éšæœºæ€§ï¼Œä¿è¯å‡†ç¡®
                    )
                    raw_segments = response.choices[0].message.content.split('\n')
                    
                    # è¿‡æ»¤ç©ºè¡Œå¹¶æ¸…æ´—
                    processed_segments = []
                    for s in raw_segments:
                        s = s.strip()
                        if s and ('.' in s or 'ã€' in s):
                            # å»æ‰ AI å¯èƒ½è‡ªå¸¦çš„åºå·å‰ç¼€ï¼Œé‡æ–°ç»Ÿä¸€ç¼–å·
                            content_only = s.split('.', 1)[-1].split('ã€', 1)[-1].strip()
                            processed_segments.append(content_only)
                    
                    st.session_state.segments = processed_segments
                    st.session_state.batch_index = 0
                    st.session_state.final_results = []
            except Exception as e:
                st.error(f"åˆ†é•œå¼‚å¸¸: {str(e)}")

# å±•ç¤ºåˆ†é•œé¢„è§ˆé¢æ¿ (å¸¦å­—æ•°ç»Ÿè®¡)
if st.session_state.segments:
    st.subheader("ğŸ“Š åˆ†é•œé¢„è§ˆé¢æ¿ (å­—æ•°ç›‘æ§)")
    
    # æ„é€ è¡¨æ ¼æ•°æ®
    preview_data = []
    for i, seg in enumerate(st.session_state.segments):
        char_count = len(seg)
        # æ ¹æ®å­—æ•°ç»™å‡ºå»ºè®®
        status = "âœ… å®Œç¾" if 25 <= char_count <= 40 else "âš ï¸ åçŸ­(å»ºè®®åˆå¹¶)" if char_count < 25 else "âŒ è¿‡é•¿(å»ºè®®æ‹†åˆ†)"
        preview_data.append({
            "åˆ†é•œç¼–å·": i + 1,
            "æ–‡æ¡ˆå†…å®¹": seg,
            "å­—æ•°": char_count,
            "çŠ¶æ€å»ºè®®": status
        })
    
    df = pd.DataFrame(preview_data)
    st.table(df) # ä½¿ç”¨è¡¨æ ¼å±•ç¤ºï¼Œæ›´ç›´è§‚

    st.divider()

    # ================= ç¬¬äºŒé˜¶æ®µï¼šåˆ†æ‰¹æè¿°ç”Ÿæˆ =================
    st.header("Step 2: ç”Ÿæˆ AI ç”»é¢ä¸è§†é¢‘æè¿°")
    
    # è·å–è§’è‰²è®¾å®š
    char_info = st.text_area("1. è¯·è¾“å…¥æ ¸å¿ƒè§’è‰²è®¾å®šï¼ˆç€è£…ã€å¤–è²Œï¼‰", 
                            placeholder="ä¾‹å¦‚ï¼š\næ—å‡¡ï¼šå‰‘çœ‰æ˜Ÿç›®ï¼Œèº«ç©¿é»‘è‰²é‡‘çº¹åŠ²è£…ï¼Œè…°é—´ä½©åˆ€ã€‚",
                            height=100)
    
    if char_info:
        total = len(st.session_state.segments)
        current = st.session_state.batch_index
        end = min(current + 20, total)
        
        if current < total:
            if st.button(f"ğŸ¬ ç”Ÿæˆç¬¬ {current + 1} - {end} ç»„æè¿°"):
                try:
                    client = OpenAI(api_key=api_key, base_url=base_url)
                    batch_list = st.session_state.segments[current:end]
                    
                    # æ„å»ºå¸¦ä¸Šä¸‹æ–‡çš„æè¿° Prompt
                    batch_content = ""
                    for i, text in enumerate(batch_list):
                        batch_content += f"åˆ†é•œ{current + i + 1}ï¼š{text}\n"
                        
                    desc_prompt = f"""ä½ ç°åœ¨æ˜¯è§†è§‰å¯¼æ¼”ï¼Œè´Ÿè´£æ ¹æ®åˆ†é•œæ–‡æ¡ˆï¼Œè®¾è®¡Midjourneyç”Ÿå›¾æç¤ºè¯å’Œå³æ¢¦AIè§†é¢‘è¿åŠ¨æç¤ºè¯ã€‚

è§’è‰²è®¾å®šï¼š
{char_info}

è¦æ±‚ï¼š
1. **ç”»é¢æè¿° (MJ)**ï¼šæè¿°åˆ†é•œä¸­çš„é™æ€è§†è§‰ã€‚åŒ…å«ï¼šå…·ä½“åœºæ™¯ã€äººç‰©çš„å¤–è²Œã€ç²¾ç»†çš„ç€è£…ç»†èŠ‚ã€è§†è§’ï¼ˆç‰¹å†™/å…¨æ™¯ï¼‰ã€å…‰æ•ˆã€‚**ç¦æ­¢å‡ºç°åŠ¨ä½œè¯**ã€‚
2. **è§†é¢‘ç”Ÿæˆ (å³æ¢¦AI)**ï¼šåœ¨å›¾ç‰‡åŸºç¡€ä¸Šï¼Œæè¿°è¿™5ç§’å†…å‘ç”Ÿçš„åŠ¨ä½œæµã€‚é‡‡ç”¨**çŸ­å¥å †ç Œ**ã€‚æè¿°äººç‰©çš„ç¥æ€å˜åŒ–ã€è‚¢ä½“ä½ç§»ã€é•œå¤´æ¨è¿›æ–¹å¼ã€‚éµå¾ªâ€œå•ç„¦åŸåˆ™â€ï¼Œç¡®ä¿åŠ¨ä½œè¿è´¯æœ‰æ•…äº‹æ„Ÿã€‚
3. **ä¸€è‡´æ€§**ï¼šå¿…é¡»ä¸¥æ ¼éµå®ˆè§’è‰²è®¾å®šä¸­çš„å¤–è²Œæè¿°ï¼Œç¡®ä¿æ¯ä¸ªåˆ†é•œçš„äººä¸èµ°æ ·ã€‚

å¾…å¤„ç†åˆ†é•œç»„ï¼š
{batch_content}"""

                    with st.spinner(f"æ­£åœ¨æ·±åº¦è§£æç¬¬ {current+1} æ‰¹æ¬¡æè¿°..."):
                        response = client.chat.completions.create(
                            model=model_id,
                            messages=[{"role": "user", "content": desc_prompt}],
                            temperature=0.7
                        )
                        st.session_state.final_results.append(response.choices[0].message.content)
                        st.session_state.batch_index = end
                        st.rerun()
                except Exception as e:
                    st.error(f"æè¿°ç”Ÿæˆå¤±è´¥: {str(e)}")
        else:
            st.success("âœ¨ æ‰€æœ‰åˆ†é•œæè¿°å·²å…¨éƒ¨ç”Ÿæˆï¼")

        # ç»“æœåˆ†æ‰¹å±•ç¤º
        for idx, result in enumerate(st.session_state.final_results):
            with st.expander(f"ğŸ“¦ ç¬¬ {idx+1} æ‰¹æ¬¡ç”Ÿæˆç»“æœ (20ç»„)", expanded=True):
                st.text_area(f"æ‰¹æ¬¡{idx+1}ç»“æœ", result, height=500)
