import streamlit as st
import requests
import json
import re
import pandas as pd

# é¡µé¢é…ç½®
st.set_page_config(page_title="å¯¼æ¼”å¼•æ“ V15 - æç«¯æ— æŸç‰ˆ", layout="wide")

# --- å·¥å…·å‡½æ•°ï¼šåªç»Ÿè®¡æœ‰æ•ˆå­—ç¬¦ï¼ˆæ’é™¤æ ¼å¼å­—ç¬¦ï¼‰ ---
def count_valid_chars(text):
    if not text: return 0
    # åªç»Ÿè®¡æ±‰å­—ã€å­—æ¯ã€æ•°å­—
    valid_content = re.findall(r'[\u4e00-\u9fffA-Za-z0-9]', text)
    return len(valid_content)

# --- æ ¸å¿ƒå‡½æ•°ï¼šæ ¹æ®æ¢è¡Œé‡æ–°ç¼–å· ---
def force_renumber_by_paragraphs(text_input):
    raw_lines = text_input.split('\n')
    clean_shots = []
    for line in raw_lines:
        stripped_line = re.sub(r'^\s*\d+[\.ï¼ã€\s\-]*', '', line).strip()
        if stripped_line:
            clean_shots.append(stripped_line)
    numbered_script = "\n".join([f"{i+1}. {content}" for i, content in enumerate(clean_shots)])
    return numbered_script, clean_shots

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("âš™ï¸ æç«¯æ— æŸåè®®é…ç½®")
    api_key = st.text_input("API Key", type="password")
    base_url = st.text_input("æ¥å£åœ°å€", value="https://blog.tuiwen.xyz/v1")
    model_id = st.text_input("Model ID", value="grok-4.1")
    st.divider()
    st.error("ğŸš¨ æç«¯æ¨¡å¼æç¤ºï¼š\n1. AI å°†è¢«ç¦æ­¢ä»»ä½•æ€»ç»“è¡Œä¸ºã€‚\n2. è‹¥å­—æ•°ä»æœ‰åå·®ï¼Œè¯·è°ƒå°â€˜å¤„ç†çª—å£â€™ã€‚")
    chunk_val = st.slider("å¤„ç†çª—å£å¤§å° (å­—æ•°)", 300, 1500, 800) # è°ƒå°çª—å£èƒ½æœ‰æ•ˆé˜²æ­¢ä¸¢å­—
    overlap_val = st.slider("åˆ‡ç‰‡é‡å å­—æ•°", 0, 100, 50)

# --- åˆå§‹åŒ– Session State ---
if 'final_script' not in st.session_state: st.session_state.final_script = ""
if 'pure_shots_list' not in st.session_state: st.session_state.pure_shots_list = []
if 'raw_word_count' not in st.session_state: st.session_state.raw_word_count = 0

st.title("ğŸ¥ å‰§æƒ…é€»è¾‘åˆ†é•œç³»ç»Ÿ (V15 æç«¯æ— æŸç‰ˆ)")

# 1. æ–‡ä»¶ä¸Šä¼ 
uploaded_file = st.file_uploader("ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ æ–‡æ¡ˆ (TXT)", type=['txt'])
if uploaded_file:
    raw_content = uploaded_file.read().decode("utf-8")
    clean_text_flow = "".join(raw_content.split())
    st.session_state.raw_word_count = count_valid_chars(clean_text_flow)
    
    col_info, col_btn = st.columns([3, 1])
    col_info.info(f"ğŸ“„ åŸå§‹æ–‡å­—å‡€æ•°é‡ï¼š{st.session_state.raw_word_count} å­—")
    
    if col_btn.button("ğŸš€ å¯åŠ¨æç«¯æ— æŸåˆ†é•œåˆ†æ"):
        if not api_key:
            st.error("è¯·å¡«å…¥ API Key")
        else:
            # ä½¿ç”¨å¸¦é‡å çš„åˆ‡ç‰‡é€»è¾‘
            chunks = []
            for i in range(0, len(clean_text_flow), chunk_val - overlap_val):
                chunks.append(clean_text_flow[i : i + chunk_val])
            
            all_lines = []
            progress = st.progress(0)
            
            for idx, chunk in enumerate(chunks):
                # æç«¯ Prompt å‡çº§ï¼šä½¿ç”¨äº†â€œå¬å†™å‘˜â€æ¯”å–»
                system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæå…¶æ­»æ¿çš„å¬å†™å‘˜å’Œåˆ†é•œå¸ˆã€‚
                ä»»åŠ¡ï¼šå°†æ–‡æœ¬åˆ†é•œåŒ–ã€‚
                ã€é“å¾‹ã€‘ï¼š
                1. ä¸¥ç¦æ”¹åŠ¨ã€åˆ é™¤ã€æ€»ç»“ã€ç¼©å‡ä»»ä½•ä¸€ä¸ªå­—ï¼
                2. å¿…é¡»åŒ…å«åŸæ–‡ä¸­çš„æ¯ä¸€ä¸ªæ±‰å­—ã€æ¯ä¸€ä¸ªæ•°å­—ã€‚
                3. å¦‚æœä½ æ•¢ä¸¢æ‰ä¸€ä¸ªç‰‡æ®µï¼Œæˆ‘çš„é¡¹ç›®å°±ä¼šå½»åº•å¤±è´¥ã€‚
                4. é€»è¾‘åˆ‡æ¢ï¼šæ ¹æ®åœºæ™¯å˜åŒ–ã€äººç§°åˆ‡æ¢ã€åŠ¨ä½œè¿è´¯æ€§è¿›è¡Œç‰©ç†æ¢è¡Œã€‚
                5. æ ¼å¼ï¼š
                   1. å†…å®¹...
                   2. å†…å®¹...
                è¯·å¼€å§‹åˆ†é•œï¼Œç¡®ä¿è¾“å‡ºå†…å®¹çš„å­—æ•°ä¸è¾“å…¥æ–‡æœ¬å®Œå…¨ä¸€è‡´ï¼š"""
                
                try:
                    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
                    payload = {
                        "model": model_id, 
                        "messages": [
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": f"è¿™æ˜¯ç¬¬{idx+1}éƒ¨åˆ†å¾…å¤„ç†æ–‡æœ¬ï¼Œè¯·æ— æŸè½¬åŒ–ï¼š\n{chunk}"}
                        ], 
                        "temperature": 0.0 # å¼ºåˆ¶ 0 éšæœºæ€§ï¼Œé™ä½è‡ªç”±å‘æŒ¥ç©ºé—´
                    }
                    response = requests.post(f"{base_url}/chat/completions", headers=headers, json=payload)
                    res = response.json()['choices'][0]['message']['content']
                    
                    # æå–è¡Œï¼Œå¹¶è¿‡æ»¤æ‰å› ä¸ºâ€œé‡å åˆ‡ç‰‡â€å¯èƒ½å¯¼è‡´çš„é‡å¤è¡Œï¼ˆç®€å•é€»è¾‘å¤„ç†ï¼‰
                    lines = [re.sub(r'^\s*\d+[\.ï¼ã€\s\-]*', '', l).strip() for l in res.split('\n') if l.strip()]
                    
                    # é¿å…é‡å éƒ¨åˆ†çš„ç®€å•å»é‡é€»è¾‘ï¼šå¦‚æœæ–°æ®µè½çš„ç¬¬ä¸€è¡Œå·²ç»åœ¨ list çš„æœ€åä¸€è¡Œå‡ºç°äº†ï¼Œå°±è·³è¿‡
                    for line in lines:
                        if not all_lines or line not in all_lines[-2:]: # ç®€å•å¯¹æ¯”æœ€åä¸¤è¡Œï¼Œé˜²æ­¢ç”±äºåˆ‡ç‰‡é‡å å¯¼è‡´çš„é‡å¤
                            all_lines.append(line)
                            
                except Exception as e:
                    st.error(f"å¤„ç†ç¬¬{idx+1}å—æ—¶å‡ºé”™")
                
                progress.progress((idx + 1) / len(chunks))
            
            st.session_state.pure_shots_list = all_lines
            st.session_state.final_script = "\n".join([f"{i+1}. {s}" for i, s in enumerate(all_lines)])

# --- 2. æ ¸å¿ƒç¼–è¾‘ä¸ç¨½æ ¸åŒº ---
if st.session_state.final_script:
    processed_word_count = count_valid_chars(st.session_state.final_script)
    diff = processed_word_count - st.session_state.raw_word_count

    st.divider()
    # ç¨½æ ¸é¢æ¿ï¼šå¢åŠ é¢œè‰²è­¦æŠ¥
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("åŸæ–‡æ€»å­—æ•°", st.session_state.raw_word_count)
    m2.metric("å½“å‰åˆ†é•œç»„æ•°", len(st.session_state.pure_shots_list))
    m3.metric("åˆ†é•œæ€»å­—æ•°", processed_word_count)
    
    # åå·®å€¼çº¢è‰²é¢„è­¦
    if abs(diff) > 20:
        m4.subheader(f"âŒ åå·®ï¼š{diff} å­—")
        st.error(f"âš ï¸ è­¦å‘Šï¼šç›®å‰ä¸¢å¤±äº† {abs(diff)} ä¸ªå­—ï¼AI ä¾ç„¶å­˜åœ¨åˆ å‡è¡Œä¸ºã€‚è¯·å°è¯•è°ƒå°ä¾§è¾¹æ çš„â€˜å¤„ç†çª—å£å¤§å°â€™åˆ° 500 å·¦å³å¹¶é‡æ–°ç”Ÿæˆã€‚")
    else:
        m4.metric("åå·®å€¼ (æ— æŸåº¦)", f"{diff} å­—", delta=diff)

    col_l, col_r = st.columns([1, 1])
    
    with col_l:
        st.subheader("ğŸ“ åˆ†é•œæ— æŸç¼–è¾‘å™¨")
        user_edited_text = st.text_area("åœ¨ä¸‹æ–¹ä¿®æ”¹æˆ–å¢åŠ å›è½¦ï¼š", 
                                        value=st.session_state.final_script, 
                                        height=600, 
                                        key="editor_v15")
        
        if st.button("ğŸ”— ç¡®è®¤ä¿®æ”¹å¹¶è‡ªåŠ¨é‡ç¼–åºå·", type="primary"):
            new_script, new_list = force_renumber_by_paragraphs(user_edited_text)
            st.session_state.final_script = new_script
            st.session_state.pure_shots_list = new_list
            st.rerun()

    with col_r:
        st.subheader("ğŸ“Š å®æ—¶è§†è§‰èŠ‚å¥åˆ†æ")
        df = pd.DataFrame({
            "åºå·": range(1, len(st.session_state.pure_shots_list) + 1),
            "å†…å®¹": st.session_state.pure_shots_list,
            "å­—æ•°": [count_valid_chars(s) for s in st.session_state.pure_shots_list]
        })
        st.dataframe(df, height=550, use_container_width=True)
        st.download_button("ğŸ’¾ ä¸‹è½½æœ€ç»ˆè„šæœ¬", st.session_state.final_script, file_name="storyboard_v15.txt")
