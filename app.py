import streamlit as st
from openai import OpenAI
import re

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="AI å¯¼æ¼”çº§å‰§æƒ…åˆ†é•œ (é€»è¾‘ä¼˜å…ˆç‰ˆ)",
    page_icon="ğŸ¬",
    layout="wide"
)

# --- ä¾§è¾¹æ ï¼šè®¾ç½® ---
st.sidebar.header("âš™ï¸ å¯¼æ¼”æ§åˆ¶å°")

# 1. API è®¾ç½®
default_base_url = "https://blog.tuiwen.xyz/v1"
base_url = st.sidebar.text_input("API Base URL", value=default_base_url)
api_key = st.sidebar.text_input("API Key", type="password")

# 2. æ¨¡å‹é€‰æ‹© (è‡ªç”±åº¦æœ€é«˜)
st.sidebar.subheader("ğŸ¤– æ¨¡å‹é€‰æ‹©")
model_options = ["gpt-4o", "deepseek-chat", "claude-3-5-sonnet-20240620", "gemini-pro"]
selected_list_model = st.sidebar.selectbox("å¸¸ç”¨æ¨¡å‹", model_options, index=0)
custom_model_input = st.sidebar.text_input("æˆ–æ‰‹åŠ¨è¾“å…¥æ¨¡å‹ ID", value="", help="ä¼˜å…ˆä½¿ç”¨æ‰‹åŠ¨è¾“å…¥çš„ID")
final_model = custom_model_input if custom_model_input.strip() else selected_list_model

# --- æ ¸å¿ƒé€»è¾‘å‡½æ•° ---

def clean_text_structure(text):
    """
    æ¸…æ´—å‡½æ•°ï¼šå°†åŸæ–‡â€œæ‰â€æˆä¸€å›¢ï¼Œå¼ºè¿« AI é‡æ–°æ¢³ç†ã€‚
    """
    # ç§»é™¤æ¢è¡Œã€åˆ¶è¡¨ç¬¦
    text = text.replace('\n', '').replace('\r', '').replace('\t', '')
    # ç§»é™¤å¤šä½™ç©ºæ ¼
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

def get_director_prompt():
    return """
    ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„**ç”µå½±åˆ†é•œå¯¼æ¼”**ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®å‰§æƒ…çš„**è§†è§‰é€»è¾‘**å¯¹æ–‡æœ¬è¿›è¡Œåˆ†é•œæ‹†åˆ†ã€‚

    ### æ ¸å¿ƒåŸåˆ™ (Logic First)
    **è¯·å®Œå…¨å¿½ç•¥åŸæœ¬çš„æ®µè½ç»“æ„ï¼Œä¹Ÿä¸è¦è¢«å­—æ•°ä¸¥æ ¼é™åˆ¶ã€‚**
    ä½ éœ€è¦æ ¹æ®**â€œç”»é¢æ˜¯å¦éœ€è¦åˆ‡æ¢â€**æ¥å†³å®šæ˜¯å¦æ¢è¡Œã€‚

    ### ä»€ä¹ˆæ—¶å€™åº”è¯¥åˆ†é•œï¼ˆåˆ‡åˆ†æ ‡å‡†ï¼‰ï¼Ÿ
    1.  **è§’è‰²åˆ‡æ¢**ï¼šå¯¹è¯æƒä» A è½¬ç§»åˆ° Bï¼ˆå¦‚ï¼šAè¯´å®Œè¯ï¼Œè½®åˆ°Bè¯´ -> åˆ‡ï¼‰ã€‚
    2.  **åœºæ™¯/ç©ºé—´è½¬æ¢**ï¼šä»å®¤å†…è½¬åˆ°å®¤å¤–ï¼Œæˆ–æ—¶é—´è·¨åº¦å˜åŒ–ï¼ˆå¦‚ï¼šå›å¿†ç»“æŸå›åˆ°ç°å® -> åˆ‡ï¼‰ã€‚
    3.  **è§†è§‰ç„¦ç‚¹/åŠ¨ä½œçªå˜**ï¼š
        -   å‰åŠå¥æ˜¯é™æ€æå†™ï¼ˆçœ‹ç€çª—å¤–ï¼‰ï¼ŒååŠå¥çªç„¶å‘ç”ŸåŠ¨ä½œï¼ˆæ¯å­æ‘”ç¢äº†ï¼‰ -> åˆ‡ã€‚
        -   åŸæœ¬æ˜¯å…¨æ™¯å™è¿°ï¼Œçªç„¶è½¬ä¸ºç‰¹å†™å¿ƒç†æ´»åŠ¨ -> åˆ‡ã€‚

    ### ä»€ä¹ˆæ—¶å€™ã€ä¸ã€‘åº”è¯¥åˆ†é•œï¼Ÿ
    1.  **è¿è´¯çš„å™è¿°**ï¼šå¦‚æœä¸€å¥è¯å¾ˆé•¿ï¼ˆä¾‹å¦‚50-60å­—ï¼‰ï¼Œä½†å®ƒæè¿°çš„æ˜¯**åŒä¸€ä¸ªè¿ç»­çš„åŠ¨ä½œ**æˆ–**åŒä¸€ä¸ªäººçš„å®Œæ•´å¿ƒç†ç‹¬ç™½**ï¼Œ**è¯·ä¿ç•™åœ¨åŒä¸€è¡Œï¼Œä¸è¦æ‰“æ–­æƒ…ç»ª**ã€‚
    2.  **ä¸è¦ç ´ç¢åŒ–**ï¼šç¦æ­¢ä¸ºäº†å‡‘â€œçŸ­å¥â€è€ŒæŠŠä¸€å¥å®Œæ•´çš„è¯å¼ºè¡Œæ‹†æˆä¸¤åŠï¼ˆä¾‹å¦‚ï¼šâ€œ8å²é‚£å¹´å®¶é‡Œç©·å¾—â€å’Œâ€œæ­ä¸å¼€é”…äº†â€å¿…é¡»åœ¨åŒä¸€è¡Œï¼‰ã€‚

    ### è¾“å‡ºè¦æ±‚
    1.  **ç»å¯¹å¿ å®**ï¼šä¸å¾—åˆ å‡ã€ä¿®æ”¹ã€å¢åŠ åŸæ–‡ä»»ä½•å­—è¯ã€‚
    2.  **æ ¼å¼**ï¼šä»…è¾“å‡ºå¸¦æ•°å­—åºå·çš„åˆ†é•œåˆ—è¡¨ (1. 2. 3...)ã€‚
    """

# --- ä¸»ç•Œé¢ ---
st.title("ğŸ¬ å‰§æƒ…è‡ªåŠ¨åˆ†é•œå·¥å…· (é€»è¾‘ä¼˜å…ˆç‰ˆ)")
st.markdown("""
> **è®¾è®¡ç†å¿µæ›´æ–°**ï¼š
> ä¸å†å¼ºåˆ¶ 35 å­—åˆ‡åˆ†ã€‚AI å°†æ¨¡æ‹Ÿå¯¼æ¼”æ€ç»´ï¼Œä»…åœ¨**è§’è‰²åˆ‡æ¢ã€åœºæ™¯è½¬æ¢ã€åŠ¨ä½œçªå˜**æ—¶è¿›è¡Œåˆ†é•œï¼Œç¡®ä¿æ•…äº‹çš„è¿è´¯æ€§å’Œç”»é¢çš„åˆç†æ€§ã€‚
""")

uploaded_file = st.file_uploader("ä¸Šä¼ å‰§æœ¬/æ–‡æ¡ˆ (.txt)", type=['txt'])

if uploaded_file:
    # 1. è¯»å–å¹¶æ¸…æ´—
    raw_content = uploaded_file.read().decode("utf-8")
    merged_content = clean_text_structure(raw_content)

    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("1ï¸âƒ£ å‰§æƒ…æµ (å·²æ¸…æ´—)")
        st.info("å·²å»é™¤åŸæ–‡æ®µè½ï¼Œæ„å»ºè¿ç»­å‰§æƒ…æµï¼š")
        st.text_area("Source Stream", merged_content, height=500, disabled=True)

    with col2:
        st.subheader("2ï¸âƒ£ å¯¼æ¼”åˆ†é•œè¡¨")
        result_placeholder = st.empty()
        
        start_btn = st.button("å¼€å§‹å¯¼æ¼”åˆ†é•œ", type="primary", use_container_width=True)

        if start_btn:
            if not api_key:
                st.error("âš ï¸ è¯·è¾“å…¥ API Key")
            else:
                try:
                    client = OpenAI(api_key=api_key, base_url=base_url)
                    
                    st.toast(f"æ­£åœ¨è°ƒç”¨ {final_model} è¿›è¡Œé€»è¾‘åˆ†æ...")
                    
                    stream = client.chat.completions.create(
                        model=final_model,
                        messages=[
                            {"role": "system", "content": get_director_prompt()},
                            {"role": "user", "content": f"è¯·å¯¹ä»¥ä¸‹å‰§æƒ…æµè¿›è¡Œåˆ†é•œï¼š\n\n{merged_content}"}
                        ],
                        stream=True,
                        temperature=0.2 # ç¨å¾®æé«˜ä¸€ç‚¹ç‚¹æ¸©åº¦ï¼Œè®©å®ƒç†è§£è¯­ä¹‰é€»è¾‘ï¼Œä½†ä¾ç„¶ä¿æŒå…‹åˆ¶
                    )

                    full_response = ""
                    for chunk in stream:
                        if chunk.choices[0].delta.content:
                            content = chunk.choices[0].delta.content
                            full_response += content
                            result_placeholder.text_area("ç”Ÿæˆç»“æœ...", full_response, height=500)
                    
                    # æœ€ç»ˆå±•ç¤º
                    result_placeholder.text_area("æœ€ç»ˆåˆ†é•œè¡¨", full_response, height=500)
                    st.success("âœ… åˆ†é•œå®Œæˆï¼")
                    
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½åˆ†é•œè„šæœ¬",
                        data=full_response,
                        file_name="director_storyboard.txt",
                        mime="text/plain"
                    )

                except Exception as e:
                    st.error(f"âŒ é”™è¯¯: {e}")
