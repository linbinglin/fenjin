import streamlit as st
from openai import OpenAI
import re

# ================= é¡µé¢é…ç½® =================
st.set_page_config(
    page_title="AI åˆ†é•œåˆ†æ‰¹ç”Ÿæˆå™¨ (å¼ºä¸€è‡´æ€§ç‰ˆ)",
    page_icon="ğŸ¬",
    layout="wide"
)

# ================= Session State åˆå§‹åŒ– =================
if 'processed_result' not in st.session_state:
    st.session_state.processed_result = ""
if 'current_index' not in st.session_state:
    st.session_state.current_index = 0
if 'source_scenes' not in st.session_state:
    st.session_state.source_scenes = []
if 'is_processing' not in st.session_state:
    st.session_state.is_processing = False

# ================= ä¾§è¾¹æ è®¾ç½® =================
with st.sidebar:
    st.title("âš™ï¸ è®¾ç½®")
    
    st.subheader("1. æ¥å£é…ç½®")
    api_base = st.text_input("Base URL", value="https://blog.tuiwen.xyz/v1", help="æœ«å°¾é€šå¸¸éœ€è¦/v1")
    api_key = st.text_input("API Key", type="password")
    
    st.subheader("2. æ¨¡å‹é€‰æ‹©")
    model_options = ["gpt-4o", "claude-3-5-sonnet-20240620", "deepseek-chat"]
    selected_model = st.selectbox("é¢„è®¾æ¨¡å‹", model_options)
    custom_model = st.text_input("æ‰‹åŠ¨è¾“å…¥ Model ID (ä¼˜å…ˆ)", placeholder="ä¾‹å¦‚: gpt-4o")
    final_model = custom_model if custom_model else selected_model
    
    st.divider()
    
    st.subheader("3. æ‰¹å¤„ç†æ§åˆ¶")
    batch_size = st.slider("æ¯æ¬¡å¤„ç†åˆ†é•œæ•°", 1, 10, 3, help="å»ºè®®3ä¸ªï¼Œç¡®ä¿äººè®¾ä¸ä¸¢å¤±")

    st.divider()
    
    st.subheader("4. è§’è‰²è®¾å®š (âš ï¸å¿…é¡»å¡«å†™)")
    st.info("è¯·ä¸¥æ ¼æŒ‰æ ¼å¼ï¼šå§“åï¼šæè¿°è¯")
    # æä¾›äº†é»˜è®¤å€¼ç¤ºèŒƒï¼Œå¼ºè°ƒæ ¼å¼çš„é‡è¦æ€§
    default_profile = "èµµæ¸…æœˆï¼š(æ¸…å†·ç¾äººï¼Œçœ‰çœ¼æç²¾è‡´ï¼Œè‚¤ç™½å¦‚é›ªï¼Œé“¶ä¸è´è¶å ç ç°ªï¼Œç™½è‰²åˆºç»£ç»«ç½—çº±è¡£)\nèµµçµæ›¦ï¼š(æ˜è‰³å¼ æ‰¬ï¼Œæçœ¼æ¡ƒè‰²è…®ï¼Œè‚¤ç™½å¦‚é›ªï¼Œé‡‘ä¸èŠ±çº¹ç°ªï¼Œé»„è‰²å¦†èŠ±è¥¦è£™)"
    character_profile = st.text_area("äººç‰©å°ä¼ /å¤–è²Œæå†™", height=250, value=default_profile, placeholder=default_profile)

# ================= æ ¸å¿ƒé€»è¾‘ä¿®å¤åŒº =================

def parse_source_text(text):
    """æ™ºèƒ½è§£æåˆ†é•œåºå·"""
    text = text.replace("\r\n", "\n")
    pattern = r'(^|\n)(\d+[.ã€:ï¼š\s])'
    segments = re.split(pattern, text)
    scenes = []
    current_scene = ""
    for segment in segments:
        if not segment: continue
        if re.match(r'\d+[.ã€:ï¼š\s]', segment):
            if current_scene.strip(): scenes.append(current_scene.strip())
            current_scene = segment
        elif segment.strip() == "": continue
        else: current_scene += segment
    if current_scene.strip(): scenes.append(current_scene.strip())
    if len(scenes) < 2: scenes = [line.strip() for line in text.split('\n') if line.strip()]
    return scenes

def generate_prompt(batch_scenes, profile):
    """
    ã€æ ¸å¿ƒä¿®å¤ã€‘ï¼šæ„å»ºè¶…å¼ºçº¦æŸçš„ Prompt
    å¼ºåˆ¶è¦æ±‚ AI åœ¨è¾“å‡ºç”»é¢æè¿°æ—¶ï¼Œå¿…é¡»ã€å¤åˆ¶ç²˜è´´ã€‘ç”¨æˆ·æä¾›çš„ profile
    """
    scene_text = "\n\n".join(batch_scenes)
    
    return f"""
ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼æ‰§è¡Œå‘½ä»¤çš„AIåˆ†é•œå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†æ–‡æ¡ˆè½¬åŒ–ä¸ºMidjourneyï¼ˆç”»é¢ï¼‰å’Œå³æ¢¦AIï¼ˆè§†é¢‘ï¼‰çš„æç¤ºè¯ã€‚

### ğŸš¨ æœ€é«˜ä¼˜å…ˆçº§æŒ‡ä»¤ï¼šäººç‰©ä¸€è‡´æ€§ ğŸš¨
ä½ å¿…é¡»ä¸¥æ ¼éµå®ˆä»¥ä¸‹ã€å¼ºåˆ¶å¼•ç”¨è§„åˆ™ã€‘ï¼š
1. ä»”ç»†é˜…è¯»ä¸‹æ–¹çš„ã€äººç‰©èµ„æ–™åº“ã€‘ã€‚
2. åœ¨ç”Ÿæˆçš„æ¯ä¸€ä¸ªã€ç”»é¢æè¿°ã€‘ä¸­ï¼Œ**åªè¦è¯¥äººç‰©å‡ºç°ï¼Œä½ å¿…é¡»ç›´æ¥â€œå¤åˆ¶ç²˜è´´â€èµ„æ–™åº“ä¸­è¯¥äººç‰©æ‹¬å·å†…çš„æ‰€æœ‰å¤–è²Œæè¿°è¯**ã€‚
3. **ç¦æ­¢**è‡ªå·±ç¼–é€ è¡£æœï¼Œ**ç¦æ­¢**ç®€åŒ–æè¿°ã€‚å¦‚æœæ–‡æ¡ˆæ²¡è¯´æ¢è¡£æœï¼Œå°±å¿…é¡»ç”¨èµ„æ–™åº“é‡Œçš„é»˜è®¤ç€è£…ã€‚

ã€äººç‰©èµ„æ–™åº“ (å¿…é¡»æ­»è®°ç¡¬èƒŒ)ã€‘ï¼š
{profile}

---

### ä»»åŠ¡è¦æ±‚ï¼š
1. **åˆ†é•œæ‹†åˆ†**ï¼šè‹¥å•æ¡æ–‡æ¡ˆè¶…è¿‡40å­—æˆ–å«å¤šä¸ªåŠ¨ä½œï¼Œè¯·æ‹†åˆ†ä¸º X-1, X-2ã€‚
2. **ç”»é¢æè¿° (Midjourney)**ï¼š
   - æ ¼å¼ï¼šåœºæ™¯ç¯å¢ƒï¼Œå…‰å½±æ°”æ°›ï¼Œ(äººç‰©Aåå­—ï¼Œ**ç²˜è´´äººç‰©èµ„æ–™åº“é‡Œçš„å¤–è²ŒTag**)ï¼Œ(äººç‰©Båå­—ï¼Œ**ç²˜è´´äººç‰©èµ„æ–™åº“é‡Œçš„å¤–è²ŒTag**)
   - æ³¨æ„ï¼šè¿™æ˜¯é™æ€ç”»é¢ï¼Œä¸è¦å†™å¤§å¹…åº¦åŠ¨ä½œï¼ˆå¦‚è·‘ã€è·³ï¼‰ï¼Œåªå†™å§¿æ€ï¼ˆç«™ç«‹ã€ä¾§èº«ï¼‰ã€‚
3. **è§†é¢‘ç”Ÿæˆ (å³æ¢¦AI)**ï¼š
   - æè¿°å…·ä½“çš„åŠ¨ä½œå˜åŒ–ã€è¿é•œæ–¹å¼ã€‚è¿™æ˜¯ç”¨æ¥ç”Ÿæˆè§†é¢‘çš„ï¼Œå¯ä»¥å†™å¤§å¹…åº¦åŠ¨ä½œã€‚

### å¾…å¤„ç†æ–‡æ¡ˆï¼š
{scene_text}

### è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼ˆä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šè¯­ï¼‰ï¼š

NO.x æ–‡æ¡ˆï¼š[æ–‡æ¡ˆå†…å®¹]
ç”»é¢æè¿°ï¼š[åœºæ™¯]ï¼Œ[ç¯å¢ƒ]ï¼Œ(è§’è‰²åï¼Œç²˜è´´å¯¹åº”çš„å¤–è²Œæè¿°...)
è§†é¢‘ç”Ÿæˆï¼š[å…·ä½“åŠ¨ä½œ]ï¼Œ[è¿é•œæè¿°]
"""

# ================= ä¸»ç•Œé¢é€»è¾‘ =================

st.title("ğŸ¬ AI æ™ºèƒ½åˆ†é•œ - è§’è‰²å¼ºä¸€è‡´æ€§ç‰ˆ")

uploaded_file = st.file_uploader("ğŸ“‚ ä¸Šä¼ åˆ†é•œæ–‡æ¡ˆ (.txt)", type=["txt"])

if uploaded_file:
    file_content = uploaded_file.getvalue().decode("utf-8")
    
    if not st.session_state.source_scenes:
        st.session_state.source_scenes = parse_source_text(file_content)
        st.toast(f"å·²è§£æ {len(st.session_state.source_scenes)} ä¸ªåˆ†é•œ", icon="âœ…")

    total_scenes = len(st.session_state.source_scenes)
    progress = st.session_state.current_index / total_scenes if total_scenes > 0 else 0
    
    st.write(f"ğŸ“Š è¿›åº¦ï¼š{st.session_state.current_index}/{total_scenes}")
    st.progress(progress)

    # å¸ƒå±€
    col1, col2 = st.columns([1, 3])
    
    with col1:
        # æ£€æŸ¥æ˜¯å¦å…¨éƒ¨å®Œæˆ
        if st.session_state.current_index < total_scenes:
            btn_text = "ğŸš€ å¼€å§‹ç”Ÿæˆ" if st.session_state.current_index == 0 else "â­ï¸ ç»§ç»­ç”Ÿæˆä¸‹ä¸€æ‰¹"
            
            if st.button(btn_text, type="primary"):
                # æ£€æŸ¥å¿…è¦æ¡ä»¶
                if not api_key:
                    st.error("âŒ ç¼ºå°‘ API Key")
                elif not character_profile.strip():
                    st.error("âŒ å¿…é¡»å¡«å†™è§’è‰²è®¾å®šï¼å¦åˆ™ç”»é¢æ— æ³•ç»Ÿä¸€ã€‚")
                else:
                    # å‡†å¤‡æ•°æ®
                    start_idx = st.session_state.current_index
                    end_idx = min(start_idx + batch_size, total_scenes)
                    current_batch = st.session_state.source_scenes[start_idx:end_idx]
                    
                    # ç”Ÿæˆ Prompt
                    user_prompt = generate_prompt(current_batch, character_profile)
                    
                    # è°ƒç”¨ API
                    client = OpenAI(api_key=api_key, base_url=api_base)
                    
                    try:
                        with st.spinner(f"æ­£åœ¨ä¸¥æ ¼æŒ‰ç…§äººè®¾ç”Ÿæˆç¬¬ {start_idx+1}-{end_idx} ä¸ªåˆ†é•œ..."):
                            response_box = st.empty()
                            full_text = ""
                            
                            stream = client.chat.completions.create(
                                model=final_model,
                                messages=[
                                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ²¡æœ‰æ„Ÿæƒ…çš„æ ¼å¼åŒ–æœºå™¨ã€‚å¿…é¡»ä¸¥æ ¼æ‰§è¡ŒPromptä¸­çš„â€˜äººç‰©ä¸€è‡´æ€§â€™è¦æ±‚ï¼Œå¿…é¡»åŸæ ·å¤åˆ¶äººç‰©å¤–è²Œæè¿°ã€‚"},
                                    {"role": "user", "content": user_prompt}
                                ],
                                stream=True,
                                temperature=0.6 # ç¨å¾®é™ä½æ¸©åº¦ï¼Œè®©å®ƒæ›´å¬è¯ï¼Œå‡å°‘èƒ¡ç¼–ä¹±é€ 
                            )
                            
                            for chunk in stream:
                                if chunk.choices[0].delta.content:
                                    content = chunk.choices[0].delta.content
                                    full_text += content
                                    response_box.markdown(f"**å½“å‰ç”Ÿæˆä¸­...**\n\n{full_text}")
                            
                            # å­˜å‚¨ç»“æœ
                            st.session_state.processed_result += f"\n\n{full_text}"
                            st.session_state.current_index = end_idx
                            st.rerun()
                            
                    except Exception as e:
                        st.error(f"API é”™è¯¯: {str(e)}")
        else:
            st.success("ğŸ‰ å…¨éƒ¨å®Œæˆï¼")
            if st.button("ğŸ”„ æ¸…ç©ºé‡ç½®"):
                st.session_state.current_index = 0
                st.session_state.processed_result = ""
                st.rerun()

    # ç»“æœæ˜¾ç¤ºåŒº
    with col2:
        st.subheader("ğŸ“ ç”Ÿæˆç»“æœåŒº")
        if st.session_state.processed_result:
            st.download_button("ğŸ’¾ ä¸‹è½½ç»“æœ", st.session_state.processed_result, "åˆ†é•œæè¿°.txt")
            st.text_area("ç»“æœå†…å®¹", st.session_state.processed_result, height=600)
        else:
            st.info("ç­‰å¾…ç”Ÿæˆ... ç»“æœå°†æ˜¾ç¤ºåœ¨è¿™é‡Œ")
