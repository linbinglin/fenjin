import streamlit as st
from openai import OpenAI
import re
import pandas as pd
import math

# --- é¡µé¢åŸºç¡€é…ç½® ---
st.set_page_config(
    page_title="å…¨èƒ½æ–‡æ¡ˆÂ·ç”µå½±æ„Ÿåˆ†é•œç³»ç»Ÿ (V11)",
    page_icon="ğŸ¬",
    layout="wide"
)

# --- è‡ªå®šä¹‰ CSS (ä¸ºäº†è¿˜åŸæˆªå›¾ä¸­çš„ä¸“ä¸šæ„Ÿ) ---
st.markdown("""
<style>
    .metric-container {
        background-color: #f0f2f6;
        padding: 10px;
        border-radius: 5px;
        margin-bottom: 20px;
    }
    .stDataFrame { width: 100%; }
</style>
""", unsafe_allow_html=True)

# --- ä¾§è¾¹æ ï¼šå‚æ•°é…ç½® ---
with st.sidebar:
    st.header("âš™ï¸ å¯¼æ¼”å¼•æ“ V11")
    
    api_key = st.text_input("API Key", type="password", placeholder="sk-xxxxxxxx")
    base_url = st.text_input("æ¥å£åœ°å€", value="https://blog.tuiwen.xyz/v1")
    
    # æ¨¡å‹é€‰æ‹©
    model_options = ["gpt-4o", "deepseek-chat", "claude-3-5-sonnet-20240620", "grok-beta", "gpt-3.5-turbo"]
    selected_model = st.selectbox("Model ID", model_options, index=0)
    
    if st.checkbox("æ‰‹åŠ¨è¾“å…¥æ¨¡å‹ID"):
        model_id = st.text_input("è‡ªå®šä¹‰ID", value=selected_model)
    else:
        model_id = selected_model

    st.info("""
    **ğŸ“‹ V11 è§†è§‰åˆ‡åˆ†å‡†åˆ™ï¼š**
    1. **ä¸»è¯­å³é•œå¤´**ï¼šäººç§°åˆ‡æ¢å¿…é¡»åˆ‡é•œã€‚
    2. **åŠ¨ä½œå³åˆ†é•œ**ï¼šåŠ¨ä½œå®Œæˆå¿…é¡»åˆ‡é•œã€‚
    3. **ç¡¬æ€§35å­—**ï¼šå•è¡Œç¦æ­¢è¶…è¿‡35å­—ã€‚
    """)

# --- æ ¸å¿ƒå·¥å…·å‡½æ•° ---

def clean_text_for_ai(text):
    """é¢„å¤„ç†ï¼šå»é™¤æ¢è¡Œï¼Œå˜æˆçº¯æ–‡æœ¬æµ"""
    return text.replace("\n", "").replace("\r", "").strip()

def smart_split_text(text, chunk_size=800):
    """
    æ™ºèƒ½åˆ†æ®µï¼šæŒ‰å¥å·/æ ‡ç‚¹åˆ‡åˆ†ï¼Œé¿å…æˆªæ–­å¥å­ã€‚
    å°†é•¿æ–‡æœ¬åˆ‡åˆ†ä¸ºå¤šä¸ª chunkï¼Œæ¯ä¸ªçº¦ chunk_size å­—ã€‚
    """
    chunks = []
    current_chunk = ""
    
    # ç®€å•çš„æŒ‰å¥åˆ‡åˆ†é€»è¾‘
    sentences = re.split(r'([ã€‚ï¼ï¼Ÿ])', text)
    
    # é‡æ–°ç»„åˆ
    temp_sentences = []
    for i in range(0, len(sentences)-1, 2):
        temp_sentences.append(sentences[i] + sentences[i+1])
    if len(sentences) % 2 == 1:
        temp_sentences.append(sentences[-1])
        
    for sentence in temp_sentences:
        if len(current_chunk) + len(sentence) > chunk_size:
            chunks.append(current_chunk)
            current_chunk = sentence
        else:
            current_chunk += sentence
            
    if current_chunk:
        chunks.append(current_chunk)
    
    return chunks

def parse_storyboard_to_df(full_text):
    """
    å°†åˆ†é•œæ–‡æœ¬è§£æä¸º DataFrameï¼Œç”¨äºå³ä¾§è¡¨æ ¼å±•ç¤º
    """
    lines = full_text.strip().split('\n')
    data = []
    index_counter = 1
    
    for line in lines:
        line = line.strip()
        if not line: continue
        
        # å»é™¤å¼€å¤´çš„åºå· (æ¯”å¦‚ "1. xxx" -> "xxx")
        content = re.sub(r'^\d+[.ã€]\s*', '', line)
        
        length = len(content)
        status = "âœ… ç†æƒ³" if length <= 35 else "âš ï¸ è¿‡é•¿"
        
        data.append({
            "åºå·": index_counter,
            "å†…å®¹é¢„è§ˆ": content,
            "é•¿åº¦": length,
            "çŠ¶æ€": status
        })
        index_counter += 1
        
    return pd.DataFrame(data)

def get_system_prompt():
    return """
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç”µå½±è§£è¯´åˆ†é•œå¸ˆã€‚
    ä»»åŠ¡ï¼šå°†æä¾›çš„æ–‡æœ¬æŒ‰è§†è§‰é€»è¾‘æ‹†è§£ä¸ºåˆ†é•œè„šæœ¬ã€‚
    
    ã€æ ¸å¿ƒè§„åˆ™ã€‘ï¼š
    1. **ç»å¯¹å¿ å®**ï¼šä¸¥ç¦åˆ å‡åŸæ–‡ï¼Œä¸¥ç¦å¢åŠ åŸæ–‡æ²¡æœ‰çš„è¯ã€‚
    2. **åˆ†é•œé€»è¾‘**ï¼š
       - è§’è‰²åˆ‡æ¢ -> æ¢è¡Œ
       - åœºæ™¯/æ—¶é—´åˆ‡æ¢ -> æ¢è¡Œ
       - åŠ¨ä½œ/ç”»é¢æ”¹å˜ -> æ¢è¡Œ
    3. **é•¿åº¦é£æ§**ï¼š
       - æ¯ä¸€è¡Œä»£è¡¨çº¦5ç§’ç”»é¢ã€‚
       - **å¼ºåˆ¶**ï¼šå¦‚æœä¸€å¥è¯è¶…è¿‡35ä¸ªå­—ï¼Œå¿…é¡»åœ¨è¯­ä¹‰è¿è´¯å¤„å¼ºåˆ¶æ¢è¡Œã€‚
    
    ã€è¾“å‡ºæ ¼å¼ã€‘ï¼š
    ä¸è¾“å‡ºä»»ä½•å‰è¨€åè¯­ï¼Œåªè¾“å‡ºåˆ†é•œå†…å®¹ï¼Œæ¯è¡Œä¸€å¥ã€‚
    ï¼ˆä¸éœ€è¦ä½ è‡ªå·±æ ‡æ•°å­—åºå·ï¼Œç›´æ¥è¾“å‡ºæ–‡æœ¬è¡Œå³å¯ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ç¼–å·ï¼‰
    """

# --- ä¸»ç•Œé¢é€»è¾‘ ---

st.title("ğŸ¬ å…¨èƒ½æ–‡æ¡ˆÂ·ç”µå½±æ„Ÿåˆ†é•œç³»ç»Ÿ (V11)")

# 1. ä¸Šä¼ åŒºåŸŸ
uploaded_file = st.file_uploader("ğŸ“‚ é€‰æ‹© TXT æ–‡æ¡ˆ", type=['txt'])

if uploaded_file:
    raw_content = uploaded_file.read().decode("utf-8")
    flat_content = clean_text_for_ai(raw_content)
    input_len = len(flat_content)
    
    # è®¡ç®—éœ€è¦åˆ†å¤šå°‘æ®µ (æ¨¡ä»¿å›¾2)
    chunks = smart_split_text(flat_content, chunk_size=800) # 800å­—ä¸€æ®µï¼Œé˜²æ­¢AIè¿‡è½½
    total_chunks = len(chunks)

    # é¡¶éƒ¨ä»ªè¡¨ç›˜ (é™æ€)
    st.markdown("### ğŸ“Š è§†è§‰é€»è¾‘ç¨½æ ¸é¢æ¿")
    st.metric("åŸæ–‡æ€»å­—æ•°", f"{input_len} å­—")
    
    if total_chunks > 1:
        st.info(f"ğŸ“ å·²è¯†åˆ« {total_chunks} ä¸ªç‹¬ç«‹å‰§æƒ…å—ï¼Œæ­£åœ¨è¿›è¡Œè§†è§‰å•å…ƒè§„åˆ’...")
    
    # 2. å¯åŠ¨æŒ‰é’®
    if st.button("ğŸš€ å¯åŠ¨è§†è§‰æ— æŸåˆ†é•œ", type="primary"):
        if not api_key:
            st.error("è¯·é…ç½® API Key")
        else:
            client = OpenAI(api_key=api_key, base_url=base_url)
            
            full_results = []
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            try:
                # --- å¾ªç¯å¤„ç†æ¯ä¸ªå— (Chunking) ---
                for i, chunk in enumerate(chunks):
                    current_step = i + 1
                    status_text.text(f"æ­£åœ¨è§„åˆ’ç¬¬ {current_step}/{total_chunks} å—é•œå¤´... ({len(chunk)}å­—)")
                    
                    response = client.chat.completions.create(
                        model=model_id,
                        messages=[
                            {"role": "system", "content": get_system_prompt()},
                            {"role": "user", "content": f"å¤„ç†ä»¥ä¸‹æ–‡æœ¬ï¼š\n{chunk}"}
                        ],
                        temperature=0.1
                    )
                    
                    # è·å–ç»“æœå¹¶æ¸…ç†
                    chunk_res = response.choices[0].message.content
                    full_results.append(chunk_res)
                    
                    # æ›´æ–°è¿›åº¦æ¡
                    progress_bar.progress(current_step / total_chunks)

                status_text.text("âœ… æ‰€æœ‰é•œå¤´è§„åˆ’å®Œæ¯•ï¼Œæ­£åœ¨è¿›è¡Œæœ€ç»ˆåˆæˆ...")
                
                # --- åˆæˆæœ€ç»ˆç»“æœ ---
                # å°†æ‰€æœ‰æ®µè½æ‹¼åˆï¼Œå¹¶ç»Ÿä¸€æŒ‰è¡Œåˆ†å‰²
                combined_text = "\n".join(full_results)
                # æ¸…æ´—ç©ºè¡Œ
                final_lines = [line.strip() for line in combined_text.split('\n') if line.strip()]
                
                # é‡æ–°åŠ ä¸Šåºå· (1. 2. 3...)
                numbered_text = ""
                raw_text_only = "" # ç”¨äºè®¡ç®—ç”Ÿæˆæ€»å­—æ•°
                for idx, line in enumerate(final_lines):
                    clean_line = re.sub(r'^\d+[.ã€]\s*', '', line) # å†æ¬¡æ¸…æ´—ä»¥é˜²AIè‡ªå·±åŠ äº†åºå·
                    numbered_text += f"{idx+1}. {clean_line}\n"
                    raw_text_only += clean_line

                # --- ç»“æœå±•ç¤ºé¡µé¢ (æ¨¡ä»¿å›¾3) ---
                st.markdown("---")
                
                # è®¡ç®—ç»Ÿè®¡æ•°æ®
                output_len = len(raw_text_only)
                deviation = output_len - input_len
                scene_count = len(final_lines)
                avg_len = round(output_len / scene_count, 1) if scene_count > 0 else 0

                # é¡¶éƒ¨ç»Ÿè®¡æ  (Columns)
                m1, m2, m3, m4 = st.columns(4)
                m1.metric("åŸæ–‡æ€»å­—æ•°", f"{input_len}")
                m2.metric("ç”Ÿæˆåˆ†é•œæ€»æ•°", f"{scene_count} ç»„")
                m3.metric("å¤„ç†åæ€»å­—æ•°", f"{output_len}")
                m4.metric("åå·®å€¼", f"{deviation} å­—", 
                          delta_color="off" if deviation == 0 else "inverse")
                
                if abs(deviation) > 10:
                    st.warning(f"âš ï¸ åå·®ï¼š{deviation} å­—ã€‚æ­£æ•°ä¸ºé‡å¤/è„‘è¡¥ï¼Œè´Ÿæ•°ä¸ºæ¼å­—ã€‚")

                # --- åŒæ å¸ƒå±€ï¼šå·¦ä¾§ç¼–è¾‘å™¨ï¼Œå³ä¾§åˆ†æè¡¨ ---
                col_left, col_right = st.columns([1.8, 1.2]) # å·¦å®½å³çª„
                
                with col_left:
                    st.subheader("ğŸ¬ è§†è§‰åˆ†é•œç¼–è¾‘å™¨ (æ— æŸè¿˜åŸ)")
                    # Text Areaç”¨äºå¤åˆ¶
                    st.text_area("åˆ†é•œæ­£æ–‡", value=numbered_text, height=600)
                    
                    st.download_button(
                        "ğŸ’¾ ä¸‹è½½æœ€ç»ˆåˆ†é•œç¨¿",
                        data=numbered_text,
                        file_name="åˆ†é•œè„šæœ¬.txt"
                    )

                with col_right:
                    st.subheader("ğŸ“Š å®æ—¶è§†è§‰èŠ‚å¥åˆ†æ")
                    # ç”Ÿæˆ DataFrame
                    df = parse_storyboard_to_df(numbered_text)
                    
                    # ä½¿ç”¨ Streamlit çš„ Column Config ç¾åŒ–è¡¨æ ¼
                    st.dataframe(
                        df,
                        column_config={
                            "åºå·": st.column_config.NumberColumn("åºå·", width="small"),
                            "å†…å®¹é¢„è§ˆ": st.column_config.TextColumn("å†…å®¹é¢„è§ˆ", width="large"),
                            "é•¿åº¦": st.column_config.ProgressColumn(
                                "é•¿åº¦", 
                                format="%d", 
                                min_value=0, 
                                max_value=50, # è¿›åº¦æ¡æœ€å¤§å€¼è®¾ä¸º50ï¼Œæ–¹ä¾¿çœ‹35çš„ç•Œé™
                            ),
                            "çŠ¶æ€": st.column_config.TextColumn("çŠ¶æ€", width="small"),
                        },
                        hide_index=True,
                        height=600
                    )
                    
                    st.info(f"å¹³å‡æ¯é•œåœç•™ï¼š{avg_len} å­— (çº¦ {round(avg_len/7, 1)} ç§’)")

            except Exception as e:
                st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
