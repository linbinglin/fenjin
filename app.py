import streamlit as st
from openai import OpenAI
import re
import pandas as pd

# ==========================================
# 1. æ ¸å¿ƒå·¥å…·å‡½æ•°
# ==========================================

def get_pure_text(text):
    """æå–çº¯æ–‡æœ¬å†…å®¹ï¼Œæ’é™¤ç¼–å·å’Œç©ºæ ¼ï¼Œç”¨äº 1:1 ç²¾ç¡®å¯¹è´¦"""
    if not text: return ""
    # ç§»é™¤è¡Œé¦–ç¼–å·ï¼ˆåŒ¹é… æ•°å­—. æˆ– æ•°å­—ã€ æˆ– æ•°å­— ï¼‰
    text = re.sub(r'^\s*\d+[\.ã€\s]\s*', '', text, flags=re.MULTILINE)
    # ç§»é™¤æ‰€æœ‰ç©ºç™½ç¬¦
    return "".join(text.split())

def reindex_text(text):
    """ä¸€é”®é‡æ’åºå·ï¼Œæ”¯æŒäººå·¥å¢åˆ åˆ†é•œåçš„å¿«é€Ÿä¿®å¤"""
    lines = text.split('\n')
    valid_lines = []
    count = 1
    for line in lines:
        content = re.sub(r'^\s*\d+[\.ã€\s]\s*', '', line).strip()
        if content:
            valid_lines.append(f"{count}.{content}")
            count += 1
    return "\n".join(valid_lines)

def smart_chunk_text(text, max_chars=1200):
    """æ™ºèƒ½è¯­ä¹‰åˆ†æ®µï¼šç¡®ä¿ä»»åŠ¡å—åˆ‡åœ¨å¥å·å¤„ï¼Œé˜²æ­¢AIäº§ç”Ÿå†…å®¹é‡å¤"""
    chunks = []
    while len(text) > max_chars:
        split_index = -1
        # å¯»æ‰¾æœ€è¿‘çš„å¥å­ç»“æŸæ ‡å¿—
        for mark in ["\n", "ã€‚", "ï¼", "ï¼Ÿ"]:
            pos = text.rfind(mark, 0, max_chars)
            split_index = max(split_index, pos)
        
        if split_index == -1: split_index = max_chars
        else: split_index += 1 
            
        chunks.append(text[:split_index].strip())
        text = text[split_index:]
    if text: chunks.append(text.strip())
    return [c for c in chunks if c]

# ==========================================
# 2. é¡µé¢é…ç½®ä¸åˆå§‹åŒ–
# ==========================================

st.set_page_config(page_title="è§£è¯´åˆ†é•œ Pro V16", layout="wide")

if 'final_storyboard' not in st.session_state:
    st.session_state.final_storyboard = ""
if 'original_text_clean' not in st.session_state:
    st.session_state.original_text_clean = ""

# --- ä¾§è¾¹æ é…ç½® ---
with st.sidebar:
    st.title("âš™ï¸ å¼•æ“é…ç½®ä¸­å¿ƒ")
    api_key = st.text_input("1. API Key", type="password")
    
    # URL é€»è¾‘ä¿®å¤ï¼šè¿™é‡Œä¸å†è‡ªåŠ¨åŠ  /v1ï¼Œè®©ç”¨æˆ·è¾“å…¥ä»€ä¹ˆå°±æ˜¯ä»€ä¹ˆ
    base_url_input = st.text_input("2. æ¥å£åœ°å€", value="https://blog.tuiwen.xyz/v1")
    
    st.markdown("**3. Model ID**")
    model_id = st.text_input("æ¨¡å‹åç§°", value="gpt-4o", help="åƒä¸‡ä¸è¦å¡«é”™è¯¯çš„åç§°ï¼Œæ¨è gpt-4o")
    
    st.divider()
    st.info("""
    **ğŸï¸ å¯¼æ¼”æ‰‹å†Œï¼š**
    - 0 å­—æŸè€—è¿˜åŸã€‚
    - æ¯é•œ 25-35 å­—ï¼ŒèŠ‚å¥é»„é‡‘å¹³è¡¡ã€‚
    - **ä¸‡èƒ½é€‚é…**ï¼šå°è¯´ã€æ•£æ–‡ã€è§£è¯´ã€ç§‘æ™®é€šç”¨ã€‚
    """)

# ==========================================
# 3. ä¸»ç•Œé¢é€»è¾‘
# ==========================================

st.title("ğŸ¬ ç”µå½±è§£è¯´Â·ä¸‡èƒ½åˆ†é•œå¯¼æ¼”ç³»ç»Ÿ (V16)")
uploaded_file = st.file_uploader("ğŸ“‚ é€‰æ‹©æ–‡æ¡ˆ TXT æ–‡ä»¶", type=['txt'])

if uploaded_file:
    raw_text = uploaded_file.getvalue().decode("utf-8")
    # é”å®šåŸæ–‡è¿›è¡Œç¨½æ ¸
    st.session_state.original_text_clean = "".join(raw_text.split())
    input_len = len(st.session_state.original_text_clean)

    st.subheader("ğŸ“Š æ–‡æ¡ˆé€»è¾‘ç¨½æ ¸çœ‹æ¿")
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("åŸæ–‡æ€»å­—æ•°", f"{input_len} å­—")

    if st.button("ğŸš€ å¯åŠ¨è¯­ä¹‰æ— æŸåˆ†é•œ"):
        if not api_key:
            st.error("è¯·è¾“å…¥ API Key")
        else:
            try:
                # ã€è·¯å¾„ä¿®å¤å…³é”®ç‚¹ã€‘ï¼šå½»åº•æ¸…ç† URLï¼Œé˜²æ­¢é‡å¤ v1/v1
                clean_url = base_url_input.strip()
                if clean_url.endswith('/'): clean_url = clean_url[:-1]
                
                client = OpenAI(api_key=api_key, base_url=clean_url)
                
                # å¼€å§‹åˆ†å—å¤„ç†
                chunks = smart_chunk_text(st.session_state.original_text_clean)
                st.write(f"ğŸ“¦ æ–‡æœ¬å·²æ ¹æ®è¯­ä¹‰é”šç‚¹æ‹†åˆ†ä¸º {len(chunks)} ä¸ªä»»åŠ¡å—ï¼Œæ­£åœ¨å¤„ç†...")
                
                all_results = []
                current_idx = 1
                prog = st.progress(0)
                
                for i, chunk in enumerate(chunks):
                    with st.spinner(f"æ­£åœ¨å¤„ç†ç¬¬ {i+1} å—å†…å®¹..."):
                        # V16 å¯¼æ¼”æŒ‡ä»¤ï¼šä¸‡èƒ½å™äº‹é€»è¾‘
                        prompt = f"""ä½ æ˜¯ä¸€ä¸ªé«˜çº§è§£è¯´åˆ†é•œå¯¼æ¼”ã€‚
ã€åˆ†é•œèšåˆåŸåˆ™ã€‘ï¼š
1. **0 æŸé•œåƒè¿˜åŸ**ï¼šå¿…é¡» 1:1 è¾“å‡ºåŸæ–‡æ–‡å­—ã€‚ä¸å‡†åˆ å‡ã€é‡å¤ã€æ¶¦è‰²ã€‚
2. **é»„é‡‘å¹³è¡¡é•¿åº¦**ï¼šå•è¡Œç›®æ ‡ 25-35 å­—ã€‚
   - ä¸¥ç¦å‡ºç°ä½äº 15 å­—çš„ç¢å¥ã€‚å¦‚æœä¸€å¥è¯å¾ˆçŸ­ï¼Œå¿…é¡»ä¸å‰åæ–‡åˆå¹¶ã€‚
   - å¦‚æœä¸€å¥è¯è¶…é•¿ï¼Œå¿…é¡»åœ¨é€—å·æˆ–è¯­ä¹‰ç‚¹å¼ºè¡Œæˆªæ–­ã€‚
3. **è§†è§‰é©±åŠ¨**ï¼šä¸»è¯­åˆ‡æ¢ï¼ˆäººç§°æ¢äººï¼‰æˆ–å°è¯ç»“æŸå¿…é¡»åˆ‡åˆ†é•œã€‚
4. **ç¼–å·é”šç‚¹**ï¼šä»ç¼–å· {current_idx} å¼€å§‹ã€‚
å¾…å¤„ç†æ–‡æœ¬æµï¼š
{chunk}"""
                        
                        response = client.chat.completions.create(
                            model=model_id,
                            messages=[
                                {"role": "system", "content": "ä½ åªè¾“å‡ºå¸¦ç¼–å·çš„åˆ†é•œåˆ—è¡¨ï¼Œç¦æ­¢ä»»ä½•åºŸè¯ã€‚"},
                                {"role": "user", "content": prompt}
                            ],
                            temperature=0
                        )
                        chunk_res = response.choices[0].message.content.strip()
                        all_results.append(chunk_res)
                        
                        # åŠ¨æ€æ›´æ–°ä¸‹ä¸€å—èµ·å§‹ç¼–å·
                        nums = re.findall(r'(\d+)[\.ã€]', chunk_res)
                        if nums: current_idx = int(nums[-1]) + 1
                        prog.progress((i+1)/len(chunks))
                
                st.session_state.final_storyboard = "\n".join(all_results)
                st.success("å¯¼æ¼”è§„åˆ’å®Œæ¯•ï¼")
            except Exception as e:
                st.error(f"å¤„ç†å¤±è´¥: {str(e)}")

# ==========================================
# 4. ç¼–è¾‘ä¸ç›‘æ§åŒº
# ==========================================

if st.session_state.final_storyboard:
    st.divider()
    col_l, col_r = st.columns([2, 1])
    
    with col_l:
        st.subheader("âœï¸ å¯¼æ¼”ç²¾ä¿®åŒº")
        edited_text = st.text_area(
            "å¯åœ¨ä¸‹æ–¹æ‰‹åŠ¨å¢å‡å†…å®¹ï¼ˆå›è½¦åˆ†é•œï¼Œåˆ é™¤åˆå¹¶ï¼‰ï¼š",
            value=st.session_state.final_storyboard,
            height=600
        )
        
        c1, c2 = st.columns(2)
        if c1.button("ğŸ”¢ æ ¡å‡†æ‰€æœ‰åˆ†é•œåºå·"):
            st.session_state.final_storyboard = reindex_text(edited_text)
            st.rerun()
            
        c2.download_button("ğŸ’¾ ä¸‹è½½å…¨æœ¬åˆ†é•œç¨¿", st.session_state.final_storyboard, "storyboard_final.txt")

    with col_r:
        st.subheader("ğŸ“Š å®æ—¶èŠ‚å¥åˆ†æ")
        current_clean = get_pure_text(st.session_state.final_storyboard)
        curr_len = len(current_clean)
        diff = curr_len - len(st.session_state.original_text_clean)
        
        shot_lines = [l for l in st.session_state.final_storyboard.split('\n') if re.match(r'^\d+', l.strip())]
        
        st.metric("ç”Ÿæˆåˆ†é•œæ€»æ•°", f"{len(shot_lines)} ç»„")
        st.metric("å½“å‰è¿˜åŸå­—æ•°", f"{curr_len} å­—")
        
        if diff == 0: st.success("âœ… å­—æ•°å¯¹é½")
        else: st.error(f"âŒ åå·®ï¼š{diff} å­—")

        # èŠ‚å¥åˆ†æè¡¨
        analysis = []
        for i, line in enumerate(shot_lines):
            txt = re.sub(r'^\d+[\.ã€\s]\s*', '', line)
            ln = len(txt)
            analysis.append({"é•œå¤´": i+1, "å­—æ•°": ln, "çŠ¶æ€": "âœ…" if 15 <= ln <= 35 else "âš ï¸è°ƒèŠ‚å¥"})
        
        st.dataframe(pd.DataFrame(analysis), height=400, use_container_width=True)
