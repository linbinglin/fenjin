import streamlit as st
from openai import OpenAI
import io
import re
import pandas as pd

st.set_page_config(page_title="ç”µå½±è§£è¯´AIåˆ†é•œå¯¼æ¼”", layout="wide")

# --- åˆå§‹åŒ– Session State ---
if 'original_raw' not in st.session_state: st.session_state.original_raw = ""
if 'current_storyboard' not in st.session_state: st.session_state.current_storyboard = ""
if 'batch_results' not in st.session_state: st.session_state.batch_results = []
if 'process_idx' not in st.session_state: st.session_state.process_idx = 0

# --- ä¾§è¾¹æ é…ç½® ---
st.sidebar.title("âš™ï¸ å¯¼æ¼”å®¤è®¾ç½®")
api_key = st.sidebar.text_input("API Key", type="password")
base_url = st.sidebar.text_input("æ¥å£åœ°å€", value="https://blog.tuiwen.xyz/v1")
model_id = st.sidebar.text_input("Model ID", value="gpt-4o")

st.title("ğŸ¬ ç”µå½±è§£è¯´å…¨æµç¨‹æ— æŸåˆ†é•œå¯¼æ¼”")
st.info("ğŸ’¡ æ ¸å¿ƒè§„åˆ™ï¼š35å­—/5ç§’åŸåˆ™ï¼Œä¸€å­—ä¸å·®ï¼Œå¼ºåˆ¶åºå·ã€‚")

# ================= ç¬¬ä¸€é˜¶æ®µï¼šç‰©ç†ç²‰ç¢ä¸åˆ†é•œé‡ç»„ =================
st.header("Step 1: æ–‡æ¡ˆé‡ç»„åˆ†é•œ (æ— æŸåˆ‡å‰²)")

uploaded_file = st.file_uploader("é€‰æ‹©æœ¬åœ°TXTæ–‡æ¡ˆ", type=['txt'])

if uploaded_file:
    # å½»åº•æŠ¹é™¤åŸæ®µè½é€»è¾‘
    raw_text = io.StringIO(uploaded_file.getvalue().decode("utf-8")).read()
    # ç‰©ç†ç²‰ç¢ï¼šå»æ‰æ‰€æœ‰æ¢è¡Œã€ç©ºæ ¼ã€ç‰¹æ®Šåˆ¶è¡¨ç¬¦
    clean_stream = re.sub(r'[\s\n\r\t]+', '', raw_text).strip()
    st.session_state.original_raw = clean_stream
    
    st.write(f"âœ… **æ–‡æœ¬å·²ç‰©ç†ç²‰ç¢**ï¼šå¾…å¤„ç†å­—ç¬¦æ€»æ•° {len(clean_stream)} å­—ã€‚")

    if st.button("ğŸš€ å¼€å§‹ç”Ÿæˆåˆ†é•œè‰ç¨¿"):
        if not api_key:
            st.error("è¯·å…ˆé…ç½® API Key")
        else:
            try:
                client = OpenAI(api_key=api_key, base_url=base_url)
                
                # æç«¯ä¸¥å‰çš„ Step 1 æŒ‡ä»¤
                step1_prompt = f"""ä½ æ˜¯ä¸€ä¸ªç”µå½±åˆ†é•œå¯¼æ¼”ã€‚ä½ çš„ä»»åŠ¡æ˜¯å¯¹ä¸‹é¢è¿™æ®µæ²¡æœ‰ä»»ä½•æ®µè½çš„æ–‡æ¡ˆè¿›è¡Œã€æ— æŸåˆ†é•œåˆ‡å‰²ã€‘ã€‚

### å¼ºåˆ¶å‡†åˆ™ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰ï¼š
1. **ç»å¯¹æ— æŸ**ï¼šä¸¥ç¦åˆ é™¤ã€ä¿®æ”¹ã€ç¼©å‡ã€æ·»åŠ åŸæ–‡ä¸­çš„ä»»ä½•ä¸€ä¸ªå­—ã€‚
2. **å¼ºåˆ¶åºå·**ï¼šæ¯ä¸€è¡Œå¿…é¡»ä»¥â€œæ•°å­—.â€å¼€å¤´ï¼Œä¾‹å¦‚ï¼š1.æ–‡æ¡ˆå†…å®¹
3. **å­—æ•°çº¢çº¿**ï¼šæ¯ä¸ªåˆ†é•œæ–‡æ¡ˆç†æƒ³åœ¨ 20-35 å­—ç¬¦ã€‚ç»å¯¹ç¦æ­¢è¶…è¿‡ 40 å­—ç¬¦ï¼ˆå¯¹åº”5ç§’éŸ³é¢‘ï¼‰ã€‚
4. **åˆ†é•œé€»è¾‘**ï¼š
   - åªè¦é‡åˆ°ï¼šè§’è‰²è¯´è¯ã€åœºæ™¯åˆ‡æ¢ã€æ ¸å¿ƒåŠ¨ä½œæ”¹å˜ï¼Œå¿…é¡»å¦èµ·ä¸€è¡Œä½œä¸ºæ–°åˆ†é•œã€‚
   - å¦‚æœè¿ç»­çŸ­å¥åœ¨35å­—å†…ä¸”å±äºåŒä¸€è¿è´¯åŠ¨ä½œï¼Œè¯·èšæ‹¢åœ¨ä¸€è¡Œã€‚

### å¾…å¤„ç†å­—ç¬¦æµï¼š
{clean_stream}"""

                with st.spinner("AI æ­£åœ¨é€å­—åˆ†æå¹¶è¿›è¡Œæ— æŸåˆ†é•œ..."):
                    response = client.chat.completions.create(
                        model=model_id,
                        messages=[
                            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ— æŸåˆ†é•œæœºå™¨äººã€‚åªè¾“å‡ºå¸¦åºå·çš„åˆ†é•œï¼Œä¸å‡†è¯´åºŸè¯ï¼Œä¸å‡†æ¼å­—ã€‚"},
                            {"role": "user", "content": step1_prompt}
                        ],
                        temperature=0 # å¼ºåˆ¶ç¡®å®šæ€§
                    )
                    st.session_state.current_storyboard = response.choices[0].message.content
                    st.session_state.batch_results = []
                    st.session_state.process_idx = 0
            except Exception as e:
                st.error(f"åˆ†é•œç”Ÿæˆå¼‚å¸¸: {str(e)}")

# å±•ç¤ºä¸æ ¡éªŒé¢æ¿
if st.session_state.current_storyboard:
    col_edit, col_mon = st.columns([3, 2])
    
    with col_edit:
        st.subheader("âœï¸ åˆ†é•œç¼–è¾‘åŒº (ç¡®è®¤åºå·å’Œå­—æ•°)")
        # ç”¨æˆ·å¯ä»¥åœ¨æ­¤æ‰‹åŠ¨æ ¡æ­£ AI é—æ¼çš„åºå·æˆ–è¿‡é•¿çš„å¥å­
        st.session_state.current_storyboard = st.text_area(
            "åˆ†é•œæ–‡æ¡ˆè‰ç¨¿", 
            value=st.session_state.current_storyboard, 
            height=500
        )

    with col_mon:
        st.subheader("ğŸ“Š å®æ—¶ç›‘æ§çœ‹æ¿")
        lines = [l.strip() for l in st.session_state.current_storyboard.split('\n') if l.strip()]
        
        analysis_data = []
        reconstructed_text = ""
        
        for i, line in enumerate(lines):
            # æ­£åˆ™åŒ¹é…åºå·ï¼š1. æˆ–è€… 1ã€
            match = re.match(r'^(\d+)[.ã€\s]+(.*)', line)
            if match:
                num, content = match.groups()
                reconstructed_text += content
                char_len = len(content)
            else:
                content = line
                reconstructed_text += content
                char_len = len(content)
                num = "ERR" # ç¼ºå¤±åºå·æ ‡è®°

            # è¯„ä¼°çŠ¶æ€
            if char_len > 40: status = "ğŸ”´ è¿‡é•¿(>40)"
            elif char_len > 35: status = "ğŸŸ¡ æ‹¥æŒ¤(>35)"
            elif num == "ERR": status = "âš ï¸ ç¼ºå¤±åºå·"
            else: status = "ğŸŸ¢ ç†æƒ³"
            
            analysis_data.append({"åºå·": num, "å†…å®¹é¢„è§ˆ": content[:10]+"...", "å­—æ•°": char_len, "èŠ‚å¥": status})
        
        # æ— æŸæ ¡éªŒ
        orig_len = len(st.session_state.original_raw)
        curr_len = len(reconstructed_text)
        if orig_len == curr_len:
            st.success(f"âœ… æ— æŸæ£€æµ‹ï¼šé€šè¿‡ ({curr_len}/{orig_len})")
        else:
            diff = orig_len - curr_len
            st.error(f"âš ï¸ ä¸¢å­—è­¦å‘Šï¼šåŸ{orig_len}å­—ï¼Œç°{curr_len}å­— (ç›¸å·®{diff}å­—)")
        
        st.dataframe(pd.DataFrame(analysis_data), use_container_width=True)

    st.divider()

    # ================= ç¬¬äºŒé˜¶æ®µï¼šåˆ†æ­¥æè¿°ç”Ÿæˆ =================
    st.header("Step 2: ç”Ÿæˆç”»é¢ä¸è§†é¢‘æç¤ºè¯ (åˆ†æ‰¹)")
    
    char_info = st.text_area("1. è¯·è¾“å…¥è¯¥è§†é¢‘æ¶‰åŠçš„æ ¸å¿ƒäººç‰©æè¿° (ç€è£…ã€æ ·è²Œ)", 
                            placeholder="ä¾‹å¦‚ï¼šæ—å‡¡ï¼š25å²ï¼Œå‰‘çœ‰æ˜Ÿç›®ï¼Œç©¿ç€æ·±è“åˆºç»£é•¿è¡«ï¼Œè…°ä½©ç™½ç‰ã€‚",
                            height=100)
    
    if char_info:
        # é¢„å¤„ç†ç¡®è®¤çš„åˆ†é•œåˆ—è¡¨
        confirmed_lines = []
        for l in st.session_state.current_storyboard.split('\n'):
            if l.strip():
                # æå–æ–‡æ¡ˆ
                m = re.match(r'^(\d+)[.ã€\s]+(.*)', l.strip())
                confirmed_lines.append(m.group(2) if m else l.strip())
        
        total_shots = len(confirmed_lines)
        curr_p = st.session_state.process_idx
        batch_size = 20
        end_p = min(curr_p + batch_size, total_shots)

        if curr_p < total_shots:
            if st.button(f"ğŸï¸ ç”Ÿæˆåˆ†é•œæè¿° ({curr_p + 1} - {end_p})"):
                try:
                    client = OpenAI(api_key=api_key, base_url=base_url)
                    batch_text = ""
                    for i, t in enumerate(confirmed_lines[curr_p:end_p]):
                        batch_text += f"åˆ†é•œ{curr_p + i + 1}ï¼š{t}\n"
                    
                    step2_prompt = f"""ä½ ç°åœ¨æ˜¯è§†è§‰å¯¼æ¼”ã€‚è¯·æ ¹æ®åˆ†é•œæ–‡æ¡ˆç”Ÿæˆæç¤ºè¯ã€‚

ã€è§’è‰²è®¾å®šã€‘ï¼š
{char_info}

ã€è¦æ±‚ã€‘ï¼š
1. æ¯ä¸ªåˆ†é•œå¿…é¡»åŒ…å«ï¼š[ç”»é¢æè¿°(Midjourney)]ã€[è§†é¢‘ç”Ÿæˆ(å³æ¢¦AI)]ã€‚
2. **ç”»é¢æè¿°**ï¼šé’ˆå¯¹Midjourneyã€‚æè¿°é™æ€ï¼šæ™¯åˆ«ã€åœºæ™¯ã€äººç‰©ç»†èŠ‚ã€å…‰å½±ã€æè´¨ã€‚ä¸¥ç¦æè¿°è¡Œä¸ºã€‚
3. **è§†é¢‘ç”Ÿæˆ**ï¼šé’ˆå¯¹å³æ¢¦AIã€‚æè¿°åŠ¨æ€ï¼š5ç§’å†…çš„åŠ¨ä½œæµã€å¾®è¡¨æƒ…å˜åŒ–ã€é•œå¤´æ¨ç§»ã€‚é‡‡ç”¨çŸ­å¥å †ç Œã€‚
4. **å•ç„¦åŸåˆ™**ï¼šä¸€ä¸ªåˆ†é•œä¸“æ³¨ä¸€ä¸ªè§†è§‰é‡å¿ƒï¼ŒåŠ¨ä½œè¿è´¯ã€‚

ã€å¾…å¤„ç†æ–‡æ¡ˆã€‘ï¼š
{batch_text}"""

                    with st.spinner("æ­£åœ¨ç²¾ä¿®è§†è§‰æç¤ºè¯..."):
                        response = client.chat.completions.create(
                            model=model_id,
                            messages=[{"role": "user", "content": step2_prompt}]
                        )
                        st.session_state.batch_results.append(response.choices[0].message.content)
                        st.session_state.process_idx = end_p
                        st.rerun()
                except Exception as e:
                    st.error(f"æè¿°ç”Ÿæˆå¤±è´¥: {e}")
        else:
            st.success("âœ… å…¨éƒ¨åˆ†é•œæè¿°ç”Ÿæˆå®Œæ¯•ï¼")

        for r_idx, r_text in enumerate(st.session_state.batch_results):
            with st.expander(f"ğŸ“¦ æ‰¹æ¬¡ {r_idx+1} ç”Ÿæˆç»“æœ (20ç»„)", expanded=True):
                st.markdown(r_text)
