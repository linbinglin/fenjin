import streamlit as st
from openai import OpenAI
import re
import time

# ====================
# 1. é¡µé¢é…ç½®ä¸æ ·å¼
# ====================
st.set_page_config(
    page_title="å…¨èƒ½æ–‡æ¡ˆÂ·ç”µå½±æ„Ÿåˆ†é•œç³»ç»Ÿ (V12 Pro)",
    page_icon="ğŸ¬",
    layout="wide"
)

# æ³¨å…¥CSSä»¥å¤åˆ»UIé£æ ¼
st.markdown("""
<style>
    .main-header {font-size: 2rem; font-weight: bold; margin-bottom: 1rem;}
    .stat-box {
        background-color: #f8f9fa;
        padding: 20px;
        border-radius: 8px;
        text-align: center;
        border: 1px solid #e0e0e0;
        box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }
    .stat-value {font-size: 2.2rem; font-weight: bold; color: #333;}
    .stat-label {font-size: 0.9rem; color: #666; margin-top: 5px;}
    .stProgress > div > div > div > div {
        background-color: #007bff;
    }
    textarea {
        font-family: 'Courier New', Courier, monospace; /* å‰§æœ¬å¸¸ç”¨ç­‰å®½å­—ä½“ */
    }
</style>
""", unsafe_allow_html=True)

# ====================
# 2. ä¾§è¾¹æ é…ç½®
# ====================
with st.sidebar:
    st.markdown("### âš™ï¸ å¯¼æ¼”å¼•æ“ V12 è®¾ç½®")
    api_key = st.text_input("API Key", type="password")
    base_url = st.text_input("æ¥å£åœ°å€ (Base URL)", value="https://blog.tuiwen.xyz/v1")
    
    model_options = ["deepseek-chat", "gpt-4o", "claude-3-5-sonnet", "gemini-pro", "grok-beta", "è‡ªå®šä¹‰"]
    selected_model = st.selectbox("Model ID (æ¨¡å‹é€‰æ‹©)", model_options)
    
    if selected_model == "è‡ªå®šä¹‰":
        model_id = st.text_input("è¯·è¾“å…¥è‡ªå®šä¹‰æ¨¡å‹åç§°", value="grok-4.1")
    else:
        model_id = selected_model

# ====================
# 3. æ ¸å¿ƒé€»è¾‘å‡½æ•°
# ====================

def clean_text_for_count(text):
    """çº¯å‡€å­—æ•°ç»Ÿè®¡ï¼ˆå»é™¤æ‰€æœ‰æ ‡ç‚¹ç¬¦å·å’Œç©ºæ ¼ï¼‰"""
    if not text: return ""
    pattern = re.compile(r'[^\u4e00-\u9fa5a-zA-Z0-9]')
    return re.sub(pattern, '', text)

def split_text_into_chunks(text, max_chunk_size=1000):
    """
    æ™ºèƒ½åˆ†å—ç®—æ³•ï¼š
    å°†é•¿æ–‡æœ¬åˆ‡åˆ†æˆå¤šä¸ªå—ï¼Œé˜²æ­¢AIå¤„ç†é•¿æ–‡æ—¶æ³¨æ„åŠ›ä¸¢å¤±æˆ–â€œå·æ‡’â€ã€‚
    å°½é‡åœ¨å¥å·ã€æ„Ÿå¹å·å¤„åˆ‡åˆ†ï¼Œä¿è¯è¯­ä¹‰å®Œæ•´ã€‚
    """
    chunks = []
    current_chunk = ""
    
    # æŒ‰å¥å­ç²—ç•¥æ‹†åˆ†
    sentences = re.split(r'(ã€‚|ï¼|ï¼Ÿ|\n)', text)
    
    for part in sentences:
        if len(current_chunk) + len(part) < max_chunk_size:
            current_chunk += part
        else:
            if current_chunk:
                chunks.append(current_chunk)
            current_chunk = part
            
    if current_chunk:
        chunks.append(current_chunk)
        
    return chunks

def process_chunk(client, model, text_chunk, chunk_index, total_chunks):
    """
    å•ä¸ªå‰§æƒ…å—çš„å¤„ç†é€»è¾‘
    é‡ç‚¹ï¼šPromptè¦æ±‚â€œèšåˆâ€è€Œéâ€œæ‹†æ•£â€
    """
    system_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç”µå½±åˆ†é•œå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†å°è¯´æ–‡æœ¬è½¬æ¢ä¸ºç´§å‡‘çš„è§†é¢‘åˆ†é•œè„šæœ¬ã€‚
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹**â€œèšåˆé€»è¾‘â€**æ‰§è¡Œï¼š

1. **æ ¸å¿ƒç›®æ ‡**ï¼šå°†åŸæœ¬çç¢çš„çŸ­å¥ï¼Œåˆå¹¶æˆä¸€ä¸ªå®Œæ•´çš„ç”»é¢æè¿°ã€‚ä¸è¦æ¯ä¸€å¥è¯éƒ½æ¢è¡Œï¼
2. **æ—¶é•¿æ§åˆ¶**ï¼šæ¯ä¸€è¡Œåˆ†é•œçš„æ–‡æ¡ˆé•¿åº¦ï¼Œå¿…é¡»æ§åˆ¶åœ¨ **25-35ä¸ªå­—ç¬¦ä¹‹é—´**ï¼ˆçº¦5ç§’æ—¶é•¿ï¼‰ã€‚
   - å¦‚æœåŸæ–‡æ˜¯ "ä»–åƒé¥­ã€‚ä»–å–æ°´ã€‚" -> è¯·åˆå¹¶ä¸ºä¸€è¡Œï¼š"1.ä»–åƒé¥­ï¼Œåˆå–äº†ä¸€å£æ°´"
   - åªæœ‰å½“å­—æ•°è¶…è¿‡35å­—ï¼Œæˆ–è€…åœºæ™¯/è§’è‰²å‘ç”Ÿå‰§çƒˆåˆ‡æ¢æ—¶ï¼Œæ‰å…è®¸æ¢è¡Œã€‚
3. **ç»å¯¹æ— æŸ**ï¼šå¿…é¡»åŒ…å«åŸæ–‡æ‰€æœ‰ä¿¡æ¯ï¼Œä¸€ä¸ªå­—éƒ½ä¸èƒ½å°‘ï¼Œç¦æ­¢åˆ å‡ï¼Œç¦æ­¢æ·»åŠ åŸæ–‡æ²¡æœ‰çš„æè¿°ã€‚
4. **æ ¼å¼**ï¼šçº¯æ–‡æœ¬è¾“å‡ºï¼Œæ¯è¡Œä»¥æ•°å­—å¼€å¤´ï¼Œä¾‹å¦‚ "1. xxxxxx"ã€‚
5. **å¤„ç†å¯¹è±¡**ï¼šè¿™æ˜¯å…¨ä¹¦çš„ç¬¬ {chunk_index + 1}/{total_chunks} éƒ¨åˆ†ï¼Œè¯·ç´§æ¥ä¸Šæ–‡é€»è¾‘ã€‚

å¾…å¤„ç†æ–‡æœ¬ï¼ˆå¿½ç•¥åŸæœ‰æ¢è¡Œï¼Œé‡æ–°è§„åˆ’ï¼‰ï¼š
"""
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": text_chunk}
            ],
            stream=False,
            temperature=0.5 # é™ä½éšæœºæ€§ï¼Œè®©èšåˆæ›´ç¨³å®š
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Error: {str(e)}"

# ====================
# 4. ä¸»ç•Œé¢é€»è¾‘
# ====================

st.markdown('<div class="main-header">ğŸ¬ å…¨èƒ½æ–‡æ¡ˆÂ·ç”µå½±æ„Ÿåˆ†é•œç³»ç»Ÿ (V12 Pro)</div>', unsafe_allow_html=True)

uploaded_file = st.file_uploader("ğŸ“‚ é€‰æ‹© TXT æ–‡æ¡ˆ", type=['txt'])

if uploaded_file and api_key:
    raw_content = uploaded_file.read().decode("utf-8")
    # é¢„å¤„ç†ï¼šç§»é™¤åŸæ–‡æ¢è¡Œï¼Œå˜æˆä¸€æ•´æ¡æ•°æ®æµ
    clean_input = raw_content.replace("\n", "").replace("\r", "").strip()
    original_len = len(clean_text_for_count(clean_input))
    
    st.info(f"ğŸ“„ åŸæ–‡å·²åŠ è½½ï¼Œå…± {len(clean_input)} å­—ç¬¦ã€‚")

    if st.button("ğŸš€ å¯åŠ¨è§†è§‰æ— æŸåˆ†é•œ", type="primary"):
        
        # 1. åˆ‡åˆ†å‰§æƒ…å—
        chunks = split_text_into_chunks(clean_input, max_chunk_size=800) # 800å­—ä¸€å—ï¼Œä¿è¯AIæ³¨æ„åŠ›é›†ä¸­
        total_chunks = len(chunks)
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        full_result = []
        client = OpenAI(api_key=api_key, base_url=base_url)
        
        start_time = time.time()
        
        # 2. å¾ªç¯å¤„ç†æ¯ä¸ªå—
        for i, chunk in enumerate(chunks):
            status_text.markdown(f"**æ­£åœ¨å¤„ç†å‰§æƒ…å— {i+1}/{total_chunks}**... (æ­£åœ¨è¿›è¡Œè§†è§‰å•å…ƒè§„åˆ’)")
            
            chunk_result = process_chunk(client, model_id, chunk, i, total_chunks)
            
            if "Error" in chunk_result:
                st.error(f"å¤„ç†ç¬¬ {i+1} å—æ—¶å‡ºé”™: {chunk_result}")
                break
                
            # æ¸…ç†AIè¿”å›çš„æ ¼å¼ï¼ˆå»æ‰AIè‡ªå·±ç”Ÿæˆçš„åºå·ï¼Œæˆ‘ä»¬æœ€åç»Ÿä¸€åŠ ï¼‰
            # è¿™ä¸€æ­¥å¾ˆé‡è¦ï¼Œé˜²æ­¢AIç”Ÿæˆçš„åºå·æ–­å±‚
            lines = chunk_result.split('\n')
            for line in lines:
                clean_line = re.sub(r'^\d+[\.ã€]\s*', '', line).strip()
                if clean_line:
                    full_result.append(clean_line)
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.progress((i + 1) / total_chunks)
        
        # 3. æœ€ç»ˆç»„è£…
        status_text.success("âœ… åˆ†é•œè§„åˆ’å®Œæˆï¼æ­£åœ¨è¿›è¡Œå…¨é‡ç¨½æ ¸...")
        time.sleep(0.5)
        
        # é‡æ–°ç¼–å·
        final_output = ""
        final_clean_text = ""
        for idx, line in enumerate(full_result):
            final_output += f"{idx + 1}.{line}\n"
            final_clean_text += line
            
        # å­˜å…¥Session State
        st.session_state['final_output'] = final_output
        st.session_state['original_len'] = original_len
        st.session_state['final_clean_len'] = len(clean_text_for_count(final_clean_text))
        st.session_state['shot_count'] = len(full_result)
        st.session_state['chunks_count'] = total_chunks

# ====================
# 5. ç»“æœé¢æ¿ (UIå¤åˆ»)
# ====================

if 'final_output' in st.session_state:
    out_text = st.session_state['final_output']
    orig_len = st.session_state['original_len']
    final_len = st.session_state['final_clean_len']
    shots = st.session_state['shot_count']
    deviation = final_len - orig_len
    chunks_num = st.session_state['chunks_count']

    st.markdown("---")
    
    # è¿›åº¦æ¡å ä½å±•ç¤º (æ¨¡æ‹Ÿå›¾2)
    st.caption(f"ğŸ“š å·²è¯†åˆ« {chunks_num} ä¸ªç‹¬ç«‹å‰§æƒ…å—ï¼Œè§†è§‰å•å…ƒè§„åˆ’å®Œæ¯•ã€‚")
    st.progress(100)

    # æ•°æ®ç»Ÿè®¡å¡ç‰‡
    c1, c2, c3, c4 = st.columns(4)
    with c1:
        st.markdown(f'<div class="stat-box"><div class="stat-label">åŸæ–‡çº¯å­—æ•°</div><div class="stat-value">{orig_len}</div></div>', unsafe_allow_html=True)
    with c2:
        # é«˜äº®æ˜¾ç¤ºåˆ†é•œç»„æ•°ï¼Œè¿™åº”è¯¥æ˜¯ç°åœ¨çš„æ•°å€¼ä¼šå°‘å¾ˆå¤š
        st.markdown(f'<div class="stat-box" style="border: 2px solid #28a745;"><div class="stat-label">ç”Ÿæˆåˆ†é•œæ€»æ•°</div><div class="stat-value">{shots} ç»„</div></div>', unsafe_allow_html=True)
    with c3:
        st.markdown(f'<div class="stat-box"><div class="stat-label">å¤„ç†åçº¯å­—æ•°</div><div class="stat-value">{final_len}</div></div>', unsafe_allow_html=True)
    with c4:
        color = "#d9534f" if deviation != 0 else "#28a745"
        st.markdown(f'<div class="stat-box"><div class="stat-label">åå·®å€¼ (æ ‡ç‚¹é™¤å¤–)</div><div class="stat-value" style="color:{color}">{deviation} å­—</div></div>', unsafe_allow_html=True)

    # è­¦å‘Šä¿¡æ¯
    if deviation != 0:
        st.warning(f"âš ï¸ è­¦å‘Šï¼šAIé—æ¼æˆ–æ·»åŠ äº† {abs(deviation)} ä¸ªå­—ï¼Œè¯·æ£€æŸ¥æ–‡æœ¬æœ«å°¾æˆ–è¿‡é•¿æ®µè½ã€‚")
    else:
        st.success("âœ… å®Œç¾ï¼å­—æ•°é›¶åå·®ï¼Œå†…å®¹æ— æŸè¿˜åŸã€‚")

    # ç¼–è¾‘å™¨
    st.markdown("### ğŸ“ è§†è§‰åˆ†é•œç¼–è¾‘å™¨ (æ— æŸè¿˜åŸ)")
    st.text_area("ç”Ÿæˆç»“æœ (å¯ç›´æ¥å¤åˆ¶)", value=out_text, height=600)
    
    st.download_button("ğŸ“¥ ä¸‹è½½åˆ†é•œæ–‡ä»¶", out_text, "storyboard.txt")
