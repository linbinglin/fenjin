import streamlit as st
from openai import OpenAI
import re
import pandas as pd
import time

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="åˆ†é•œå¼•æ“ V4.0 (æ™ºèƒ½ç¼åˆç‰ˆ)",
    page_icon="ğŸ¬",
    layout="wide"
)

# --- CSSæ ·å¼ ---
st.markdown("""
<style>
    .main-header { font-size: 2.2rem; color: #333; font-weight: 700; }
    .stDataFrame { border: 1px solid #ddd; }
    div[data-testid="stMetricValue"] { font-size: 1.2rem; }
</style>
""", unsafe_allow_html=True)

# --- æ ¸å¿ƒå·¥å…·å‡½æ•° ---

def count_valid_chars(text):
    """ç»Ÿè®¡æœ‰æ•ˆå­—æ•°"""
    if not text: return 0
    clean_text = re.sub(r'[^\w\u4e00-\u9fa50-9]', '', text)
    return len(clean_text)

def analyze_rhythm(text):
    """åˆ†æåˆ†é•œèŠ‚å¥çŠ¶æ€"""
    length = count_valid_chars(text)
    if length == 0: return "âŒ ç©ºç™½", length
    if length < 10: return "ğŸŸ¡ è¾ƒçŸ­ (å¿«èŠ‚å¥)", length
    if 10 <= length <= 38: return "âœ… å®Œç¾ (5ç§’)", length
    return "ğŸ”´ è¾ƒé•¿ (éœ€å…³æ³¨)", length

def smart_chunking(text, max_chunk_size=1000):
    """åˆ†å—é˜²æ­¢å¹»è§‰"""
    sentences = re.split(r'(?<=[ã€‚ï¼ï¼Ÿ!?])', text)
    chunks = []
    current_chunk = ""
    for sentence in sentences:
        if len(current_chunk) + len(sentence) < max_chunk_size:
            current_chunk += sentence
        else:
            if current_chunk: chunks.append(current_chunk)
            current_chunk = sentence
    if current_chunk: chunks.append(current_chunk)
    return chunks

def post_process_merge(lines, max_chars=35, min_chars=12):
    """
    ã€V4.0 æ ¸å¿ƒç®—æ³•ï¼šè§†è§‰èƒ¶æ°´ã€‘
    å¼ºåˆ¶éå† AI è¾“å‡ºçš„åˆ—è¡¨ã€‚
    å¦‚æœå‘ç°æŸè¡Œå¤ªçŸ­ï¼ˆ< min_charsï¼‰ï¼Œä¸”åŠ ä¸Šä¸‹ä¸€è¡Œä¸è¶…è¿‡ max_charsï¼Œ
    åˆ™å¼ºåˆ¶åˆå¹¶ï¼Œæ²»æ„ˆâ€œç¢ç‰‡ç—‡â€ã€‚
    """
    if not lines: return []
    
    merged_lines = []
    buffer = lines[0] # åˆå§‹åŒ–ç¼“å†²åŒº
    
    for i in range(1, len(lines)):
        current_line = lines[i]
        buffer_len = count_valid_chars(buffer)
        current_len = count_valid_chars(current_line)
        
        # æ ¸å¿ƒåˆ¤æ–­é€»è¾‘ï¼š
        # 1. å¦‚æœç¼“å†²åŒºå¤ªçŸ­ (æ¯”å¦‚ "æ¯«æ— ç”¨å¤„" 4ä¸ªå­—)
        # 2. å¹¶ä¸”åˆå¹¶åæ€»é•¿åº¦ä¸ä»…æ²¡æœ‰è¶…æ ‡
        # 3. æˆ–è€…ç¼“å†²åŒºæœ¬èº«æ²¡æœ‰ç»“å°¾æ ‡ç‚¹ï¼ˆè¯´æ˜è¯æ²¡è¯´å®Œï¼‰
        should_merge = False
        
        # è§„åˆ™ A: æçŸ­ç¢ç‰‡å¼ºåˆ¶åˆå¹¶
        if buffer_len < min_chars and (buffer_len + current_len <= max_chars):
            should_merge = True
        
        # è§„åˆ™ B: è¯æ²¡è¯´å®Œï¼ˆæ— æ ‡ç‚¹ï¼‰å°è¯•åˆå¹¶
        if not re.search(r'[ã€‚ï¼ï¼Ÿ!?]$', buffer) and (buffer_len + current_len <= max_chars):
             should_merge = True

        if should_merge:
            buffer += current_line # ç¼åˆ
        else:
            merged_lines.append(buffer) # é‡Šæ”¾ç¼“å†²åŒº
            buffer = current_line # æ–°çš„ç¼“å†²åŒº
            
    merged_lines.append(buffer) # æœ€åçš„æ®‹ç•™
    return merged_lines

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.markdown("## âš™ï¸ å¼•æ“è®¾ç½® V4.0")
    base_url = st.text_input("Base URL", value="https://blog.tuiwen.xyz/v1")
    api_key = st.text_input("API Key", type="password")
    model_id = st.text_input("Model ID", value="gpt-4o")
    
    st.divider()
    st.markdown("### ğŸ”§ ç¢ç‰‡ä¿®å¤å¼ºåº¦")
    min_merge_len = st.slider("æœ€å°åˆ†é•œå­—æ•° (ä½äºæ­¤å€¼å°†å°è¯•åˆå¹¶)", 5, 20, 12, 
                              help="å¦‚æœåˆ†é•œå°äºè¿™ä¸ªå­—æ•°ï¼Œç®—æ³•ä¼šå¼ºåˆ¶å°†å…¶ä¸ä¸‹ä¸€è¡Œåˆå¹¶ï¼ˆé™¤éåˆå¹¶åå¤ªé•¿ï¼‰ã€‚è°ƒå¤§æ­¤å€¼å¯å‡å°‘ç¢ç‰‡ã€‚")

# --- ä¸»ç•Œé¢ ---
st.markdown('<div class="main-header">ğŸ¬ åˆ†é•œå¼•æ“ V4.0 (æ™ºèƒ½ç¼åˆç‰ˆ)</div>', unsafe_allow_html=True)
st.markdown("##### ğŸš€ æ ¸å¿ƒç‰¹æ€§ï¼šåˆ†å—æŠ—å¹»è§‰ + Pythonè§†è§‰èƒ¶æ°´(ä¿®å¤ç¢ç‰‡)")
st.divider()

uploaded_file = st.file_uploader("ğŸ“‚ é€‰æ‹© TXT æ–‡æ¡ˆ", type=["txt"])

if uploaded_file is not None:
    raw_text = uploaded_file.read().decode("utf-8")
    flattened_text = raw_text.replace('\n', '').replace('\r', '').strip()
    input_count = count_valid_chars(flattened_text)

    st.success(f"åŸæ–‡è£…è½½å®Œæ¯• | {input_count} å­—")
    
    if st.button("âš¡ å¯åŠ¨ç”Ÿæˆ", type="primary"):
        if not api_key:
            st.error("ç¼ºå°‘ API Key"); st.stop()

        # 1. æ™ºèƒ½åˆ†å—
        chunks = smart_chunking(flattened_text)
        client = OpenAI(api_key=api_key, base_url=base_url)
        
        raw_ai_lines = []
        progress_bar = st.progress(0)
        status = st.empty()
        
        # 2. AI ç²—å‰ª
        for i, chunk in enumerate(chunks):
            status.text(f"æ­£åœ¨åˆ†æç¬¬ {i+1}/{len(chunks)} åŒºå—...")
            
            # Prompt ä¾§é‡äºè¯­ä¹‰å®Œæ•´æ€§ï¼Œä¸å†è¿‡åˆ†å¼ºè°ƒçŸ­å¥ï¼Œå› ä¸ºåé¢æœ‰Pythonä»£ç æŠŠå…³
            system_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šåˆ†é•œå¸ˆã€‚è¯·å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œåˆ†é•œå¤„ç†ã€‚

ã€é‡è¦åŸåˆ™ã€‘
1. **ä¼˜å…ˆä¿æŒè¯­ä¹‰å®Œæ•´**ï¼šä¸è¦ä¸ºäº†æ¢è¡Œè€Œåˆ‡æ–­â€œä¸»è¯­-è°“è¯­-å®¾è¯­â€ç»“æ„ã€‚
   - é”™è¯¯ï¼šæœ€ç»ˆæŸ³ä¸ç›¸ / å’Œè´µå¦ƒ / è¢«åˆ¤å¤„è…°æ–©
   - æ­£ç¡®ï¼šæœ€ç»ˆæŸ³ä¸ç›¸å’Œè´µå¦ƒè¢«åˆ¤å¤„è…°æ–©
2. **ç¦æ­¢å¹»è§‰**ï¼šç»å¯¹ä¸è¦å¢åŠ åŸæ–‡æ²¡æœ‰çš„å­—ï¼Œä¸è¦åˆ å‡ã€‚
3. **æ¢è¡Œé€»è¾‘**ï¼šä»…åœ¨â€œåŠ¨ä½œåˆ‡æ¢â€ã€â€œåœºæ™¯åˆ‡æ¢â€æˆ–â€œå¥å­ç¡®å®å¤ªé•¿(>35å­—)â€æ—¶æ¢è¡Œã€‚

ã€æ–‡æœ¬ã€‘
{chunk}

è¯·è¾“å‡ºçº¯æ–‡æœ¬ï¼Œæ¯è¡Œä¸€å¥ï¼Œä¸è¦å¸¦åºå·ã€‚
"""
            try:
                response = client.chat.completions.create(
                    model=model_id,
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„åˆ†é•œå¸ˆã€‚ä¿æŒå¥æ„å®Œæ•´æ˜¯ç¬¬ä¸€ä¼˜å…ˆçº§ã€‚"},
                        {"role": "user", "content": system_prompt}
                    ],
                    temperature=0.1,
                )
                chunk_res = response.choices[0].message.content
                # æ”¶é›†æ‰€æœ‰è¡Œï¼Œå»é™¤ç©ºè¡Œ
                lines = [line.strip() for line in chunk_res.split('\n') if line.strip()]
                # å»é™¤å¯èƒ½å­˜åœ¨çš„åºå·
                lines = [re.sub(r'^\d+[\.ã€]\s*', '', line) for line in lines]
                raw_ai_lines.extend(lines)
                progress_bar.progress((i + 1) / len(chunks))
                
            except Exception as e:
                st.error(f"å¤„ç†å‡ºé”™: {e}"); break
        
        status.text("ğŸ¤– AI å¤„ç†å®Œæ¯•ï¼Œæ­£åœ¨è¿›è¡Œâ€œè§†è§‰èƒ¶æ°´â€ç¼åˆè¿ç®—...")
        
        # 3. Python å¼ºåŠ›ç¼åˆ (æ ¸å¿ƒä¿®æ­£æ­¥éª¤)
        # è°ƒç”¨æˆ‘ä»¬å†™çš„ç®—æ³•ï¼ŒæŠŠç¢ç‰‡ç²˜èµ·æ¥
        final_lines = post_process_merge(raw_ai_lines, max_chars=38, min_chars=min_merge_len)
        
        # 4. æ„å»ºè¾“å‡º
        final_text = ""
        valid_chars = 0
        data_list = []
        
        for idx, line in enumerate(final_lines):
            line_len = count_valid_chars(line)
            valid_chars += line_len
            rhythm, _ = analyze_rhythm(line)
            
            final_text += f"{idx+1}.{line}\n"
            data_list.append({
                "åºå·": idx+1,
                "åˆ†é•œå†…å®¹": line,
                "å­—æ•°": line_len,
                "çŠ¶æ€": rhythm
            })

        # 5. å±•ç¤º
        st.divider()
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("ğŸ“ æœ€ç»ˆåˆ†é•œ")
            st.text_area("ç»“æœ", value=final_text, height=600)
            
        with col2:
            st.subheader("ğŸ“Š æ•ˆæœç¨½æ ¸")
            diff = valid_chars - input_count
            st.metric("å­—æ•°åå·®", f"{diff} å­—", delta_color="off" if diff==0 else "inverse")
            if abs(diff) > 20:
                st.warning("å­—æ•°åå·®è¾ƒå¤§ï¼Œè¯·æ£€æŸ¥")
            else:
                st.success("å­—æ•°åŒ¹é…å®Œç¾")
                
            df = pd.DataFrame(data_list)
            
            def highlight(val):
                if 'âŒ' in val: return 'background-color: #ffcccc'
                if 'ğŸŸ¡' in val: return 'background-color: #fff8dc' # åªæœ‰æçŸ­æ—¶æ‰é»„
                return ''

            st.dataframe(
                df.style.map(highlight, subset=['çŠ¶æ€']),
                use_container_width=True,
                height=500,
                column_config={
                    "åºå·": st.column_config.NumberColumn(width="small"),
                    "åˆ†é•œå†…å®¹": st.column_config.TextColumn(width="large"),
                    "å­—æ•°": st.column_config.ProgressColumn(format="%d", max_value=40)
                }
            )
