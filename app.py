import streamlit as st
import openai
import json
import requests
import os
import tempfile
import time

# --- é¡µé¢å…¨å±€é…ç½® ---
st.set_page_config(page_title="IndexTTS é«˜çº§é…éŸ³å·¥ä½œå°", layout="wide")

# --- CSS æ ·å¼ä¼˜åŒ–ï¼šè®©ç•Œé¢æ›´åƒåŸç”Ÿåº”ç”¨ ---
st.markdown("""
<style>
    /* è§’è‰²å¡ç‰‡æ ·å¼ */
    .role-container {
        background-color: #2b2b2b;
        padding: 20px;
        border-radius: 10px;
        border: 1px solid #444;
        margin-bottom: 20px;
    }
    .role-header {
        font-size: 20px;
        font-weight: bold;
        color: #fff;
        margin-bottom: 10px;
        border-bottom: 1px solid #555;
        padding-bottom: 5px;
    }
    /* æ¨¡æ‹Ÿæˆªå›¾ä¸­çš„æ·±è‰²èƒŒæ™¯è¾“å…¥æ¡† */
    .stTextInput input {
        background-color: #1e1e1e;
        color: #e0e0e0;
        border: 1px solid #555;
    }
    /* æ»‘å—æ ·å¼å¾®è°ƒ */
    .stSlider > div > div > div > div {
        background-color: #7c4dff;
    }
</style>
""", unsafe_allow_html=True)

# --- Session State åˆå§‹åŒ– ---
if 'script_data' not in st.session_state:
    st.session_state.script_data = []
if 'roles' not in st.session_state:
    st.session_state.roles = set()
if 'role_settings' not in st.session_state:
    st.session_state.role_settings = {} # å­˜å‚¨æ¯ä¸ªè§’è‰²çš„è¯¦ç»†é…ç½®

# ================= ä¾§è¾¹æ é…ç½® =================
st.sidebar.title("ğŸ› ï¸ ç³»ç»Ÿè®¾ç½®")

with st.sidebar.expander("1. æ¨¡å‹æ¥å£ (LLM)", expanded=False):
    llm_base_url = st.text_input("Base URL", value="https://yunwu.ai/v1/")
    llm_api_key = st.text_input("API Key", type="password")
    model_options = ["deepseek-chat", "gpt-4o", "claude-3-5-sonnet", "gemini-1.5-pro"]
    selected_model = st.selectbox("é€‰æ‹©æ¨¡å‹", model_options + ["è‡ªå®šä¹‰"])
    if selected_model == "è‡ªå®šä¹‰":
        selected_model = st.text_input("è¾“å…¥æ¨¡å‹åç§°")

with st.sidebar.expander("2. IndexTTS æ¥å£è®¾ç½®", expanded=True):
    tts_api_url = st.text_input("API åœ°å€", value="http://127.0.0.1:9880/tts_advanced")
    st.caption("æ³¨ï¼šæ­¤æ¥å£éœ€æ”¯æŒæ¥æ”¶ emotion_vector å’Œ ref_audio_path å‚æ•°")

# ================= æ ¸å¿ƒå‡½æ•° =================

def parse_script_with_ai(text):
    """AI è§’è‰²è¯†åˆ«"""
    if not llm_api_key:
        st.error("è¯·å…ˆè®¾ç½® API Key")
        return None
    
    client = openai.OpenAI(api_key=llm_api_key, base_url=llm_base_url)
    prompt = """
    åˆ†æå‰§æœ¬ï¼Œæå–è§’è‰²å’Œå°è¯ã€‚
    æ ¼å¼ï¼šJSON æ•°ç»„ [{"role": "è§’è‰²å", "text": "å°è¯å†…å®¹"}]
    å¦‚æœæ˜¯æ—ç™½ï¼Œrole å¡« "æ—ç™½"ã€‚
    åªè¿”å› JSONï¼Œæ— Markdownã€‚
    """
    try:
        with st.spinner("æ­£åœ¨åˆ†æå‰§æœ¬..."):
            resp = client.chat.completions.create(
                model=selected_model,
                messages=[{"role": "system", "content": prompt}, {"role": "user", "content": text}],
                temperature=0.1
            )
            return json.loads(resp.choices[0].message.content.replace("```json","").replace("```",""))
    except Exception as e:
        st.error(f"è§£æå¤±è´¥: {e}")
        return None

def generate_audio_advanced(api_url, text, settings, output_path):
    """
    è°ƒç”¨æ”¯æŒé«˜çº§å‚æ•°çš„ TTS æ¥å£
    settings: åŒ…å« ref_audio_path, emotion_mode, emotion_vector ç­‰å­—å…¸
    """
    # æ„å»ºç¬¦åˆæˆªå›¾é€»è¾‘çš„ Payload
    payload = {
        "text": text,
        "ref_audio_path": settings.get("ref_audio_path", ""),
        "emotion_control": settings.get("emotion_mode", "ä½¿ç”¨æƒ…æ„Ÿå‘é‡"),
        "format": "mp3"
    }
    
    # åªæœ‰é€‰æ‹©äº†â€œä½¿ç”¨æƒ…æ„Ÿå‘é‡â€æ‰å‘é€å…·ä½“çš„æ•°å€¼
    if settings.get("emotion_mode") == "ä½¿ç”¨æƒ…æ„Ÿå‘é‡":
        payload["emotion_vector"] = {
            "happy": settings.get("happy", 0.0),
            "angry": settings.get("angry", 0.0),
            "sad": settings.get("sad", 0.0),
            "fear": settings.get("fear", 0.0),
            "disgust": settings.get("disgust", 0.0),
            "surprise": settings.get("surprise", 0.0),
        }

    try:
        resp = requests.post(api_url, json=payload, timeout=60)
        if resp.status_code == 200:
            with open(output_path, "wb") as f:
                f.write(resp.content)
            return True
        else:
            print(f"Error: {resp.text}")
            return False
    except Exception as e:
        print(f"Request Error: {e}")
        return False

# ================= ä¸»ç•Œé¢é€»è¾‘ =================

st.title("ğŸ›ï¸ AI å‰§æœ¬é…éŸ³ - é«˜çº§æ§åˆ¶ç‰ˆ")

# --- ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ ä¸è¯†åˆ« ---
uploaded_file = st.file_uploader("1. ä¸Šä¼ å‰§æœ¬ (TXT)", type="txt")
if uploaded_file and st.button("å¼€å§‹è§’è‰²åˆ†æ"):
    text = uploaded_file.getvalue().decode("utf-8")
    result = parse_script_with_ai(text)
    if result:
        st.session_state.script_data = result
        st.session_state.roles = sorted(list(set(r['role'] for r in result)))
        st.success(f"è¯†åˆ«åˆ° {len(st.session_state.roles)} ä¸ªè§’è‰²")

# --- ç¬¬äºŒæ­¥ï¼šé«˜çº§è§’è‰²é…ç½®ï¼ˆå¤åˆ»æˆªå›¾ç•Œé¢ï¼‰---
if st.session_state.roles:
    st.divider()
    st.header("2. è§’è‰²éŸ³è‰²ä¸æƒ…æ„Ÿé…ç½®")
    st.info("åœ¨æ­¤å¤„é…ç½®æ¯ä¸ªè§’è‰²çš„å‚è€ƒéŸ³é¢‘å’Œæƒ…æ„Ÿå‚æ•°ï¼Œè®¾ç½®å°†åº”ç”¨äºè¯¥è§’è‰²çš„æ‰€æœ‰å°è¯ã€‚")

    # ä¸ºæ¯ä¸ªè§’è‰²åˆ›å»ºä¸€ä¸ªé…ç½®é¢æ¿
    for role in st.session_state.roles:
        # åˆå§‹åŒ–è¯¥è§’è‰²çš„é»˜è®¤è®¾ç½®
        if role not in st.session_state.role_settings:
            st.session_state.role_settings[role] = {
                "ref_audio_path": "",
                "emotion_mode": "ä½¿ç”¨æƒ…æ„Ÿå‘é‡",
                "happy": 0.0, "angry": 0.0, "sad": 0.0, 
                "fear": 0.0, "disgust": 0.0, "surprise": 0.0
            }
        
        settings = st.session_state.role_settings[role]

        with st.expander(f"ğŸ‘¤ {role} é…ç½®é¢æ¿", expanded=False):
            # å¸ƒå±€ï¼šå·¦ä¾§å‚è€ƒéŸ³é¢‘ï¼Œå³ä¾§æƒ…æ„Ÿæ§åˆ¶
            c1, c2 = st.columns([2, 1])
            
            with c1:
                st.markdown("**å‚è€ƒéŸ³é¢‘ (Reference Audio)**")
                # é€‰é¡¹ 1ï¼šè¾“å…¥æœåŠ¡å™¨è·¯å¾„ (æˆªå›¾é£æ ¼)
                path_val = st.text_input(
                    f"æœ¬åœ°è·¯å¾„ (å¦‚ I:/F5tts/{role}.wav)", 
                    value=settings["ref_audio_path"],
                    key=f"path_{role}"
                )
                
                # é€‰é¡¹ 2ï¼šä¸Šä¼ æ–‡ä»¶ (é€‚åˆ Streamlit Cloud)
                uploaded_ref = st.file_uploader(f"æˆ–ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ ({role})", type=["wav", "mp3"], key=f"up_{role}")
                
                # é€»è¾‘ï¼šå¦‚æœæœ‰ä¸Šä¼ ï¼Œä¼˜å…ˆä½¿ç”¨ä¸Šä¼ çš„ä¸´æ—¶è·¯å¾„ï¼Œå¦åˆ™ä½¿ç”¨è¾“å…¥çš„è·¯å¾„
                if uploaded_ref:
                    # ä¿å­˜ä¸´æ—¶æ–‡ä»¶è·å–è·¯å¾„
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                        tmp.write(uploaded_ref.getvalue())
                        settings["ref_audio_path"] = tmp.name
                else:
                    settings["ref_audio_path"] = path_val

            with c2:
                st.markdown("**æƒ…æ„Ÿæ§åˆ¶ (Emotion Control)**")
                mode = st.selectbox(
                    "æ§åˆ¶æ¨¡å¼", 
                    ["ä¸è¯­éŸ³å‚è€ƒç›¸åŒ", "ä½¿ç”¨æƒ…æ„Ÿå‚è€ƒéŸ³é¢‘", "ä½¿ç”¨æƒ…æ„Ÿå‘é‡", "ä½¿ç”¨æ–‡æœ¬æè¿°"],
                    index=2, # é»˜è®¤é€‰ä¸­ "ä½¿ç”¨æƒ…æ„Ÿå‘é‡"
                    key=f"mode_{role}"
                )
                settings["emotion_mode"] = mode

            # --- æƒ…æ„Ÿå‘é‡æ»‘å— (ä»…å½“é€‰æ‹©â€œä½¿ç”¨æƒ…æ„Ÿå‘é‡â€æ—¶æ˜¾ç¤º) ---
            if mode == "ä½¿ç”¨æƒ…æ„Ÿå‘é‡":
                st.markdown("---")
                st.markdown("**æƒ…æ„Ÿå‘é‡è°ƒèŠ‚ (Emotion Vectors)**")
                
                # ä½¿ç”¨å¤šåˆ—å¸ƒå±€å¤åˆ»æˆªå›¾çš„æ’åˆ—
                ec1, ec2, ec3 = st.columns(3)
                
                with ec1:
                    settings["happy"] = st.slider("å¿«ä¹ (Happy)", 0.0, 1.0, settings["happy"], 0.1, key=f"happy_{role}")
                    settings["fear"] = st.slider("ææƒ§ (Fear)", 0.0, 1.0, settings["fear"], 0.1, key=f"fear_{role}")
                with ec2:
                    settings["angry"] = st.slider("æ„¤æ€’ (Angry)", 0.0, 1.0, settings["angry"], 0.1, key=f"angry_{role}")
                    settings["disgust"] = st.slider("åŒæ¶ (Disgust)", 0.0, 1.0, settings["disgust"], 0.1, key=f"disgust_{role}")
                with ec3:
                    settings["sad"] = st.slider("æ‚²ä¼¤ (Sad)", 0.0, 1.0, settings["sad"], 0.1, key=f"sad_{role}")
                    settings["surprise"] = st.slider("æƒŠè®¶ (Surprise)", 0.0, 1.0, settings["surprise"], 0.1, key=f"surprise_{role}")

    # --- ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆ ---
    st.divider()
    if st.button("ğŸš€ å¼€å§‹æ‰¹é‡åˆæˆ", type="primary"):
        st.write("æ­£åœ¨æ ¹æ®ä¸Šè¿°é«˜çº§é…ç½®ç”ŸæˆéŸ³é¢‘...")
        
        progress = st.progress(0)
        results = []
        total = len(st.session_state.script_data)
        temp_dir = tempfile.mkdtemp()

        for i, line in enumerate(st.session_state.script_data):
            role = line['role']
            text = line['text']
            
            # è·å–è¯¥è§’è‰²çš„ç‰¹å®šé…ç½®
            role_config = st.session_state.role_settings.get(role, {})
            
            file_name = f"{i}_{role}.mp3"
            out_path = os.path.join(temp_dir, file_name)
            
            # è°ƒç”¨æ¥å£
            success = generate_audio_advanced(tts_api_url, text, role_config, out_path)
            
            if success:
                results.append({"role": role, "text": text, "file": out_path})
            
            progress.progress((i + 1) / total)
            time.sleep(0.1)

        st.success("åˆæˆå®Œæ¯•ï¼")
        for res in results:
            with st.chat_message(name=res['role']):
                st.write(res['text'])
                st.audio(res['file'])
