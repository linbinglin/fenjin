import streamlit as st
import json
from openai import OpenAI
import io
import os
import subprocess
import tempfile
import re

st.set_page_config(page_title="AIå°è¯´é…éŸ³å·¥å…·", layout="wide")
st.title("AIå°è¯´é…éŸ³ç¨‹åºï¼ˆè‡ªéƒ¨ç½²äº‘ç«¯IndexTTS2ï¼‰")

# ==================== ä¾§è¾¹æ é…ç½® ====================
st.sidebar.header("API é…ç½®")

yunwu_api_key = st.sidebar.text_input("Yunwu.ai API Key (ç”¨äºè§’è‰²è¯†åˆ«)", type="password")
if not yunwu_api_key:
    st.sidebar.warning("è¯·å¡«å†™ Yunwu.ai Key ä»¥å¯ç”¨è§’è‰²è¯†åˆ«")

tts_base_url = st.sidebar.text_input(
    "IndexTTS2 API Base URL",
    value="https://ffo5lqa2aapiq89w-7860.containerx-gpu.com/",
    help="å¡«å†™æ‚¨çš„äº‘ç«¯å®ä¾‹åœ°å€ï¼ˆåŒ…å«æœ«å°¾æ–œæ  / ï¼‰"
)
tts_api_key = st.sidebar.text_input("IndexTTS2 API Key (è‹¥æ— éœ€è®¤è¯å¯ç•™ç©º)", type="password", value="")
tts_model = st.sidebar.text_input("IndexTTS2 æ¨¡å‹åç§°", value="indextts2", help="å¸¸è§å€¼ï¼šindextts2ã€IndexTTS-2 ç­‰")

if not tts_base_url:
    st.warning("è¯·åœ¨ä¾§è¾¹æ è¾“å…¥æ‚¨çš„ IndexTTS2 API Base URL")
    st.stop()

if yunwu_api_key:
    llm_client = OpenAI(base_url="https://yunwu.ai/v1", api_key=yunwu_api_key)
else:
    llm_client = None

# ==================== TTS Voice å‚æ•°è®¾ç½®ï¼ˆå…³é”®ä¿®å¤ï¼‰ ====================
st.sidebar.header("TTS Voice å‚æ•°è®¾ç½®ï¼ˆå¿…é¡»å¡«å†™ï¼‰")
st.sidebar.info("æ‚¨çš„å®ä¾‹è¦æ±‚ voice å‚æ•°ï¼Œè¯·å¡«å†™æœ¬åœ°è½¯ä»¶èƒ½æˆåŠŸçš„ voice å€¼")

common_voices = [
    "default", "male", "female",
    "zh_male", "zh_female",
    "Xiaoxiao", "Yunxi", "Yunjian",
    "male_qn", "female_qn"
]

selected_voice_preset = st.sidebar.selectbox("â‘  å¿«é€Ÿå°è¯•å¸¸è§voice", ["ï¼ˆä¸é€‰ï¼‰"] + common_voices, index=0)

custom_voice = st.sidebar.text_input(
    "â‘¡ voice å‚æ•°ï¼ˆè‡ªä¸»å¡«å†™ï¼Œä»¥æ­¤ä¸ºå‡†ï¼‰",
    value=selected_voice_preset if selected_voice_preset != "ï¼ˆä¸é€‰ï¼‰" else "",
    placeholder="ä¾‹å¦‚ï¼šdefault / male / Xiaoxiao / æ‚¨æœ¬åœ°è½¯ä»¶æˆåŠŸçš„voice"
)

final_voice = custom_voice.strip()
if not final_voice and selected_voice_preset != "ï¼ˆä¸é€‰ï¼‰":
    final_voice = selected_voice_preset

if not final_voice:
    st.sidebar.error("å¿…é¡»é€‰æ‹©æˆ–å¡«å†™ voice å‚æ•°ï¼")
    st.stop()

st.sidebar.success(f"å½“å‰ä½¿ç”¨ voiceï¼š**{final_voice}**")

# ==================== è§’è‰²è¯†åˆ«æ¨¡å‹é€‰æ‹© ====================
st.sidebar.header("è§’è‰²è¯†åˆ«æ¨¡å‹è®¾ç½®")
st.sidebar.info("æ¨èç¨³å®šæ¨¡å‹ï¼šgpt-4oã€claude-3-5-sonnet-20240620ã€gemini-1.5-pro")

common_models = [
    "gpt-4o", "gpt-4o-mini",
    "claude-3-5-sonnet-20240620", "claude-3-5-sonnet-20241022",
    "deepseek-chat", "gemini-1.5-pro", "gemini-1.5-flash",
    "grok-beta", "doubao-lite-32k"
]

selected_preset = st.sidebar.selectbox("â‘  å¿«é€Ÿé€‰æ‹©å¸¸ç”¨æ¨¡å‹", ["ï¼ˆä¸é€‰ï¼‰"] + common_models, index=0)
custom_model = st.sidebar.text_input(
    "â‘¡ æ¨¡å‹åç§°ï¼ˆè‡ªä¸»å¡«å†™ï¼Œä»¥æ­¤ä¸ºå‡†ï¼‰",
    value=selected_preset if selected_preset != "ï¼ˆä¸é€‰ï¼‰" else "",
    placeholder="ä¾‹å¦‚ï¼šgpt-4o"
)

final_model = custom_model.strip()
if not final_model and selected_preset != "ï¼ˆä¸é€‰ï¼‰":
    final_model = selected_preset

if not final_model:
    st.sidebar.error("å¿…é¡»é€‰æ‹©æˆ–å¡«å†™ä¸€ä¸ªæ¨¡å‹åç§°")
    st.stop()

st.sidebar.success(f"å½“å‰ä½¿ç”¨æ¨¡å‹ï¼š**{final_model}**")

# ==================== æ–‡ä»¶ä¸Šä¼ ä¸è§’è‰²è¯†åˆ« ====================
uploaded_file = st.file_uploader("ä¸Šä¼ å°è¯´TXTæ–‡ä»¶ï¼ˆåˆ†é•œå†…å®¹ï¼‰", type=["txt"])
if uploaded_file:
    text = uploaded_file.read().decode("utf-8")
    st.text_area("å°è¯´å…¨æ–‡é¢„è§ˆ", text, height=300)

    if st.button("ğŸ” è‡ªåŠ¨è¯†åˆ«è§’è‰²ä¸åˆ†æ®µ", type="primary"):
        if not llm_client:
            st.error("è¯·å…ˆå¡«å†™ Yunwu.ai API Key")
            st.stop()

        with st.spinner("AI æ­£åœ¨åˆ†ææ–‡æœ¬ï¼Œè¯†åˆ«è§’è‰²ä¸å°è¯..."):
            prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å°è¯´é…éŸ³è„šæœ¬åˆ†æå¸ˆã€‚è¯·å°†ä»¥ä¸‹å°è¯´æ–‡æœ¬åˆ†è§£ä¸ºé¡ºåºçš„é…éŸ³æ®µè½ã€‚

è¦æ±‚ï¼š
1. æ¯æ®µåªèƒ½æ˜¯â€œæ—ç™½â€ï¼ˆå™è¿°æ–‡å­—ï¼‰æˆ–æŸä¸ªè§’è‰²çš„å°è¯ã€‚
2. è‡ªåŠ¨è¯†åˆ«æ‰€æœ‰å‡ºç°çš„è§’è‰²åï¼ˆä¿æŒä¸€è‡´ï¼‰ã€‚
3. è¾“å‡ºä¸¥æ ¼ä¸ºå®Œæ•´çš„JSONæ•°ç»„ï¼Œæ ¼å¼ï¼š[ {{"role": "è§’è‰²åæˆ–æ—ç™½", "text": "è¯¥æ®µå®Œæ•´æ–‡å­—"}} ]
4. textå­—æ®µä¸­çš„åŒå¼•å·å¿…é¡»è½¬ä¹‰ä¸º \\"
5. è¦†ç›–å…¨éƒ¨æ–‡æœ¬ï¼Œç»ä¸èƒ½æˆªæ–­ã€‚
6. åªè¾“å‡ºçº¯JSONã€‚

å°è¯´æ–‡æœ¬ï¼š
{text}
"""

            try:
                response = llm_client.chat.completions.create(
                    model=final_model,
                    messages=[
                        {"role": "system", "content": "ä½ å¿…é¡»åªè¾“å‡ºå®Œæ•´çš„åˆæ³•JSONæ•°ç»„ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.2,
                    max_tokens=8192
                )
                content = response.choices[0].message.content.strip()

                if content.startswith("```"):
                    content = content.split("```")[1].strip()
                    if content.lower().startswith("json"):
                        content = content[4:].strip()

                try:
                    segments = json.loads(content)
                except json.JSONDecodeError as e:
                    st.warning(f"JSONè§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤ï¼š{e}")
                    content = re.sub(r',\s*]', ']', content)
                    content = content.strip()
                    if not content.endswith(']'): content += ']'
                    if not content.startswith('['): content = '[' + content
                    try:
                        segments = json.loads(content)
                        st.info("è‡ªåŠ¨ä¿®å¤æˆåŠŸ")
                    except:
                        st.error("ä¿®å¤å¤±è´¥")
                        st.code(content)
                        st.stop()

                st.session_state.segments = segments
                unique_roles = list(set(s['role'] for s in segments if s['role'] != 'æ—ç™½'))
                st.success(f"è¯†åˆ«å®Œæˆï¼å…± {len(segments)} æ®µï¼Œæ£€æµ‹åˆ°è§’è‰²ï¼š{unique_roles}")

            except Exception as e:
                st.error(f"è¯†åˆ«å¤±è´¥ï¼š{e}")

# ==================== ç”ŸæˆéŸ³é¢‘ ====================
if 'segments' in st.session_state:
    segments = st.session_state.segments
    tts_client = OpenAI(base_url=tts_base_url.rstrip("/"), api_key=tts_api_key or "none")

    st.header("ğŸ¤ å½“å‰è®¾ç½®ï¼šç»Ÿä¸€ä½¿ç”¨åŒä¸€voiceï¼ˆæ‰€æœ‰è§’è‰²+æ—ç™½ï¼‰")
    st.info("IndexTTS2 æ”¯æŒå£°çº¿å…‹éš†ï¼Œåç»­å¯ä¸ºæ¯ä¸ªè§’è‰²ä¸Šä¼ å‚è€ƒéŸ³é¢‘å®ç°ä¸åŒå£°éŸ³")

    if st.button("ğŸ”Š ç”Ÿæˆå®Œæ•´é…éŸ³", type="primary"):
        with st.spinner("æ­£åœ¨è°ƒç”¨äº‘ç«¯IndexTTS2ç”Ÿæˆå¹¶åˆå¹¶éŸ³é¢‘..."):
            audio_bytes_list = []
            progress_bar = st.progress(0)
            for i, seg in enumerate(segments):
                text_seg = seg["text"].strip()
                if not text_seg:
                    continue
                try:
                    response = tts_client.audio.speech.create(
                        model=tts_model,
                        voice=final_voice,  # å…³é”®ï¼šæ·»åŠ voiceå‚æ•°
                        input=text_seg,
                        response_format="mp3"
                    )
                    audio_bytes_list.append(response.content)
                except Exception as e:
                    st.error(f"ç¬¬ {i+1} æ®µï¼ˆ{seg['role']}ï¼‰ç”Ÿæˆå¤±è´¥ï¼š{e}")
                progress_bar.progress((i + 1) / len(segments))

            if not audio_bytes_list:
                st.error("æ‰€æœ‰æ®µè½ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥ voice å‚æ•°æ˜¯å¦æ­£ç¡®")
                st.stop()

            # ffmpeg åˆå¹¶
            with tempfile.TemporaryDirectory() as tmpdir:
                input_paths = []
                for idx, audio_bytes in enumerate(audio_bytes_list):
                    path = os.path.join(tmpdir, f"seg{idx}.mp3")
                    with open(path, "wb") as f:
                        f.write(audio_bytes)
                    input_paths.append(path)

                list_path = os.path.join(tmpdir, "list.txt")
                with open(list_path, "w") as f:
                    for p in input_paths:
                        f.write(f"file '{p}'\n")

                output_path = os.path.join(tmpdir, "output.mp3")
                result = subprocess.run([
                    "ffmpeg", "-y", "-f", "concat", "-safe", "0", "-i", list_path,
                    "-c", "copy", output_path
                ], capture_output=True)
                if result.returncode != 0:
                    subprocess.run([
                        "ffmpeg", "-y", "-f", "concat", "-safe", "0", "-i", list_path,
                        "-c:a", "libmp3lame", output_path
                    ], check=True)

                with open(output_path, "rb") as f:
                    combined_bytes = f.read()

            output_io = io.BytesIO(combined_bytes)
            st.audio(output_io, format="audio/mp3")
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½å®Œæ•´é…éŸ³MP3",
                data=output_io,
                file_name="AIé…éŸ³_IndexTTS2.mp3",
                mime="audio/mp3"
            )
            st.success("é…éŸ³ç”Ÿæˆå¹¶åˆå¹¶å®Œæˆï¼")

st.info("""
éƒ¨ç½²è¦æ±‚ï¼š
- requirements.txtï¼šstreamlit\nopenai
- packages.txtï¼šffmpeg
å»ºè®®ï¼šå…ˆç”¨æçŸ­æ–‡æœ¬ï¼ˆ1-2å¥ï¼‰æµ‹è¯•é…éŸ³ï¼Œæ‰¾åˆ°æ­£ç¡®çš„ voice å€¼åå†å¤„ç†é•¿æ–‡ã€‚
å¦‚æœè¿˜æœ‰æŠ¥é”™ï¼ˆæ¯”å¦‚ voice ä¸æ”¯æŒï¼‰ï¼Œè¯·æŠŠé”™è¯¯æˆªå›¾å‘æˆ‘ï¼Œæˆ‘ç»§ç»­å¸®æ‚¨è°ƒã€‚
""")
