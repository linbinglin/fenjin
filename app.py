import streamlit as st
from openai import OpenAI
import re
import pandas as pd
import string

# --- é¡µé¢åŸºç¡€é…ç½® ---
st.set_page_config(
    page_title="å¯¼æ¼”å¼•æ“ V12 (æ— æŸæ——èˆ°ç‰ˆ)",
    page_icon="ğŸ¬",
    layout="wide"
)

# --- è‡ªå®šä¹‰ CSS (å¯¼æ¼”çº§é»‘æ·±è‰²æ¨¡å¼é€‚é…) ---
st.markdown("""
<style>
    .metric-box {
        background-color: #f0f2f6;
        padding: 15px;
        border-radius: 8px;
        border-left: 5px solid #ff4b4b;
        margin-bottom: 20px;
    }
    .stProgress > div > div > div > div {
        background-color: #ff4b4b;
    }
</style>
""", unsafe_allow_html=True)

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("âš™ï¸ å¯¼æ¼”å¼•æ“ V12")
    st.caption("æ——èˆ°ç‰ˆï¼šæ™ºèƒ½çº é”™ + è§†è§‰é‡éŸ³åˆ‡åˆ†")
    
    api_key = st.text_input("API Key", type="password", placeholder="sk-...")
    base_url = st.text_input("æ¥å£åœ°å€", value="https://blog.tuiwen.xyz/v1")
    
    model_options = ["gpt-4o", "deepseek-chat", "claude-3-5-sonnet-20240620", "gpt-4-turbo", "gpt-3.5-turbo"]
    selected_model = st.selectbox("Model ID", model_options, index=0)
    
    if st.checkbox("è‡ªå®šä¹‰æ¨¡å‹ID"):
        model_id = st.text_input("è¾“å…¥ID", value=selected_model)
    else:
        model_id = selected_model

    st.divider()
    st.markdown("### ğŸ¬ V12 è§†è§‰åˆ‡åˆ†é€»è¾‘")
    st.info("""
    1. **æƒ…ç»ªé‡éŸ³**ï¼šå¦‚â€œæ—¥å¤ä¸€æ—¥â€ã€â€œæ¨ä¸å¾—â€ç­‰æƒ…ç»ªè¯å•ç‹¬æˆé•œã€‚
    2. **åŠ¨ä½œæ‹†è§£**ï¼šä¸€ä¸ªåŠ¨ä½œï¼ˆæ¨å€’ï¼‰+ ä¸€ä¸ªååº”ï¼ˆçœ‹ç€ï¼‰= ä¸¤ä¸ªåˆ†é•œã€‚
    3. **é›¶æŸè€—**ï¼šå¿½ç•¥æ ‡ç‚¹å·®å¼‚ï¼Œä¸¥æŸ¥æ–‡å­—ä¸¢å¤±ã€‚
    """)

# --- æ ¸å¿ƒé€»è¾‘å‡½æ•° ---

def clean_text_for_ai(text):
    """é¢„å¤„ç†ï¼šå»æ ¼å¼ï¼Œå˜çº¯æ–‡æœ¬"""
    return text.replace("\n", "").replace("\r", "").strip()

def normalize_text_for_comparison(text):
    """
    æ¸…æ´—æ–‡æœ¬ä»¥ä¾¿è¿›è¡Œã€å†…å®¹çº§ã€‘æ¯”å¯¹ã€‚
    å»é™¤æ‰€æœ‰æ ‡ç‚¹ç¬¦å·ã€ç©ºæ ¼ã€æ¢è¡Œã€æ•°å­—åºå·ã€‚
    åªä¿ç•™çº¯æ±‰å­—/è‹±æ–‡å•è¯ã€‚
    """
    # å»é™¤å¸¸è§çš„ä¸­æ–‡æ ‡ç‚¹å’Œè‹±æ–‡æ ‡ç‚¹
    punctuation = r"""!"#$%&'()*+,-./:;<=>?@[\]^_`{|}~â€œâ€ï¼Ÿï¼Œï¼ã€ã€‘ï¼ˆï¼‰ã€ã€‚ï¼šï¼›â€™â€˜â€¦â€¦"""
    translator = str.maketrans('', '', punctuation)
    
    # 1. å»é™¤åºå· (1. æˆ– 100.)
    text = re.sub(r'\d+[.ã€]', '', text)
    # 2. å»é™¤æ¢è¡Œå’Œç©ºæ ¼
    text = re.sub(r'\s+', '', text)
    # 3. å»é™¤æ ‡ç‚¹
    text = text.translate(translator)
    return text

def smart_split_text(text, chunk_size=1000):
    """
    æ›´æ™ºèƒ½çš„åˆ†å—ï¼šæŒ‰å¥å·åˆ‡åˆ†ï¼Œæ¯å—çº¦1000å­—ã€‚
    """
    sentences = re.split(r'([ã€‚ï¼ï¼Ÿ])', text)
    chunks = []
    current = ""
    
    # é‡æ–°æ‹¼æ¥
    temp = []
    for i in range(0, len(sentences)-1, 2):
        temp.append(sentences[i] + sentences[i+1])
    if len(sentences) % 2 == 1:
        temp.append(sentences[-1])
        
    for s in temp:
        if len(current) + len(s) > chunk_size:
            chunks.append(current)
            current = s
        else:
            current += s
    if current:
        chunks.append(current)
    return chunks

def parse_df(full_text):
    """ç”Ÿæˆå³ä¾§åˆ†æè¡¨æ ¼æ•°æ®"""
    lines = full_text.split('\n')
    data = []
    for i, line in enumerate(lines):
        if not line.strip(): continue
        # æ¸…æ´—åºå·ï¼Œè·å–çº¯å†…å®¹
        clean_content = re.sub(r'^\d+[.ã€]\s*', '', line)
        length = len(clean_content)
        # çŠ¶æ€åˆ¤æ–­
        if length > 35: status = "âš ï¸ æ‹¥æŒ¤"
        elif length < 5: status = "âš¡ å¿«åˆ‡"
        else: status = "âœ… å®Œç¾"
        
        data.append({
            "åºå·": i+1,
            "åˆ†é•œå†…å®¹": clean_content,
            "å­—æ•°": length,
            "è§†è§‰èŠ‚å¥": status
        })
    return pd.DataFrame(data)

# --- ä¸»ç¨‹åº ---
st.title("ğŸ¬ å¯¼æ¼”å¼•æ“ V12 (æ— æŸè¿˜åŸç‰ˆ)")

# 1. ä¸Šä¼ 
uploaded_file = st.file_uploader("ğŸ“‚ ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ å‰§æœ¬ TXT", type=['txt'])

if uploaded_file:
    raw = uploaded_file.read().decode("utf-8")
    flat_input = clean_text_for_ai(raw)
    input_len_display = len(flat_input)
    
    # çº¯å‡€ç‰ˆé•¿åº¦ï¼ˆç”¨äºæ¯”å¯¹ï¼Œä¸å«æ ‡ç‚¹ï¼‰
    input_pure_len = len(normalize_text_for_comparison(flat_input))
    
    chunks = smart_split_text(flat_input)
    total_chunks = len(chunks)

    # çŠ¶æ€æ 
    col1, col2, col3 = st.columns(3)
    col1.metric("åŸæ–‡æ€»å­—æ•°", f"{input_len_display}")
    col2.metric("å‰§æƒ…åˆ‡ç‰‡æ•°", f"{total_chunks} å—")
    
    # 2. ç”Ÿæˆ
    st.markdown("---")
    if st.button("ğŸš€ å¯åŠ¨ V12 å¯¼æ¼”å¼•æ“", type="primary"):
        if not api_key:
            st.error("è¯·å…ˆé…ç½® API Key")
        else:
            client = OpenAI(api_key=api_key, base_url=base_url)
            
            full_results = []
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            try:
                # Prompt å¼ºåŒ–ï¼šåŠ å…¥äº†ä½ å–œæ¬¢çš„â€œæƒ…ç»ªåˆ‡åˆ†â€ç¤ºä¾‹
                system_prompt = """
                ä½ æ˜¯ä¸€ä¸ªç”µå½±åˆ†é•œå¯¼æ¼”ã€‚è¯·å°†æ–‡æœ¬æ‹†è§£ä¸ºåˆ†é•œè„šæœ¬ã€‚
                
                ã€æ ¸å¿ƒæŒ‡ä»¤ã€‘ï¼š
                1. **å¿…é¡»æ— æŸ**ï¼šä¸¥ç¦åˆ å‡åŸæ–‡ä»»ä½•æ–‡å­—ã€‚
                2. **æ ¼å¼**ï¼šä¸€è¡Œä¸€ä¸ªåˆ†é•œï¼Œä¸è¦åŠ åºå·ï¼ˆç³»ç»Ÿä¼šåŠ ï¼‰ã€‚
                3. **åˆ‡åˆ†é€»è¾‘ï¼ˆæ¨¡ä»¿ä»¥ä¸‹é£æ ¼ï¼‰**ï¼š
                   - "ç¬‘ç€è¯´ç”»æŠ€å†å¥½å“ªæ¯”å¾—ä¸Šäº²èº«ä½“ä¼š" -> æ‹†åˆ†ä¸ºï¼š
                     ç¬‘ç€è¯´ç”»æŠ€å†å¥½
                     å“ªæ¯”å¾—ä¸Šäº²èº«ä½“ä¼š
                   - "ç”¨åœ¨æˆ‘èº«ä¸Šæ—¥å¤ä¸€æ—¥" -> æ‹†åˆ†ä¸ºï¼š
                     â€”â€”ç”¨åœ¨æˆ‘èº«ä¸Š
                     æ—¥å¤ä¸€æ—¥
                4. **ç¡¬æ€§é™åˆ¶**ï¼šå•è¡Œç»å¯¹ä¸å¯è¶…è¿‡35å­—ï¼Œé•¿å¥å¿…é¡»åœ¨è¯­ä¹‰åœé¡¿å¤„åˆ‡å¼€ã€‚
                """

                for i, chunk in enumerate(chunks):
                    status_text.markdown(f"**ğŸ¬ æ­£åœ¨å¤„ç†ç¬¬ {i+1}/{total_chunks} å¹•...**")
                    
                    response = client.chat.completions.create(
                        model=model_id,
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": f"å¤„ç†è¿™æ®µå‰§æƒ…ï¼š\n{chunk}"}
                        ],
                        temperature=0.1 # æä½æ¸©åº¦ä¿è¯ä¸ä¹±æ”¹å­—
                    )
                    
                    res_text = response.choices[0].message.content
                    full_results.append(res_text)
                    progress_bar.progress((i + 1) / total_chunks)

                # åˆæˆ
                combined = "\n".join(full_results)
                # æ¸…æ´—ç©ºè¡Œ
                final_lines = [line.strip() for line in combined.split('\n') if line.strip()]
                
                # é‡å»ºåºå·æ–‡æœ¬
                final_output_text = ""
                raw_output_content = ""
                for idx, line in enumerate(final_lines):
                    clean = re.sub(r'^\d+[.ã€]\s*', '', line)
                    final_output_text += f"{idx+1}. {clean}\n"
                    raw_output_content += clean

                # --- ç»“æœåˆ†æåŒº ---
                st.success("ğŸ‰ åˆ†é•œç”Ÿæˆå®Œæ¯•ï¼")
                
                # å…³é”®ï¼šè®¡ç®—çº¯æ±‰å­—åå·®ï¼ˆå¿½ç•¥æ ‡ç‚¹ï¼‰
                output_pure_len = len(normalize_text_for_comparison(raw_output_content))
                diff = output_pure_len - input_pure_len
                
                # ç»Ÿè®¡é¢æ¿
                m1, m2, m3, m4 = st.columns(4)
                m1.metric("ç”Ÿæˆåˆ†é•œç»„æ•°", f"{len(final_lines)} ç»„")
                m2.metric("åŸæ–‡çº¯å‡€å­—æ•°(æ— æ ‡ç‚¹)", f"{input_pure_len}")
                m3.metric("åˆ†é•œçº¯å‡€å­—æ•°(æ— æ ‡ç‚¹)", f"{output_pure_len}")
                
                # æ™ºèƒ½åå·®æ˜¾ç¤º
                if diff == 0:
                    m4.metric("å†…å®¹å®Œæ•´åº¦", "å®Œç¾æ— æŸ âœ…", delta="0", delta_color="normal")
                else:
                    m4.metric("å†…å®¹åå·®", f"{diff} å­—", delta="å¯èƒ½æ¼å­—" if diff < 0 else "å¯èƒ½é‡å¤", delta_color="inverse")
                    if abs(diff) > 10:
                        st.error(f"âš ï¸ è­¦å‘Šï¼šæ£€æµ‹åˆ° {abs(diff)} ä¸ªæ±‰å­—çš„å®è´¨æ€§å·®å¼‚ï¼Œè¯·æ£€æŸ¥å³ä¾§è¡¨æ ¼ã€‚")

                # åŒæ å±•ç¤º
                c_left, c_right = st.columns([1.5, 1])
                
                with c_left:
                    st.subheader("ğŸ“ åˆ†é•œè„šæœ¬ç¼–è¾‘å™¨")
                    st.text_area("å¯ç›´æ¥å¤åˆ¶", value=final_output_text, height=600)
                    st.download_button("ğŸ“¥ ä¸‹è½½è„šæœ¬", data=final_output_text, file_name="æ— æŸåˆ†é•œ.txt")

                with c_right:
                    st.subheader("ğŸ“Š è§†è§‰èŠ‚å¥è¡¨")
                    df = parse_df(final_output_text)
                    st.dataframe(
                        df,
                        column_config={
                            "åºå·": st.column_config.NumberColumn(width="small"),
                            "å­—æ•°": st.column_config.ProgressColumn(
                                "æ—¶é•¿ä¼°ç®—", 
                                format="%d å­—", 
                                min_value=0, 
                                max_value=40
                            ),
                            "è§†è§‰èŠ‚å¥": st.column_config.TextColumn(width="small")
                        },
                        hide_index=True,
                        height=600
                    )

            except Exception as e:
                st.error(f"âŒ è¿è¡Œä¸­æ–­ï¼š{e}")
