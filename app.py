import streamlit as st
import json
from openai import OpenAI
import io
import os
import subprocess
import tempfile
import re
import requests

st.set_page_config(page_title="AIå°è¯´é…éŸ³å·¥å…·", layout="wide")
st.title("AIå°è¯´é…éŸ³ç¨‹åºï¼ˆè‡ªéƒ¨ç½²äº‘ç«¯IndexTTS2ï¼‰")

# ==================== ä¾§è¾¹æ é…ç½® ====================
st.sidebar.header("API é…ç½®")

yunwu_api_key = st.sidebar.text_input("Yunwu.ai API Key (ç”¨äºè§’è‰²è¯†åˆ«)", type="password")
if not yunwu_api_key:
    st.sidebar.warning("è¯·å¡«å†™ Yunwu.ai Key ä»¥å¯ç”¨è§’è‰²è¯†åˆ«")

tts_base_url = st.sidebar.text_input(
    "IndexTTS2 API Base URL",
    value="https://ffo5lqa2aapiq89w-7860.containerx-gpu.com/",
    help="å®Œæ•´åœ°å€ï¼ŒåŒ…å« https å’Œæœ«å°¾ /"
)
tts_api_key = st.sidebar.text_input("IndexTTS2 API Key (è‹¥æ— éœ€è®¤è¯å¯ç•™ç©º)", type="password", value="")
tts_model = st.sidebar.text_input("IndexTTS2 æ¨¡å‹åç§°", value="indextts2", help="å¸¸è§ï¼šindextts2ã€IndexTTS-2ã€tts-1")

# ==================== TTS Voice å‚æ•°ï¼ˆå¯é€‰ï¼‰ ====================
st.sidebar.header("TTS Voice å‚æ•°ï¼ˆå¯é€‰ï¼‰")
st.sidebar.info("å¦‚æœç•™ç©ºï¼Œå°†è‡ªåŠ¨å°è¯•æ— voiceè°ƒç”¨ã€‚å…ˆè¯•æœ¬åœ°è½¯ä»¶æˆåŠŸçš„voiceå€¼")

common_voices = ["default", "male", "female", "zh_male", "zh_female", "Xiaoxiao", "Yunxi", "male_qn", "female_qn"]

selected_voice_preset = st.sidebar.selectbox("å¿«é€Ÿå°è¯•å¸¸è§voice", ["ï¼ˆç•™ç©ºï¼‰"] + common_voices, index=0)
custom_voice = st.sidebar.text_input(
    "voice å€¼ï¼ˆå¡«å†™åä¼˜å…ˆä½¿ç”¨ï¼Œç•™ç©ºåˆ™è‡ªåŠ¨é™çº§ï¼‰",
    value="" if selected_voice_preset == "ï¼ˆç•™ç©ºï¼‰" else selected_voice_preset,
    placeholder="ä¾‹å¦‚ï¼šmale / Xiaoxiao / æ‚¨æœ¬åœ°æˆåŠŸçš„voice"
)

final_voice = custom_voice.strip() if custom_voice.strip() else None

if final_voice:
    st.sidebar.success(f"å°†ä¼˜å…ˆä½¿ç”¨ voiceï¼š**{final_voice}**")
else:
    st.sidebar.info("æœªå¡«å†™ voiceï¼Œå°†è‡ªåŠ¨å°è¯•æ—  voice è°ƒç”¨")

if not tts_base_url:
    st.warning("è¯·å¡«å†™ IndexTTS2 API Base URL")
    st.stop()

# LLM å®¢æˆ·ç«¯
if yunwu_api_key:
    llm_client = OpenAI(base_url="https://yunwu.ai/v1", api_key=yunwu_api_key)
else:
    llm_client = None

# TTS å®¢æˆ·ç«¯
tts_client = OpenAI(base_url=tts_base_url.rstrip("/"), api_key=tts_api_key or "none")

# ==================== API è¿é€šæ€§æµ‹è¯•ï¼ˆå…³é”®è°ƒè¯•å·¥å…·ï¼‰ ====================
st.sidebar.header("è°ƒè¯•å·¥å…·")
if st.sidebar.button("ğŸ”— æµ‹è¯• IndexTTS2 API è¿é€šæ€§"):
    with st.spinner("æ­£åœ¨æµ‹è¯• API æ˜¯å¦å¯è®¿é—®..."):
        test_url = tts_base_url.rstrip("/") + "/v1/models"
        headers = {}
        if tts_api_key:
            headers["Authorization"] = f"Bearer {tts_api_key}"
        try:
            resp = requests.get(test_url, headers=headers, timeout=10)
            if resp.status_code == 200:
                models = resp.json()
                st.sidebar.success(f"è¿æ¥æˆåŠŸï¼å¯ç”¨æ¨¡å‹æ•°ï¼š{len(models.get('data', []))}")
                st.sidebar.code(json.dumps(models, indent=2, ensure_ascii=False))
            else:
                st.sidebar.error(f"è¿æ¥å¤±è´¥ï¼šHTTP {resp.status_code}\n{resp.text}")
        except Exception as e:
            st.sidebar.error(f"è¿æ¥è¶…æ—¶æˆ–é”™è¯¯ï¼š{e}")

# ==================== è§’è‰²è¯†åˆ«æ¨¡å‹é€‰æ‹© ====================
st.sidebar.header("è§’è‰²è¯†åˆ«æ¨¡å‹è®¾ç½®")
common_models = ["gpt-4o", "claude-3-5-sonnet-20240620", "gemini-1.5-pro", "deepseek-chat"]
selected_preset = st.sidebar.selectbox("å¿«é€Ÿé€‰æ‹©", ["ï¼ˆä¸é€‰ï¼‰"] + common_models, index=0)
custom_model = st.sidebar.text_input("æ¨¡å‹åç§°ï¼ˆè‡ªä¸»å¡«å†™ï¼Œä»¥æ­¤ä¸ºå‡†ï¼‰", value=selected_preset if selected_preset != "ï¼ˆä¸é€‰ï¼‰" else "")
final_model = custom_model.strip() or selected_preset
if not final_model:
    st.sidebar.error("å¿…é¡»å¡«å†™æ¨¡å‹åç§°")
    st.stop()
st.sidebar.success(f"ä½¿ç”¨æ¨¡å‹ï¼š**{final_model}**")

# ==================== æ–‡ä»¶ä¸Šä¼ ä¸è§’è‰²è¯†åˆ« ====================
uploaded_file = st.file_uploader("ä¸Šä¼ å°è¯´TXTæ–‡ä»¶", type=["txt"])
if uploaded_file:
    text = uploaded_file.read().decode("utf-8")
    st.text_area("å…¨æ–‡é¢„è§ˆ", text, height=300)

    if st.button("ğŸ” è‡ªåŠ¨è¯†åˆ«è§’è‰²ä¸åˆ†æ®µ", type="primary"):
        if not llm_client:
            st.error("è¯·å¡«å†™ Yunwu.ai Key")
            st.stop()

        # ï¼ˆè§’è‰²è¯†åˆ«éƒ¨åˆ†ä¿æŒä¸å˜ï¼Œå·²è¯æ˜å¯æ­£å¸¸å·¥ä½œï¼‰
        # ... [åŒä¹‹å‰ä»£ç çš„è¯†åˆ«é€»è¾‘ï¼Œçœç•¥ä»¥èŠ‚çœç¯‡å¹…ï¼Œæ‚¨ç›´æ¥å¤åˆ¶ä¹‹å‰ç‰ˆæœ¬çš„è¯†åˆ«éƒ¨åˆ†å³å¯]

# ==================== ç”ŸæˆéŸ³é¢‘ï¼ˆå¢å¼ºå®¹é”™ï¼‰ ====================
if 'segments' in st.session_state:
    segments = st.session_state.segments

    st.header("ğŸ¤ é…éŸ³è®¾ç½®")
    st.info("å½“å‰ç»Ÿä¸€å£°çº¿ï¼Œåç»­å¯æ‰©å±•å¤šè§’è‰²å…‹éš†")

    if st.button("ğŸ”Š ç”Ÿæˆå®Œæ•´é…éŸ³", type="primary"):
        with st.spinner("æ­£åœ¨ç”Ÿæˆé…éŸ³..."):
            audio_bytes_list = []
            progress_bar = st.progress(0)
            for i, seg in enumerate(segments):
                text_seg = seg["text"].strip()
                if not text_seg:
                    continue

                success = False
                # ç­–ç•¥1ï¼šå¦‚æœå¡«å†™äº†voiceï¼Œä¼˜å…ˆå°è¯•å¸¦voice
                if final_voice:
                    try:
                        response = tts_client.audio.speech.create(
                            model=tts_model,
                            voice=final_voice,
                            input=text_seg,
                            response_format="mp3"
                        )
                        audio_bytes_list.append(response.content)
                        success = True
                    except Exception as e:
                        st.warning(f"ç¬¬ {i+1} æ®µå¸¦ voice è°ƒç”¨å¤±è´¥ï¼š{e}")

                # ç­–ç•¥2ï¼šé™çº§ä¸ºæ— voiceè°ƒç”¨
                if not success:
                    try:
                        response = tts_client.audio.speech.create(
                            model=tts_model,
                            input=text_seg,
                            response_format="mp3"
                        )
                        audio_bytes_list.append(response.content)
                        success = True
                        st.info(f"ç¬¬ {i+1} æ®µæ—  voice è°ƒç”¨æˆåŠŸ")
                    except Exception as e:
                        st.error(f"ç¬¬ {i+1} æ®µå…¨éƒ¨å¤±è´¥ï¼š{e}")

                progress_bar.progress((i + 1) / len(segments))

            if not audio_bytes_list:
                st.error("æ‰€æœ‰æ®µè½éƒ½å¤±è´¥ï¼è¯·å…ˆç‚¹å‡»å·¦ä¾§â€œæµ‹è¯• API è¿é€šæ€§â€æ£€æŸ¥è¿æ¥")
                st.stop()

            # ffmpeg åˆå¹¶ï¼ˆåŒä¹‹å‰ï¼‰
            # ... [åˆå¹¶é€»è¾‘åŒä¹‹å‰]

            # è¾“å‡ºéŸ³é¢‘å’Œä¸‹è½½
            # ... [åŒä¹‹å‰]

st.info("""
é‡è¦è°ƒè¯•æ­¥éª¤ï¼š
1. å…ˆç‚¹å‡»å·¦ä¾§ â€œæµ‹è¯• IndexTTS2 API è¿é€šæ€§â€ æŒ‰é’®ï¼
   - å¦‚æœæ˜¾ç¤ºâ€œè¿æ¥å¤±è´¥â€æˆ–è¶…æ—¶ â†’ è¯´æ˜ Streamlit Cloud æ— æ³•è®¿é—®æ‚¨çš„å®ä¾‹ï¼ˆç½‘ç»œ/é˜²ç«å¢™é—®é¢˜ï¼‰ã€‚
   - è§£å†³åŠæ³•ï¼šâ‘  ç¡®ä¿å®ä¾‹å…¬ç½‘å¯è®¿é—® â‘¡ æˆ–åˆ‡æ¢åˆ° SiliconFlow å…¬å…± APIï¼ˆæˆ‘å¯ä»¥å¸®æ‚¨æ”¹ä»£ç ï¼‰ã€‚
2. å¦‚æœè¿æ¥æˆåŠŸä½†é…éŸ³ä»å¤±è´¥ â†’ æŠŠå…·ä½“é”™è¯¯æˆªå›¾å‘æˆ‘ã€‚
""")
