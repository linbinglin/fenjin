import streamlit as st
from openai import OpenAI
import io
import math

st.set_page_config(page_title="ç”µå½±è§£è¯´åˆ†é•œå¯¼æ¼”ç³»ç»Ÿ", layout="wide")

# --- åˆå§‹åŒ– Session State ---
if 'all_shots' not in st.session_state:
    st.session_state.all_shots = []  # å­˜å‚¨çº¯åˆ†é•œæ–‡æ¡ˆåˆ—è¡¨
if 'current_batch_idx' not in st.session_state:
    st.session_state.current_batch_idx = 0 # å½“å‰å¤„ç†åˆ°ç¬¬å‡ ç»„
if 'descriptions' not in st.session_state:
    st.session_state.descriptions = [] # å­˜å‚¨ç”Ÿæˆçš„è¯¦ç»†æè¿°

# --- ä¾§è¾¹æ ï¼šAPIé…ç½® ---
st.sidebar.title("âš™ï¸ é…ç½®ä¸­å¿ƒ")
api_key = st.sidebar.text_input("è¾“å…¥ API Key", type="password")
base_url = st.sidebar.text_input("ä¸­è½¬æ¥å£åœ°å€", value="https://blog.tuiwen.xyz/v1")
model_id = st.sidebar.text_input("Model ID", value="gpt-4o")

# --- ä¸»ç•Œé¢ ---
st.title("ğŸ¬ ç”µå½±è§£è¯´å…¨æµç¨‹åˆ†é•œå¯¼æ¼”ç³»ç»Ÿ")

# è¾“å…¥åŒº
col_a, col_b = st.columns(2)
with col_a:
    uploaded_file = st.file_uploader("1. ä¸Šä¼ æ–‡æ¡ˆ (TXT)", type=['txt'])
with col_b:
    char_desc = st.text_area("2. æ ¸å¿ƒè§’è‰²è®¾å®š (å¿…å¡«)", 
                            placeholder="è§’è‰²åï¼šå¤–è²Œç»†èŠ‚ã€æœè£…æ ·å¼...\nä¾‹å¦‚ï¼šæ—å‡¡ï¼š25å²ï¼Œé»‘è‰²å†²é”‹è¡£ï¼Œçœ¼ç¥å†·é…·ã€‚", 
                            height=100)

# --- ç¬¬ä¸€æ­¥ï¼šåˆ†é•œæ‹†è§£ ---
if uploaded_file and char_desc:
    raw_text = io.StringIO(uploaded_file.getvalue().decode("utf-8")).read()
    
    if st.button("Step 1: ç”Ÿæˆ/åˆ·æ–°åˆ†é•œé¢„è§ˆ"):
        try:
            client = OpenAI(api_key=api_key, base_url=base_url)
            # å¼ºåˆ¶åˆ†é•œPrompt
            seg_prompt = f"""ä½ æ˜¯ä¸€ä¸ªç”µå½±å‰ªè¾‘å¸ˆã€‚è¯·å¿½ç•¥åŸæ–‡æ®µè½ï¼Œå°†ä»¥ä¸‹æ–‡æœ¬é‡æ–°æ‹†è§£ä¸ºåˆ†é•œã€‚
è§„åˆ™ï¼š
1. æ¯ç»„åˆ†é•œæ–‡æ¡ˆä¸¥æ ¼ç¦æ­¢è¶…è¿‡40ä¸ªå­—ç¬¦ï¼ˆçº¦5ç§’éŸ³é¢‘ï¼‰ã€‚
2. åªè¦æœ‰ï¼šåœºæ™¯åˆ‡æ¢ã€è§’è‰²å¯¹è¯åˆ‡æ¢ã€æ ¸å¿ƒåŠ¨ä½œæ”¹å˜ï¼Œå¿…é¡»ç«‹å³æ‹†åˆ†ä¸ºä¸‹ä¸€ç»„ã€‚
3. ä¸¥ç¦æ”¹åŠ¨ã€é—æ¼åŸæ–‡ä»»ä½•æ–‡å­—ã€‚
4. è¾“å‡ºæ ¼å¼ï¼šä»…è¾“å‡ºåºå·å’Œæ–‡æ¡ˆï¼Œæ¯è¡Œä¸€ä¸ªã€‚ä¾‹å¦‚ï¼š1.æ–‡æ¡ˆå†…å®¹
æ–‡æœ¬å†…å®¹ï¼š\n{raw_text}"""
            
            with st.spinner("æ­£åœ¨è¿›è¡Œç‰©ç†æ‹†åˆ†åˆ†é•œ..."):
                response = client.chat.completions.create(
                    model=model_id,
                    messages=[{"role": "user", "content": seg_prompt}],
                    temperature=0.3
                )
                res_text = response.choices[0].message.content
                # ç®€å•è§£æç»“æœå­˜å…¥session
                st.session_state.all_shots = [line for line in res_text.split('\n') if line.strip()]
                st.session_state.current_batch_idx = 0
                st.session_state.descriptions = []
        except Exception as e:
            st.error(f"æ‹†è§£å¤±è´¥: {e}")

# --- ç»“æœå±•ç¤ºä¸æ·±åº¦æè¿°ç”Ÿæˆ ---
if st.session_state.all_shots:
    st.divider()
    st.subheader("ğŸ“‹ åˆ†é•œé¢„è§ˆ (å…±è®¡ {} ç»„)".format(len(st.session_state.all_shots)))
    
    # é¢„è§ˆåŒºåŸŸ
    with st.expander("æŸ¥çœ‹æ‰€æœ‰åˆ†é•œæ–‡æ¡ˆ", expanded=True):
        for shot in st.session_state.all_shots:
            st.write(shot)

    st.divider()
    st.subheader("ğŸ¨ æ·±åº¦ç”»é¢æè¿°ç”Ÿæˆ (æ¯æ‰¹20ç»„)")

    # ç¡®å®šå½“å‰æ‰¹æ¬¡
    start_idx = st.session_state.current_batch_idx
    end_idx = min(start_idx + 20, len(st.session_state.all_shots))
    current_batch_list = st.session_state.all_shots[start_idx:end_idx]

    if start_idx < len(st.session_state.all_shots):
        if st.button(f"ç”Ÿæˆç¬¬ {start_idx+1} - {end_idx} ç»„çš„ç”»é¢æè¿°"):
            try:
                client = OpenAI(api_key=api_key, base_url=base_url)
                
                # æ·±åº¦æè¿°Prompt
                desc_prompt = f"""ä½ æ˜¯ä¸€ä¸ªè§†è§‰å¯¼æ¼”ï¼Œè¯·ä¸ºä»¥ä¸‹åˆ†é•œç”ŸæˆMidjourneyå’Œå³æ¢¦AIæç¤ºè¯ã€‚
è§’è‰²è®¾å®šï¼š{char_desc}

è¦æ±‚ï¼š
1. æ¯ä¸€ç»„åˆ†é•œå¿…é¡»åŒ…å«ï¼š[åˆ†é•œæ–‡æ¡ˆ]ã€[ç”»é¢æè¿°]ã€[è§†é¢‘ç”Ÿæˆ]ã€‚
2. [ç”»é¢æè¿°]é’ˆå¯¹Midjourneyï¼šæè¿°åœºæ™¯ã€äººç‰©å¤–è²Œã€ç€è£…ã€å…‰å½±ï¼Œä¸¥ç¦æè¿°åŠ¨ä½œã€‚
3. [è§†é¢‘ç”Ÿæˆ]é’ˆå¯¹å³æ¢¦AIï¼šæè¿°é•œå¤´è¯­è¨€ã€å¾®è¡¨æƒ…ã€æ ¸å¿ƒåŠ¨ä½œã€‚é‡‡ç”¨çŸ­å¥å †ç Œï¼Œå•ç„¦åŸåˆ™ï¼ˆä¸€ä¸ªåˆ†é•œ1ä¸ªåŠ¨ä½œï¼‰ã€‚
4. ç¡®ä¿åœºæ™¯å’Œæœè£…åœ¨å„åˆ†é•œé—´çš„ä¸€è‡´æ€§ã€‚

å¾…å¤„ç†åˆ†é•œï¼š
{chr(10).join(current_batch_list)}"""

                with st.spinner("AIæ­£åœ¨æ„æ€ç”»é¢ç»†èŠ‚..."):
                    response = client.chat.completions.create(
                        model=model_id,
                        messages=[{"role": "user", "content": desc_prompt}],
                        temperature=0.7
                    )
                    batch_res = response.choices[0].message.content
                    st.session_state.descriptions.append(batch_res)
                    st.session_state.current_batch_idx = end_idx
                    st.rerun() # åˆ·æ–°æ˜¾ç¤ºç»“æœ
            except Exception as e:
                st.error(f"æè¿°ç”Ÿæˆå¤±è´¥: {e}")
    else:
        st.success("âœ… æ‰€æœ‰åˆ†é•œæè¿°å·²ç”Ÿæˆå®Œæ¯•ï¼")

    # æ˜¾ç¤ºå·²ç”Ÿæˆçš„æè¿°
    for idx, desc in enumerate(st.session_state.descriptions):
        st.markdown(f"### ğŸ“¦ ç¬¬ {idx+1} æ‰¹æ¬¡ç»“æœ")
        st.text_area(f"æ‰¹æ¬¡ {idx+1} æ–‡æœ¬ (å¯å¤åˆ¶)", desc, height=400)

    if st.session_state.current_batch_idx > 0 and st.session_state.current_batch_idx < len(st.session_state.all_shots):
        if st.button("ç»§ç»­ç”Ÿæˆä¸‹20ç»„æè¿°"):
            st.rerun()
