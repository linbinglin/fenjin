import streamlit as st
from openai import OpenAI
import io
import re
import pandas as pd

st.set_page_config(page_title="AIç”µå½±è§£è¯´åˆ†é•œæ— æŸç³»ç»Ÿ", layout="wide")

# --- åˆå§‹åŒ– Session State ---
if 'original_text' not in st.session_state:
    st.session_state.original_text = ""
if 'editable_storyboard' not in st.session_state:
    st.session_state.editable_storyboard = ""
if 'final_descriptions' not in st.session_state:
    st.session_state.final_descriptions = []
if 'current_batch' not in st.session_state:
    st.session_state.current_batch = 0

# --- ä¾§è¾¹æ  ---
st.sidebar.title("ğŸ› ï¸ å¯¼æ¼”é…ç½®ä¸­å¿ƒ")
api_key = st.sidebar.text_input("API Key", type="password")
base_url = st.sidebar.text_input("ä¸­è½¬åœ°å€", value="https://blog.tuiwen.xyz/v1")
model_id = st.sidebar.text_input("Model ID", value="gpt-4o")

st.title("ğŸ¬ ç”µå½±è§£è¯´æ— æŸåˆ†é•œä¸“å®¶")
st.info("æœ¬ç³»ç»Ÿé‡‡ç”¨ã€æ— æŸåˆ‡å‰²é€»è¾‘ã€‘ï¼Œç¡®ä¿æ–‡æ¡ˆä¸€å­—ä¸å·®ï¼ŒåŒæ—¶é€‚é… 5 ç§’è§†é¢‘èŠ‚å¥ã€‚")

# ================= ç¬¬ä¸€é˜¶æ®µï¼šæ— æŸåˆ†é•œåˆ‡å‰² =================
st.header("Step 1: æ–‡æœ¬åˆ‡å‰²ä¸èŠ‚å¥å¯¹é½")

uploaded_file = st.file_uploader("ä¸Šä¼ æ–‡æ¡ˆ (TXT)", type=['txt'])

if uploaded_file:
    raw_content = io.StringIO(uploaded_file.getvalue().decode("utf-8")).read()
    # é¢„å¤„ç†ï¼šå»æ‰æ‰€æœ‰æ¢è¡Œï¼Œåˆå¹¶ä¸ºçº¯å­—ç¬¦æµ
    clean_raw = re.sub(r'\s+', '', raw_content)
    st.session_state.original_text = clean_raw
    
    if st.button("ğŸ“½ï¸ å¯åŠ¨æ™ºèƒ½æ— æŸåˆ†é•œ"):
        if not api_key:
            st.error("è¯·é…ç½® API Key")
        else:
            try:
                client = OpenAI(api_key=api_key, base_url=base_url)
                # æå…¶ä¸¥å‰çš„â€œæ— æŸâ€æç¤ºè¯
                system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªé¡¶çº§çš„ç”µå½±è§£è¯´åˆ†é•œå¯¼æ¼”ã€‚ä½ çš„ä»»åŠ¡æ˜¯è¿›è¡Œã€æ— æŸåˆ‡å‰²ã€‘ã€‚
                
ã€æ ¸å¿ƒå‡†åˆ™ - è¿è€…é‡ç½šã€‘ï¼š
1. ç»å¯¹ä¸¥ç¦åˆ é™¤ã€æ·»åŠ ã€ä¿®æ”¹åŸæ–‡ä¸­çš„ä»»ä½•ä¸€ä¸ªå­—ã€‚
2. æ–‡æœ¬ç»“æ„å¿…é¡»æŒ‰ç…§åŸæ–‡é¡ºåºã€‚
3. ä½ çš„å·¥ä½œä»…æ˜¯åœ¨åˆé€‚çš„é€»è¾‘ç‚¹æ’å…¥æ¢è¡Œç¬¦ã€‚

ã€åˆ†é•œåˆ‡å‰²é€»è¾‘ã€‘ï¼š
1. **é•¿åº¦ç¡¬æŒ‡æ ‡**ï¼šæ¯ä¸ªåˆ†é•œç†æƒ³é•¿åº¦ä¸º30-38ä¸ªå­—ç¬¦ã€‚ç»å¯¹ä¸èƒ½è¶…è¿‡40ä¸ªå­—ç¬¦ï¼ˆè¶…è¿‡5ç§’ï¼‰ã€‚
2. **é€»è¾‘åˆ‡åˆ†ç‚¹**ï¼š
   - è§’è‰²æ›´æ¢è¯´è¯ã€‚
   - åœºæ™¯å‘ç”Ÿåœ°ç‚¹æ”¹å˜ã€‚
   - å‡ºç°é‡å¤§çš„ã€ç‹¬ç«‹çš„åŠ¨ä½œåŠ¨ä½œï¼ˆå¦‚ï¼šä»â€œåç€â€å˜æˆâ€œç«™èµ·â€ï¼‰ã€‚
3. **å¹³è¡¡æ„Ÿ**ï¼šå¦‚æœä¸€æ®µè¯åªæœ‰10ä¸ªå­—ï¼Œä½†ä¸‹ä¸€æ®µè¯åˆå¹¶è¿‡æ¥åæ€»é•¿ä»å°äº38å­—ï¼Œä¸”åŠ¨ä½œè¿è´¯ï¼Œè¯·åŠ¡å¿…åˆå¹¶ã€‚ä¸è¦åˆ†å¾—å¤ªç¢å¯¼è‡´ç”»é¢é—ªçƒã€‚

è¯·å¤„ç†ä»¥ä¸‹æ–‡æœ¬ï¼š
{clean_raw}"""

                with st.spinner("AIæ­£åœ¨è¿›è¡Œç²¾å¯†åˆ‡å‰²..."):
                    response = client.chat.completions.create(
                        model=model_id,
                        messages=[{"role": "system", "content": system_prompt}],
                        temperature=0 # å¼ºåˆ¶è¦æ±‚ç¡®å®šæ€§ï¼Œä¸å‡†è‡ªç”±å‘æŒ¥
                    )
                    st.session_state.editable_storyboard = response.choices[0].message.content
                    st.session_state.final_descriptions = []
                    st.session_state.current_batch = 0
            except Exception as e:
                st.error(f"å¤„ç†å¤±è´¥: {e}")

# é¢„è§ˆä¸äººå·¥å¾®è°ƒåŒº
if st.session_state.editable_storyboard:
    col_edit, col_stat = st.columns([3, 2])
    
    with col_edit:
        st.subheader("ğŸ“ åˆ†é•œç¼–è¾‘ï¼ˆå®æ—¶åŒæ­¥ï¼‰")
        edited_text = st.text_area("åˆ†é•œæ–‡æ¡ˆ", value=st.session_state.editable_storyboard, height=450, help="æ¯è¡Œä»£è¡¨ä¸€ä¸ªåˆ†é•œã€‚ä½ å¯ä»¥æ‰‹åŠ¨åˆå¹¶æˆ–æ‹†åˆ†ã€‚")
        st.session_state.editable_storyboard = edited_text

    with col_stat:
        st.subheader("ğŸ“Š è´¨é‡ç›‘æ§çœ‹æ¿")
        # æ•°æ®è§£æ
        lines = [l.strip() for l in edited_text.split('\n') if l.strip()]
        processed_lines = []
        full_recombined = ""
        
        for i, line in enumerate(lines):
            # å»æ‰åºå·
            content = re.sub(r'^\d+[\.ã€\s]+', '', line)
            full_recombined += content
            char_len = len(content)
            
            if char_len > 40: status = "ğŸ”´ å¤ªæŒ¤ (è¶…5s)"
            elif char_len < 20: status = "ğŸŸ¡ å¤ªç¢ (åŠ¨ä½œæ„Ÿå¼±)"
            else: status = "ğŸŸ¢ å®Œç¾"
            
            processed_lines.append({"åˆ†é•œ": i+1, "æ–‡æ¡ˆé¢„è§ˆ": content[:15]+"...", "å­—æ•°": char_len, "å»ºè®®": status})
        
        # æ ¸å¿ƒï¼šå­—æ•°æ ¡éªŒ
        orig_len = len(st.session_state.original_text)
        new_len = len(full_recombined)
        
        if orig_len == new_len:
            st.success(f"âœ… æ— æŸæ£€æµ‹é€šè¿‡ï¼šåŸæ–‡ {orig_len} å­— -> åˆ†é•œ {new_len} å­—")
        else:
            diff = orig_len - new_len
            st.error(f"âš ï¸ æ£€æµ‹åˆ°ä¸¢å­—ï¼åŸæ–‡ {orig_len} å­— -> åˆ†é•œ {new_len} å­— (å°‘äº† {diff} å­—)")
            st.warning("æç¤ºï¼šè¯·æ£€æŸ¥æ˜¯å¦æœ‰åˆ†é•œè¢«æ„å¤–åˆ é™¤æˆ–åˆå¹¶ã€‚")
        
        st.dataframe(pd.DataFrame(processed_lines), use_container_width=True)

    st.divider()

    # ================= ç¬¬äºŒé˜¶æ®µï¼šåˆ†æ­¥æè¿°ç”Ÿæˆ =================
    st.header("Step 2: ç”»é¢ä¸è§†é¢‘é€»è¾‘ç”Ÿæˆ")
    
    char_desc = st.text_area("è¾“å…¥è§’è‰²è§†è§‰è®¾å®š (Midjourneyç”Ÿå›¾å…³é”®)", placeholder="æè¿°è§’è‰²é•¿ç›¸ã€ç©¿ç€ã€‚ä¾‹å¦‚ï¼šæ—å‡¡ï¼šå‰‘çœ‰æ˜Ÿç›®ï¼Œé»‘è‰²æ–—ç¯·ã€‚")
    
    if char_desc:
        final_list = [re.sub(r'^\d+[\.ã€\s]+', '', l.strip()) for l in edited_text.split('\n') if l.strip()]
        total = len(final_list)
        idx = st.session_state.current_batch
        size = 20
        end = min(idx + size, total)

        if idx < total:
            if st.button(f"ğŸ¨ ç”Ÿæˆç¬¬ {idx+1} - {end} ç»„å¯¼æ¼”æç¤ºè¯"):
                try:
                    client = OpenAI(api_key=api_key, base_url=base_url)
                    batch_data = "\n".join([f"{i+idx+1}. {text}" for i, text in enumerate(final_list[idx:end])])
                    
                    prompt = f"""ä½ ç°åœ¨æ˜¯è§†è§‰å¯¼æ¼”ã€‚åŸºäºä»¥ä¸‹åˆ†é•œæ–‡æ¡ˆå’Œè§’è‰²è®¾å®šï¼Œç”ŸæˆMJç”Ÿå›¾è¯å’Œå³æ¢¦AIåŠ¨ä½œè¯ã€‚

ã€è§’è‰²è®¾å®šã€‘ï¼š{char_desc}

ã€è¦æ±‚ã€‘ï¼š
1. **ç”»é¢æè¿° (MJ)**ï¼šä»…æè¿°é™æ€ã€‚åŒ…å«åœºæ™¯ã€äººç‰©ç‰¹å†™ç»†èŠ‚ã€æè´¨ã€å…‰å½±ã€‚ä¸¥ç¦åŠ¨ä½œè¯ã€‚
2. **è§†é¢‘ç”Ÿæˆ (å³æ¢¦AI)**ï¼šæè¿°5ç§’å†…çš„åŠ¨ä½œè½¨è¿¹ã€‚é’ˆå¯¹å½“å‰åˆ†é•œæ–‡æ¡ˆï¼Œæè¿°äººç‰©ç¥æ€å˜åŒ–ã€è‚¢ä½“ä½ç§»ã€‚ä½¿ç”¨â€œçŸ­å¥å †ç Œâ€ã€‚
3. **å•ç„¦åŸåˆ™**ï¼šä¸€ä¸ªåˆ†é•œä¸“æ³¨ä¸€ä¸ªæ ¸å¿ƒè§†è§‰ç„¦ç‚¹ã€‚

ã€å¾…å¤„ç†åˆ†é•œã€‘ï¼š
{batch_data}"""

                    with st.spinner("å¯¼æ¼”æ­£åœ¨ç²¾ä¿®æè¿°..."):
                        response = client.chat.completions.create(
                            model=model_id,
                            messages=[{"role": "user", "content": prompt}]
                        )
                        st.session_state.final_results.append(response.choices[0].message.content)
                        st.session_state.current_batch = end
                        st.rerun()
                except Exception as e:
                    st.error(f"æè¿°ç”Ÿæˆå¤±è´¥: {e}")
        else:
            st.success("ğŸ æ‰€æœ‰æè¿°ç”Ÿæˆå®Œæ¯•ï¼")

        for r_idx, r_text in enumerate(st.session_state.final_results):
            with st.expander(f"ğŸ“¦ æ‰¹æ¬¡ {r_idx+1} ç”Ÿæˆç»“æœ"):
                st.text_area(f"Result {r_idx+1}", r_text, height=400)
