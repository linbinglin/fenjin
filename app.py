import streamlit as st
from openai import OpenAI
import re
import pandas as pd

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="å¯¼æ¼”å¼•æ“ V16 (åŠ¨ä½œå›å½’ç‰ˆ)",
    page_icon="ğŸ¬",
    layout="wide"
)

# --- CSS ---
st.markdown("""
<style>
    .metric-container { background-color: #f8f9fa; padding: 10px; border-radius: 5px; }
    .stDataFrame { width: 100%; }
</style>
""", unsafe_allow_html=True)

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("âš™ï¸ å¯¼æ¼”å¼•æ“ V16")
    st.caption("å›å½’åˆå¿ƒï¼šè§’è‰²Â·åœºæ™¯Â·åŠ¨ä½œ")
    
    api_key = st.text_input("API Key", type="password", placeholder="sk-...")
    base_url = st.text_input("æ¥å£åœ°å€", value="https://blog.tuiwen.xyz/v1")
    
    model_options = ["gpt-4o", "deepseek-chat", "claude-3-5-sonnet-20240620", "gpt-4-turbo"]
    selected_model = st.selectbox("Model ID", model_options, index=0)
    
    if st.checkbox("è‡ªå®šä¹‰æ¨¡å‹ID"):
        model_id = st.text_input("è¾“å…¥ID", value=selected_model)
    else:
        model_id = selected_model

    st.divider()
    st.markdown("### ğŸ¬ V16 åˆ†é•œåŸåˆ™")
    st.info("""
    **å›å½’æœ€åŸå§‹çš„ 3 å¤§åˆ‡åˆ†é€»è¾‘ï¼š**
    1. ğŸ‘¤ **è§’è‰²åˆ‡æ¢**ï¼šAè¯´å®ŒBè¯´ -> åˆ‡ï¼
    2. ğŸŒ **åœºæ™¯åˆ‡æ¢**ï¼šå®¤å†…è½¬å®¤å¤–/ç™½å¤©è½¬é»‘å¤œ -> åˆ‡ï¼
    3. ğŸƒ **åŠ¨ä½œæ”¹å˜**ï¼šæ¨å€’ -> ç”»ç”» -> ç©¿è¡£ã€‚åŠ¨ä½œå˜äº†å°±å¿…é¡»åˆ‡ï¼Œå“ªæ€•åªæœ‰3ä¸ªå­—ï¼
    """)

# --- æ ¸å¿ƒå·¥å…·å‡½æ•° ---

def clean_text_for_ai(text):
    """é¢„å¤„ç†ï¼šå»æ¢è¡Œï¼Œå˜çº¯æ–‡æœ¬æµ"""
    return text.replace("\n", "").replace("\r", "").strip()

def sanitize_ai_output(text):
    """
    ã€å¼ºåˆ¶æ¸…æ´—ã€‘
    ä¸ç®¡Promptæ€ä¹ˆå¼ºè°ƒï¼Œé˜²æ­¢AIè„‘è¡¥ç”»é¢æè¿°ã€‚
    å¼ºåˆ¶åˆ é™¤æ‰€æœ‰æ‹¬å·å†…å®¹ã€‚
    """
    text = re.sub(r'[\(ï¼ˆã€\[].*?[\)ï¼‰ã€‘\]]', '', text)
    return text

def normalize_text_for_comparison(text):
    """ç”¨äºæ— æŸæ¯”å¯¹ï¼šå¿½ç•¥æ ‡ç‚¹å’Œç©ºç™½"""
    punctuation = r"""!"#$%&'()*+,-./:;<=>?@[\]^_`{|}~â€œâ€ï¼Ÿï¼Œï¼ã€ã€‘ï¼ˆï¼‰ã€ã€‚ï¼šï¼›â€™â€˜â€¦â€¦â€”â€”"""
    translator = str.maketrans('', '', punctuation)
    text = sanitize_ai_output(text) # å…ˆæ¸…æ´—
    text = re.sub(r'\d+[.ã€]', '', text)
    text = re.sub(r'\s+', '', text)
    return text.translate(translator)

def smart_split_text(text, chunk_size=800):
    """åˆ†å—ç¨å¾®æ”¹å°ä¸€ç‚¹ï¼Œä¿è¯AIæ³¨æ„åŠ›é›†ä¸­åœ¨åŠ¨ä½œåˆ†æä¸Š"""
    sentences = re.split(r'([ã€‚ï¼ï¼Ÿ])', text)
    chunks = []
    current = ""
    temp = []
    for i in range(0, len(sentences)-1, 2):
        temp.append(sentences[i] + sentences[i+1])
    if len(sentences) % 2 == 1:
        temp.append(sentences[-1])
        
    for s in temp:
        if len(current) + len(s) > chunk_size:
            chunks.append(current)
            current = s
        else:
            current += s
    if current:
        chunks.append(current)
    return chunks

def parse_df(full_text):
    lines = full_text.split('\n')
    data = []
    for i, line in enumerate(lines):
        if not line.strip(): continue
        clean_content = re.sub(r'^\d+[.ã€]\s*', '', line)
        length = len(clean_content)
        
        # è§†è§‰è¯„åˆ†é€»è¾‘
        if length > 35: status = "âŒ å¤ªé•¿ (éœ€å†æ‹†)"
        elif length < 6: status = "âš¡ å¿«åˆ‡/åŠ¨ä½œ"
        else: status = "âœ… æ ‡å‡†é•œå¤´"
            
        data.append({
            "åºå·": i+1,
            "åˆ†é•œå†…å®¹": clean_content,
            "å­—æ•°": length,
            "ç±»å‹": status
        })
    return pd.DataFrame(data)

# --- ä¸»ç¨‹åº ---
st.title("ğŸ¬ å¯¼æ¼”å¼•æ“ V16 (åŠ¨ä½œå›å½’ç‰ˆ)")

uploaded_file = st.file_uploader("ğŸ“‚ ä¸Šä¼  TXT", type=['txt'])

if uploaded_file:
    raw = uploaded_file.read().decode("utf-8")
    flat_input = clean_text_for_ai(raw)
    input_pure_len = len(normalize_text_for_comparison(flat_input))
    chunks = smart_split_text(flat_input)
    
    st.info(f"åŸæ–‡å·²å°±ç»ªï¼š{input_pure_len} ä¸ªæœ‰æ•ˆæ±‰å­—ã€‚æ­£åœ¨å‡†å¤‡æŒ‰ã€åŠ¨ä½œ/åœºæ™¯ã€‘è¿›è¡Œæ‹†è§£ã€‚")

    st.markdown("---")
    
    if st.button("ğŸš€ å¼€å§‹åŠ¨ä½œåˆ†é•œæ‹†è§£", type="primary"):
        if not api_key:
            st.error("è¯·é…ç½® API Key")
        else:
            client = OpenAI(api_key=api_key, base_url=base_url)
            full_results = []
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # --- V16 æ ¸å¿ƒ Promptï¼šå›å½’åˆå¿ƒ ---
            system_prompt = """
            ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„ç”µå½±åˆ†é•œå¸ˆã€‚
            è¯·å°†ç”¨æˆ·è¾“å…¥çš„æ–‡æ¡ˆï¼ŒæŒ‰ç…§ã€é•œå¤´åˆ‡æ¢é€»è¾‘ã€‘è¿›è¡Œåˆ†è¡Œå¤„ç†ã€‚

            ã€å¿…é¡»éµå®ˆçš„ 3 å¤§åˆ‡åˆ†è§„åˆ™ã€‘ï¼š
            1. **åŠ¨ä½œæ”¹å˜å³åˆ‡åˆ†**ï¼š
               - å¦‚æœä¸€å¥è¯é‡ŒåŒ…å«ä¸¤ä¸ªè¿ç»­åŠ¨ä½œï¼Œå¿…é¡»æ¢è¡Œã€‚
               - ä¾‹å¦‚ï¼šâ€œä»–æŠŠæˆ‘æ¨å€’åœ¨åºŠä¸Šï¼Œå¼€å§‹ç”»ç”»â€ -> å¿…é¡»åˆ‡åˆ†ä¸ºä¸¤è¡Œï¼šâ€œä»–æŠŠæˆ‘æ¨å€’åœ¨åºŠä¸Šâ€ã€â€œå¼€å§‹ç”»ç”»â€ã€‚
            2. **è§’è‰²/åœºæ™¯åˆ‡æ¢å³åˆ‡åˆ†**ï¼š
               - å¯¹è¯äººæ”¹å˜ï¼Œæˆ–è€…æ—¶é—´/åœ°ç‚¹å‘ç”Ÿæµé€ï¼Œå¿…é¡»æ¢è¡Œã€‚
            3. **å¼ºåˆ¶é•¿åº¦é™åˆ¶**ï¼š
               - ä»»ä½•ä¸€è¡Œä¸å¾—è¶…è¿‡ 35 å­—ã€‚å¦‚æœåŸæ–‡å¤ªé•¿ï¼Œè¯·åœ¨æ ‡ç‚¹ç¬¦å·å¤„åˆ‡å¼€ã€‚

            ã€ç»å¯¹ç¦ä»¤ã€‘ï¼š
            - **ä¸¥ç¦ä¿®æ”¹åŸæ–‡**ï¼šä¸è¦æ”¹å­—ï¼Œä¸è¦åˆ å­—ï¼Œä¸è¦åŠ å­—ã€‚
            - **ä¸¥ç¦æ·»åŠ æè¿°**ï¼šä¸è¦åŠ æ‹¬å·ï¼Œä¸è¦åŠ ç”»é¢è¯´æ˜ï¼Œåªä¿ç•™åŸæ–‡ã€‚
            - **ä¸è¦åˆå¹¶**ï¼šä¸è¦å› ä¸ºå¥å­çŸ­å°±åˆå¹¶ï¼Œåªè¦åŠ¨ä½œå˜äº†å°±å¿…é¡»åˆ‡ï¼
            """

            try:
                for i, chunk in enumerate(chunks):
                    status_text.markdown(f"**ğŸ¬ æ­£åœ¨åˆ†æç¬¬ {i+1}/{len(chunks)} éƒ¨åˆ†çš„åŠ¨ä½œç”»é¢...**")
                    
                    response = client.chat.completions.create(
                        model=model_id,
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": f"è¯·å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œåˆ†é•œåˆ‡åˆ†ï¼š\n{chunk}"}
                        ],
                        temperature=0.1 # ä½æ¸©ï¼Œä¸¥è°¨
                    )
                    
                    # è·å–ç»“æœå¹¶æ¸…æ´—
                    ai_raw_text = response.choices[0].message.content
                    # å¼ºåˆ¶æ¸…æ´—ï¼šç¡®ä¿æ²¡æœ‰æ‹¬å·é‡Œçš„åºŸè¯
                    cleaned_text = sanitize_ai_output(ai_raw_text)
                    
                    full_results.append(cleaned_text)
                    progress_bar.progress((i + 1) / len(chunks))

                # åˆæˆ
                combined = "\n".join(full_results)
                final_lines = [line.strip() for line in combined.split('\n') if line.strip()]
                
                # é‡å»ºè¾“å‡º
                final_output_text = ""
                raw_output_content = ""
                for idx, line in enumerate(final_lines):
                    clean = re.sub(r'^\d+[.ã€]\s*', '', line)
                    final_output_text += f"{idx+1}. {clean}\n"
                    raw_output_content += clean

                # --- ç»“æœå±•ç¤ºä¸æ ¸å¯¹ ---
                st.success("âœ… åˆ†é•œæ‹†è§£å®Œæˆï¼")
                
                output_pure_len = len(normalize_text_for_comparison(raw_output_content))
                diff = output_pure_len - input_pure_len
                
                # çœ‹æ¿
                m1, m2, m3, m4 = st.columns(4)
                m1.metric("åŸæ–‡æ±‰å­—æ•°", f"{input_pure_len}")
                m2.metric("åˆ†é•œæ±‰å­—æ•°", f"{output_pure_len}")
                
                if diff == 0:
                    m3.metric("å†…å®¹å®Œæ•´åº¦", "å®Œç¾æ— æŸ âœ…", delta="0", delta_color="normal")
                else:
                    m3.metric("åå·®å€¼", f"{diff}", delta="å¼‚å¸¸", delta_color="inverse")
                    
                m4.metric("åˆ†é•œæ€»ç»„æ•°", f"{len(final_lines)}", help="ç»„æ•°è¶Šå¤šï¼Œè¯´æ˜åŠ¨ä½œæ‹†è§£è¶Šç»†è‡´")

                if abs(diff) > 5:
                    st.error(f"âš ï¸ è­¦å‘Šï¼šæ£€æµ‹åˆ° {abs(diff)} å­—çš„åå·®ï¼Œè¯·æ£€æŸ¥ AI æ˜¯å¦æœ‰é—æ¼ã€‚")

                # å†…å®¹åŒº
                c1, c2 = st.columns([1.5, 1])
                
                with c1:
                    st.subheader("ğŸ“ åŠ¨ä½œåˆ†é•œè„šæœ¬")
                    st.text_area("ç»“æœé¢„è§ˆ", value=final_output_text, height=650)
                    st.download_button("ğŸ“¥ ä¸‹è½½åˆ†é•œ", data=final_output_text, file_name="åŠ¨ä½œåˆ†é•œ.txt")

                with c2:
                    st.subheader("ğŸ“Š ç”»é¢åˆ†æè¡¨")
                    df = parse_df(final_output_text)
                    st.dataframe(
                        df,
                        column_config={
                            "åºå·": st.column_config.NumberColumn(width="small"),
                            "åˆ†é•œå†…å®¹": st.column_config.TextColumn(width="large"),
                            "å­—æ•°": st.column_config.ProgressColumn(
                                "ç”»é¢è´Ÿè·", 
                                format="%d", 
                                min_value=0, 
                                max_value=40
                            ),
                            "ç±»å‹": st.column_config.TextColumn(width="medium")
                        },
                        hide_index=True,
                        height=650
                    )

            except Exception as e:
                st.error(f"âŒ é”™è¯¯: {e}")
