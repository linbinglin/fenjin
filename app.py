import streamlit as st
from openai import OpenAI
import io
import re
import pandas as pd

st.set_page_config(page_title="AIå…¨æµç¨‹å¯¼æ¼”åˆ†é•œç³»ç»Ÿ", layout="wide")

# --- åˆå§‹åŒ– Session State ---
if 'original_text' not in st.session_state: st.session_state.original_text = ""
if 'storyboard_draft' not in st.session_state: st.session_state.storyboard_draft = ""
if 'desc_batches' not in st.session_state: st.session_state.desc_batches = []
if 'batch_progress' not in st.session_state: st.session_state.batch_progress = 0

# --- ä¾§è¾¹æ é…ç½® ---
st.sidebar.title("ğŸ¬ å¯¼æ¼”å®¤è®¾ç½®")
api_key = st.sidebar.text_input("API Key", type="password")
base_url = st.sidebar.text_input("æ¥å£åœ°å€", value="https://blog.tuiwen.xyz/v1")
model_id = st.sidebar.text_input("Model ID", value="gpt-4o")

st.title("ğŸ¥ ç”µå½±è§£è¯´å…¨æµç¨‹å¯¼æ¼”åˆ†é•œç³»ç»Ÿ")
st.caption("åŸºäºç”µå½±å‰ªè¾‘é€»è¾‘ï¼šåœ¨éŸ³é¢‘æ—¶é•¿é™åˆ¶å†…ï¼Œå¯»æ‰¾æœ€å®Œç¾çš„è§†è§‰åˆ‡åˆ†ç‚¹ã€‚")

# ================= ç¬¬ä¸€é˜¶æ®µï¼šå¯¼æ¼”æ€ç»´åˆ†é•œ =================
st.header("ç¬¬ä¸€é˜¶æ®µï¼šæ–‡æ¡ˆåˆ†é•œæ‹†è§£")

uploaded_file = st.file_uploader("ä¸Šä¼ æ–‡æ¡ˆ (TXT)", type=['txt'])

if uploaded_file:
    # ã€é¢„å¤„ç†ã€‘ç‰©ç†å‰¥ç¦»åŸæ–‡æœ¬æ‰€æœ‰æ®µè½ï¼Œé˜²æ­¢AIå‚è€ƒåŸç»“æ„
    raw_content = io.StringIO(uploaded_file.getvalue().decode("utf-8")).read()
    clean_stream = re.sub(r'[\s\n\r]+', '', raw_content).strip()
    st.session_state.original_text = clean_stream
    
    st.write(f"**æ–‡æ¡ˆæµæŒ‡çº¹å·²ç”Ÿæˆ**ï¼ˆæ€»è®¡ï¼š{len(clean_stream)} å­—ï¼‰")

    if st.button("ğŸš€ å¼€å§‹æ™ºèƒ½åˆ†é•œå¤„ç†"):
        if not api_key:
            st.error("è¯·å…ˆè¾“å…¥ API Key")
        else:
            try:
                client = OpenAI(api_key=api_key, base_url=base_url)
                
                # æ·±åº¦å¯¼æ¼”æŒ‡ä»¤
                director_prompt = f"""ä½ ç°åœ¨æ˜¯ä¸€åèµ„æ·±ç”µå½±å‰ªè¾‘å¸ˆã€‚ä½ éœ€è¦å°†ä»¥ä¸‹ä¸€æ®µã€å®Œå…¨æ²¡æœ‰æ ¼å¼ã€‘çš„æ–‡æ¡ˆæµè¿›è¡Œæ— æŸåˆ†é•œå¤„ç†ã€‚

### æ ¸å¿ƒåˆ†é•œå‡†åˆ™ï¼š
1. **æ•°å­—åºå·**ï¼šæ¯ä¸€è¡Œå¿…é¡»ä»¥â€œæ•°å­—.â€å¼€å¤´ï¼Œä¾‹å¦‚ï¼š1.æ–‡æ¡ˆå†…å®¹
2. **æ‹’ç»å¹³åº¸åˆ‡å‰²**ï¼šä¸è¦ç®€å•åœ°æ¯35ä¸ªå­—ä¸€åˆ‡ã€‚35ä¸ªå­—æ˜¯ä¸€ä¸ªã€æ—¶é•¿é¢„è­¦çº¿ã€‘ï¼Œæ„å‘³ç€è§†é¢‘ç”Ÿæˆä¸Šé™æ˜¯5ç§’ã€‚
3. **åˆ†é•œæŠ€å·§ï¼ˆèŠ‚å¥æ„Ÿï¼‰**ï¼š
   - **å¯¹è¯åˆ‡æ¢**ï¼šå½“æ¢äººè¯´è¯æ—¶ï¼Œå¿…é¡»å¦èµ·åˆ†é•œï¼ˆå³ä½¿é‚£å¥è¯åªæœ‰5ä¸ªå­—ï¼‰ã€‚
   - **åœºæ™¯/æ—¶é—´è·³è·ƒ**ï¼šå½“æ•…äº‹åœ°ç‚¹æ”¹å˜æˆ–æ—¶é—´æµè½¬ï¼Œå¿…é¡»å¦èµ·åˆ†é•œã€‚
   - **è¯­ä¹‰èšæ‹¢ï¼ˆæ‹’ç»å¤ªç¢ï¼‰**ï¼šå¦‚æœè¿ç»­çš„çŸ­å¥å±äºåŒä¸€åœºæ™¯ä¸‹çš„è¿è´¯åŠ¨ä½œï¼ˆå¦‚ï¼šä»–ç«™èµ·æ¥ï¼Œæ‹¿èµ·æ¯å­ï¼Œå–äº†ä¸€å£æ°´ï¼‰ï¼Œè¯·èšæ‹¢åœ¨ä¸€ä¸ªåˆ†é•œä¸­ã€‚
   - **é•¿åº¦å¹³è¡¡**ï¼šç†æƒ³çš„åˆ†é•œé•¿åº¦åœ¨ 20-35 å­—ç¬¦ã€‚å¦‚æœä¸€å¥è¯æ¥è¿‘40å­—ç¬¦ï¼Œè¯·è§‚å¯Ÿæ˜¯å¦æœ‰é€»è¾‘æ–­ç‚¹ï¼ˆå¦‚ï¼šé€—å·ã€è½¬æŠ˜è¯ï¼‰è¿›è¡Œæ‹†åˆ†ã€‚
4. **æ— æŸåŸåˆ™**ï¼šä¸¥ç¦æ›´æ”¹ã€åˆ é™¤ã€æ·»åŠ ä»»ä½•åŸæ–‡æ–‡å­—ã€‚ä½ åªæ˜¯åœ¨æ–‡å­—é—´å†³å®šå“ªé‡Œè¯¥â€œå‰ªä¸€åˆ€â€ã€‚

### å¾…å¤„ç†æ–‡æ¡ˆæµï¼š
{clean_stream}"""

                with st.spinner("å¯¼æ¼”æ­£åœ¨æ„æ€åˆ†é•œèŠ‚å¥..."):
                    response = client.chat.completions.create(
                        model=model_id,
                        messages=[
                            {"role": "system", "content": "ä½ åªè¾“å‡ºåˆ†é•œåçš„æ–‡æ¡ˆï¼Œä¸è¦æœ‰ä»»ä½•å¤šä½™çš„å¼€åœºç™½æˆ–è§£é‡Šã€‚"},
                            {"role": "user", "content": director_instruction}
                        ],
                        temperature=0.3
                    )
                    st.session_state.storyboard_draft = response.choices[0].message.content
                    st.session_state.desc_batches = []
                    st.session_state.batch_progress = 0
            except Exception as e:
                st.error(f"å¤„ç†æŠ¥é”™: {str(e)}")

# æ˜¾ç¤ºåˆ†é•œç»“æœä¸ç›‘æ§
if st.session_state.storyboard_draft:
    col_edit, col_monitor = st.columns([3, 2])
    
    with col_edit:
        st.subheader("âœï¸ åˆ†é•œç²¾ä¿®åŒºï¼ˆå¯æ‰‹åŠ¨ç¼–è¾‘ï¼‰")
        edited_storyboard = st.text_area("åˆ†é•œæ–‡æ¡ˆé¢„è§ˆ", value=st.session_state.storyboard_draft, height=500)
        st.session_state.storyboard_draft = edited_storyboard

    with col_monitor:
        st.subheader("ğŸ“Š èŠ‚å¥ç›‘æ§é¢æ¿")
        # è§£æç¼–è¾‘æ¡†å†…å®¹
        lines = [l.strip() for l in edited_storyboard.split('\n') if l.strip()]
        rebuilt_text = ""
        analysis_list = []
        
        for i, line in enumerate(lines):
            # å…¼å®¹å„ç§åºå·æ ¼å¼å¹¶æå–æ–‡æ¡ˆ
            content = re.sub(r'^\d+[\.ã€\s]+', '', line)
            rebuilt_text += content
            char_len = len(content)
            
            # èŠ‚å¥è¯„ä»·é€»è¾‘
            if char_len > 40: status = "ğŸ”´ å¤ªæŒ¤(è¶…æ ‡)"
            elif char_len < 15: status = "ğŸŸ¡ ç•¥ç¢(è§†è¯­ä¹‰è€Œå®š)"
            else: status = "ğŸŸ¢ ç†æƒ³"
            
            analysis_list.append({"åºå·": i+1, "å­—æ•°": char_len, "èŠ‚å¥": status})
        
        # æ— æŸæ ¡éªŒ
        if len(rebuilt_text) == len(st.session_state.original_text):
            st.success(f"âœ… æ–‡æ¡ˆæ— æŸï¼šå…± {len(rebuilt_text)} å­—")
        else:
            diff = len(st.session_state.original_text) - len(rebuilt_text)
            st.error(f"âš ï¸ å†…å®¹åå·®ï¼šå·®é¢ {diff} å­—ï¼ˆè¯·æ£€æŸ¥æ˜¯å¦è¯¯åˆ ï¼‰")
            
        st.dataframe(pd.DataFrame(analysis_list), use_container_width=True)

    st.divider()

    # ================= ç¬¬äºŒé˜¶æ®µï¼šå¯¼æ¼”ç”»é¢æè¿° =================
    st.header("ç¬¬äºŒé˜¶æ®µï¼šAIç”»é¢ä¸è§†é¢‘æŒ‡ä»¤ç”Ÿæˆ")
    
    char_desc = st.text_area("1. å½•å…¥æ ¸å¿ƒè§’è‰²è§†è§‰è®¾å®š", 
                            placeholder="è¯·æè¿°è§’è‰²å¤–è²Œã€è¡£ç€ã€‚ä¾‹å¦‚ï¼šèµµå¤§å¸…ï¼š50å²ï¼Œä¸¤æ’‡èƒ¡é¡»ï¼Œèº«ç©¿æ·±è“è‰²å†›è£…ï¼Œçœ¼ç¥å¨ä¸¥ã€‚", 
                            height=100)
    
    if char_desc:
        # è·å–æœ€ç»ˆåˆ†é•œåˆ—è¡¨
        final_list = [re.sub(r'^\d+[\.ã€\s]+', '', l.strip()) for l in edited_storyboard.split('\n') if l.strip()]
        total_shots = len(final_list)
        idx = st.session_state.batch_progress
        batch_size = 20
        end_idx = min(idx + batch_size, total_shots)

        if idx < total_shots:
            if st.button(f"ğŸï¸ ç”Ÿæˆç¬¬ {idx+1} - {end_idx} ç»„ç”»é¢æè¿°"):
                try:
                    client = OpenAI(api_key=api_key, base_url=base_url)
                    batch_content = ""
                    for i, txt in enumerate(final_list[idx:end_idx]):
                        batch_content += f"åˆ†é•œ{idx+i+1}ï¼š{txt}\n"
                    
                    desc_prompt = f"""ä½ ç°åœ¨æ˜¯è§†è§‰å¯¼æ¼”ï¼Œè´Ÿè´£æ ¹æ®åˆ†é•œæ–‡æ¡ˆç”Ÿæˆç”»é¢æç¤ºè¯ã€‚

### è§’è‰²è®¾å®šï¼š
{char_desc}

### ä»»åŠ¡è¦æ±‚ï¼š
1. **ç”»é¢æè¿° (Midjourney)**ï¼šæè¿°è¯¥é•œå¤´çš„é™æ€è§†è§‰ã€‚å¿…é¡»åŒ…å«ï¼šæ™¯åˆ«ï¼ˆå¦‚ï¼šç‰¹å†™ã€ä¸­æ™¯ã€è¿œæ™¯ï¼‰ã€äººç‰©çš„ç¥æ€åŠ¨ä½œã€ç¯å¢ƒç»†èŠ‚ã€æœè£…æè´¨ã€å…‰å½±æ°›å›´ã€‚**ç¦æ­¢æè¿°åŠ¨æ€æ¼”å˜**ã€‚
2. **è§†é¢‘ç”Ÿæˆ (å³æ¢¦AI)**ï¼šæè¿°è¿™5ç§’å†…çš„ã€åŠ¨æ€å˜åŒ–ã€‘ã€‚ä½¿ç”¨çŸ­å¥ï¼Œæè¿°äººç‰©çš„å¾®è¡¨æƒ…æ¼”å˜ã€è‚¢ä½“ä½ç§»ã€æˆ–è€…é•œå¤´çš„è¿åŠ¨ï¼ˆå¦‚ï¼šæ‹‰è¿‘ã€æ‘‡ç§»ï¼‰ã€‚
3. **è¿è´¯æ€§**ï¼šç¡®ä¿æ¯ä¸ªåˆ†é•œä¸­çš„äººç‰©å¤–è²Œå’Œåœºæ™¯å…ƒç´ é«˜åº¦ç»Ÿä¸€ï¼Œé¿å…å‰²è£‚ã€‚

### å¾…å¤„ç†åˆ†é•œï¼š
{batch_content}"""

                    with st.spinner("AIæ­£åœ¨æ·±åº¦æ„æ€è§†è§‰ç»†èŠ‚..."):
                        response = client.chat.completions.create(
                            model=model_id,
                            messages=[{"role": "user", "content": desc_prompt}]
                        )
                        st.session_state.desc_batches.append(response.choices[0].message.content)
                        st.session_state.batch_progress = end_idx
                        st.rerun()
                except Exception as e:
                    st.error(f"æè¿°ç”Ÿæˆå¤±è´¥: {e}")
        else:
            st.success("âœ… å…¨éƒ¨åˆ†é•œæè¿°å·²ç”Ÿæˆå®Œæ¯•")

        # ç»“æœå±•ç¤º
        for b_idx, b_content in enumerate(st.session_state.desc_batches):
            with st.expander(f"ğŸ“¦ æ‰¹æ¬¡ {b_idx+1} ç”Ÿæˆç»“æœ (20ç»„)", expanded=True):
                st.markdown(b_content)
