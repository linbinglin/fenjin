import streamlit as st
from openai import OpenAI
import re
import pandas as pd

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="å‰ªè¾‘å¼•æ“ V15 (å­—å¹•èŠ‚å¥ç‰ˆ)",
    page_icon="âœ‚ï¸",
    layout="wide"
)

# --- CSS ---
st.markdown("""
<style>
    .metric-container { background-color: #f8f9fa; padding: 10px; border-radius: 5px; }
    .stDataFrame { width: 100%; }
</style>
""", unsafe_allow_html=True)

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("âš™ï¸ å‰ªè¾‘å¼•æ“ V15")
    st.caption("æ ¸å¿ƒï¼šçº¯å‡€æ–­å¥ï¼Œæ‹’ç»åŠ æˆ")
    
    api_key = st.text_input("API Key", type="password", placeholder="sk-...")
    base_url = st.text_input("æ¥å£åœ°å€", value="https://blog.tuiwen.xyz/v1")
    
    model_options = ["gpt-4o", "deepseek-chat", "claude-3-5-sonnet-20240620", "gpt-4-turbo"]
    selected_model = st.selectbox("Model ID", model_options, index=0)
    
    if st.checkbox("è‡ªå®šä¹‰æ¨¡å‹ID"):
        model_id = st.text_input("è¾“å…¥ID", value=selected_model)
    else:
        model_id = selected_model

    st.divider()
    st.markdown("### âœ‚ï¸ V15 æ–­å¥æ³•åˆ™")
    st.info("""
    1. **ç‰©ç†é˜»æ–­**ï¼šä»£ç å±‚å¼ºåˆ¶åˆ é™¤AIç”Ÿæˆçš„ä»»ä½•æ‹¬å·å¤‡æ³¨ã€‚
    2. **æ ‡ç‚¹é€»è¾‘**ï¼š
       - ã€ã€‚ï¼ï¼Ÿã€‘æ˜¯ç»å¯¹åˆ†ç•Œçº¿ã€‚
       - ã€ï¼Œã€‘æ˜¯è½¯åˆ†ç•Œçº¿ï¼Œä»…åœ¨é•¿å¥æ—¶åˆ‡å¼€ã€‚
    3. **æ—¶é•¿é”šç‚¹**ï¼š35å­— = 5ç§’çº¢çº¿ã€‚
    """)

# --- æ ¸å¿ƒå·¥å…·å‡½æ•° ---

def clean_text_for_ai(text):
    """é¢„å¤„ç†ï¼šå»æ¢è¡Œï¼Œå˜çº¯æ–‡æœ¬æµ"""
    return text.replace("\n", "").replace("\r", "").strip()

def sanitize_ai_output(text):
    """
    ã€V15 æ–°å¢æ ¸å¿ƒåŠŸèƒ½ã€‘
    å¼ºåˆ¶æ¸…æ´— AI çš„å¹»è§‰ï¼ˆåŠ æˆï¼‰ã€‚
    å»é™¤æ‰€æœ‰ (xxx)ã€ï¼ˆxxxï¼‰ã€ã€xxxã€‘ å†…å®¹ã€‚
    """
    # å»é™¤åœ†æ‹¬å·ã€æ–¹æ‹¬å·åŠå…¶å†…å®¹
    text = re.sub(r'[\(ï¼ˆã€\[].*?[\)ï¼‰ã€‘\]]', '', text)
    return text

def normalize_text_for_comparison(text):
    """ç”¨äºæ— æŸæ¯”å¯¹ï¼šå¿½ç•¥æ ‡ç‚¹å’Œç©ºç™½"""
    punctuation = r"""!"#$%&'()*+,-./:;<=>?@[\]^_`{|}~â€œâ€ï¼Ÿï¼Œï¼ã€ã€‘ï¼ˆï¼‰ã€ã€‚ï¼šï¼›â€™â€˜â€¦â€¦â€”â€”"""
    translator = str.maketrans('', '', punctuation)
    # å…ˆæ¸…æ´—å¯èƒ½çš„AIåŠ æˆ
    text = sanitize_ai_output(text)
    text = re.sub(r'\d+[.ã€]', '', text)
    text = re.sub(r'\s+', '', text)
    return text.translate(translator)

def smart_split_text(text, chunk_size=1000):
    sentences = re.split(r'([ã€‚ï¼ï¼Ÿ])', text)
    chunks = []
    current = ""
    temp = []
    for i in range(0, len(sentences)-1, 2):
        temp.append(sentences[i] + sentences[i+1])
    if len(sentences) % 2 == 1:
        temp.append(sentences[-1])
        
    for s in temp:
        if len(current) + len(s) > chunk_size:
            chunks.append(current)
            current = s
        else:
            current += s
    if current:
        chunks.append(current)
    return chunks

def parse_df(full_text):
    lines = full_text.split('\n')
    data = []
    for i, line in enumerate(lines):
        if not line.strip(): continue
        clean_content = re.sub(r'^\d+[.ã€]\s*', '', line)
        length = len(clean_content)
        
        # å­—å¹•èŠ‚å¥è¯„åˆ†
        if length > 35: status = "âŒ è¯»ä¸å®Œ (>35)"
        elif length > 25: status = "âš ï¸ ç¨ç´§å‡‘ (25-35)"
        elif length < 8: status = "âš¡ çŸ­ä¿ƒ (8å­—å†…)"
        else: status = "âœ… èˆ’é€‚ (8-25)"
            
        data.append({
            "åºå·": i+1,
            "åˆ†é•œæ–‡æ¡ˆ": clean_content,
            "å­—æ•°": length,
            "é…éŸ³èŠ‚å¥": status
        })
    return pd.DataFrame(data)

# --- ä¸»ç¨‹åº ---
st.title("âœ‚ï¸ å‰ªè¾‘å¼•æ“ V15 (æ— å¹»è§‰ç‰ˆ)")

uploaded_file = st.file_uploader("ğŸ“‚ ä¸Šä¼ æ–‡æ¡ˆ", type=['txt'])

if uploaded_file:
    raw = uploaded_file.read().decode("utf-8")
    flat_input = clean_text_for_ai(raw)
    input_pure_len = len(normalize_text_for_comparison(flat_input))
    
    chunks = smart_split_text(flat_input)
    
    st.info(f"åŸæ–‡è½½å…¥ï¼š{len(flat_input)} å­—ç¬¦ | {input_pure_len} æœ‰æ•ˆæ±‰å­— | åˆ‡åˆ†ä¸º {len(chunks)} å—å¤„ç†")

    st.markdown("---")
    
    if st.button("ğŸš€ å¼€å§‹çº¯å‡€æ–­å¥", type="primary"):
        if not api_key:
            st.error("è¯·é…ç½® API Key")
        else:
            client = OpenAI(api_key=api_key, base_url=base_url)
            full_results = []
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # --- V15 æ ¸å¿ƒæŒ‡ä»¤ï¼šå­—å¹•é€»è¾‘ï¼Œéå¯¼æ¼”é€»è¾‘ ---
            system_prompt = """
            ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ã€é…éŸ³å­—å¹•æ–­å¥å¸ˆã€‘ã€‚
            ä½ çš„ä»»åŠ¡æ˜¯å°†é•¿æ–‡æ¡ˆæŒ‰ç…§â€œäººè¯´è¯çš„å‘¼å¸èŠ‚å¥â€æ‹†åˆ†ä¸ºå¤šè¡Œã€‚

            ã€ç»å¯¹ç¦ä»¤ã€‘ï¼š
            1. **ä¸¥ç¦åŠ æˆ**ï¼šç»å¯¹ä¸è¦æ·»åŠ ä»»ä½•ï¼ˆåœºæ™¯æè¿°ï¼‰ã€ï¼ˆåŠ¨ä½œæŒ‡å¯¼ï¼‰ã€ï¼ˆæƒ…ç»ªå¤‡æ³¨ï¼‰ã€‚åªè¾“å‡ºåŸæ–‡ï¼
            2. **ä¸¥ç¦åˆ å‡**ï¼šåŸæ–‡çš„ä¸€ä¸ªæ ‡ç‚¹ç¬¦å·éƒ½ä¸èƒ½å°‘ã€‚

            ã€æ–­å¥è§„åˆ™ã€‘ï¼š
            1. **ç¡¬åˆ‡åˆ†**ï¼šé‡åˆ°ã€ã€‚ï¼ï¼Ÿã€‘å¿…é¡»æ¢è¡Œã€‚
            2. **è½¯åˆ‡åˆ†**ï¼šé‡åˆ°ã€ï¼Œï¼›ã€‘æ—¶ï¼Œå¦‚æœå½“å‰è¡Œå·²è¶…è¿‡ 20 ä¸ªå­—ï¼Œè¯·åœ¨æ ‡ç‚¹å¤„æ¢è¡Œã€‚
            3. **é•¿åº¦çº¢çº¿**ï¼š
               - ä»»ä½•ä¸€è¡Œä¸å¾—è¶…è¿‡ 35 å­—ã€‚
               - å¦‚æœä¸€å¥è¯é•¿è¾¾ 50 å­—ä¸”æ²¡æœ‰æ ‡ç‚¹ï¼ˆæå°‘è§ï¼‰ï¼Œè¯·åœ¨è¯­ä¹‰åœé¡¿å¤„å¼ºåˆ¶æ¢è¡Œã€‚
            4. **é˜²æ­¢è¿‡ç¢**ï¼š
               - å¦‚æœçŸ­å¥ï¼ˆå¦‚â€œä»–è¯´â€ï¼‰åç´§è·Ÿæ ‡ç‚¹ï¼Œä¸”åæ–‡å±äºåŒä¸€æ°”å£ï¼Œä¸”æ€»é•¿<25å­—ï¼Œå¯ä»¥ä¸æ¢è¡Œã€‚
            """

            try:
                for i, chunk in enumerate(chunks):
                    status_text.markdown(f"**âœ‚ï¸ æ­£åœ¨å‰ªè¾‘ç¬¬ {i+1}/{len(chunks)} å—...**")
                    
                    response = client.chat.completions.create(
                        model=model_id,
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": f"è¯·å¯¹ä»¥ä¸‹æ–‡æ¡ˆè¿›è¡Œæ–­å¥å¤„ç†ï¼š\n{chunk}"}
                        ],
                        temperature=0.1 # æä½æ¸©ï¼Œåªåšé€»è¾‘å¤„ç†
                    )
                    
                    # è·å–ç»“æœ
                    ai_raw_text = response.choices[0].message.content
                    # --- å…³é”®æ­¥éª¤ï¼šPython ä¾§å†æ¬¡æ¸…æ´— ---
                    # æ— è®º AI æœ‰æ²¡æœ‰å¬è¯ï¼Œè¿™é‡Œå¼ºåˆ¶æŠŠæ‹¬å·å†…å®¹åˆ æ‰ï¼Œé˜²æ­¢å­—æ•°æš´æ¶¨
                    cleaned_text = sanitize_ai_output(ai_raw_text)
                    
                    full_results.append(cleaned_text)
                    progress_bar.progress((i + 1) / len(chunks))

                # åˆæˆ
                combined = "\n".join(full_results)
                final_lines = [line.strip() for line in combined.split('\n') if line.strip()]
                
                # é‡å»º
                final_output_text = ""
                raw_output_content = ""
                for idx, line in enumerate(final_lines):
                    # æ¸…æ´—åºå·
                    clean = re.sub(r'^\d+[.ã€]\s*', '', line)
                    final_output_text += f"{idx+1}. {clean}\n"
                    raw_output_content += clean

                # --- ç»“æœçœ‹æ¿ ---
                st.success("âœ… å‰ªè¾‘å®Œæˆï¼å·²è‡ªåŠ¨å‰”é™¤æ‰€æœ‰AIè„‘è¡¥çš„åœºæ™¯æè¿°ã€‚")
                
                output_pure_len = len(normalize_text_for_comparison(raw_output_content))
                diff = output_pure_len - input_pure_len
                
                # ç»Ÿè®¡çœ‹æ¿
                st.markdown("### ğŸ“Š çº¯å‡€åº¦æ ¸éªŒ")
                m1, m2, m3, m4 = st.columns(4)
                
                m1.metric("ğŸ“„ åŸæ–‡æœ‰æ•ˆå­—æ•°", f"{input_pure_len}")
                m2.metric("ğŸ¬ åˆ†é•œæœ‰æ•ˆå­—æ•°", f"{output_pure_len}")
                
                # åå·®å€¼å¤„ç†
                if diff == 0:
                    delta_msg = "å®Œç¾æ— æŸ"
                    d_color = "normal"
                elif diff > 0:
                    delta_msg = f"å¤š {diff} å­—"
                    d_color = "inverse" # çº¢è‰²
                else:
                    delta_msg = f"å°‘ {abs(diff)} å­—"
                    d_color = "inverse"
                
                m3.metric("âš–ï¸ å†…å®¹åå·®", f"{diff}", delta=delta_msg, delta_color=d_color)
                
                avg_len = round(len(raw_output_content)/len(final_lines), 1)
                m4.metric("å¹³å‡æ¯è¡Œå­—æ•°", f"{avg_len}", help="20å·¦å³ä¸ºæœ€ä½³é…éŸ³èŠ‚å¥")

                if abs(diff) > 10:
                     st.error(f"âš ï¸ ä¾ç„¶å­˜åœ¨ {abs(diff)} å­—çš„åå·®ã€‚è¯·æ£€æŸ¥æ˜¯å¦ AI è¾“å‡ºäº†æ— å…³çš„å‰è¨€æˆ–åè¯­ã€‚")

                # å†…å®¹å±•ç¤º
                c1, c2 = st.columns([1.5, 1])
                
                with c1:
                    st.subheader("ğŸ“ åˆ†é•œç»“æœ (å·²æ¸…æ´—)")
                    st.text_area("æ–‡æ¡ˆé¢„è§ˆ", value=final_output_text, height=650)
                    st.download_button("ğŸ“¥ ä¸‹è½½æ–‡æ¡ˆ", data=final_output_text, file_name="åˆ†é•œæ–‡æ¡ˆ.txt")

                with c2:
                    st.subheader("â±ï¸ èŠ‚å¥åˆ†æ")
                    df = parse_df(final_output_text)
                    st.dataframe(
                        df,
                        column_config={
                            "åºå·": st.column_config.NumberColumn(width="small"),
                            "åˆ†é•œæ–‡æ¡ˆ": st.column_config.TextColumn(width="large"),
                            "å­—æ•°": st.column_config.ProgressColumn(
                                "é˜…è¯»æ—¶é•¿", 
                                format="%d", 
                                min_value=0, 
                                max_value=40
                            ),
                            "é…éŸ³èŠ‚å¥": st.column_config.TextColumn(width="medium")
                        },
                        hide_index=True,
                        height=650
                    )

            except Exception as e:
                st.error(f"âŒ å‡ºé”™äº†: {e}")
