import streamlit as st
import json
from openai import OpenAI
from pydub import AudioSegment
import io

st.set_page_config(page_title="AIå°è¯´é…éŸ³å·¥å…·", layout="wide")
st.title("AIå°è¯´é…éŸ³ç¨‹åºï¼ˆæ”¯æŒIndexTTS2äº‘ç«¯é…éŸ³ï¼‰")

# ä¾§è¾¹æ é…ç½®
st.sidebar.header("API ä¸æ¨¡å‹é…ç½®")
api_key = st.sidebar.text_input("Yunwu.ai API Key", type="password")
if not api_key:
    st.warning("è¯·åœ¨ä¾§è¾¹æ è¾“å…¥æ‚¨çš„ Yunwu.ai API Key")
    st.stop()

client = OpenAI(base_url="https://yunwu.ai/v1", api_key=api_key)

# LLM æ¨¡å‹é€‰æ‹©ï¼ˆåŒ…å«æ‚¨è¦æ±‚çš„æ‰€æœ‰æ¨¡å‹ï¼Œåç§°æ ¹æ®å¸¸è§ä»£ç†æ ¼å¼å¡«å†™ï¼‰
llm_models = [
    "gpt-4o",
    "claude-3-5-sonnet-20240620",
    "deepseek-chat",
    "gemini-1.5-pro",
    "grok-beta",
    "doubao-lite-32k",  # è±†åŒ…è½»é‡ç‰ˆï¼Œå¯æ ¹æ®å®é™…æ›¿æ¢
]
selected_llm = st.sidebar.selectbox("é€‰æ‹©ç”¨äºè§’è‰²è¯†åˆ«çš„AIæ¨¡å‹", llm_models)

# TTS é…ç½®ï¼ˆå›ºå®šä½¿ç”¨ IndexTTS2ï¼Œå¦‚éœ€æ”¹ä¸ºå¯é€‰å¯å–æ¶ˆæ³¨é‡Šï¼‰
tts_model = "indextts2"

# é¢„è®¾å£°éŸ³é€‰é¡¹ï¼ˆæ ¹æ®å¸¸è§ä¸­æ–‡TTSé¢„è®¾ï¼Œæ‚¨å¯æ ¹æ®å®é™…æ¥å£æ”¯æŒçš„å£°éŸ³åç§°è°ƒæ•´ï¼‰
voice_options = [
    "é»˜è®¤ç”·å£°", "é»˜è®¤å¥³å£°", "çƒ­æƒ…é’å¹´ç”·", "æ¸©æŸ”å°‘å¥³å¥³",
    "æˆç†Ÿç¨³é‡ç”·", "ç”œç¾å¯çˆ±å¥³", "æ—ç™½ä¸“ç”¨ç”·å£°", "å†·é™å™è¿°å¥³å£°"
]

# æ–‡ä»¶ä¸Šä¼ 
uploaded_file = st.file_uploader("ä¸Šä¼ å°è¯´TXTæ–‡ä»¶ï¼ˆåˆ†é•œå†…å®¹ï¼‰", type=["txt"])
if uploaded_file:
    text = uploaded_file.read().decode("utf-8")
    st.text_area("å°è¯´å…¨æ–‡é¢„è§ˆ", text, height=300)

    # è‡ªåŠ¨è¯†åˆ«è§’è‰²
    if st.button("ğŸ” è‡ªåŠ¨è¯†åˆ«è§’è‰²ä¸åˆ†æ®µ", type="primary"):
        with st.spinner("AI æ­£åœ¨åˆ†ææ–‡æœ¬ï¼Œè¯†åˆ«è§’è‰²ä¸å°è¯..."):
            prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å°è¯´é…éŸ³è„šæœ¬åˆ†æå¸ˆã€‚è¯·å°†ä»¥ä¸‹å°è¯´æ–‡æœ¬åˆ†è§£ä¸ºé¡ºåºçš„é…éŸ³æ®µè½ã€‚

è¦æ±‚ï¼š
1. æ¯æ®µåªèƒ½æ˜¯â€œæ—ç™½â€ï¼ˆå™è¿°æ–‡å­—ï¼‰æˆ–æŸä¸ªè§’è‰²çš„å°è¯ã€‚
2. è‡ªåŠ¨è¯†åˆ«æ‰€æœ‰å‡ºç°çš„è§’è‰²åã€‚
3. è¾“å‡ºä¸¥æ ¼ä¸ºJSONæ•°ç»„ï¼Œæ ¼å¼ï¼š[ {{"role": "è§’è‰²åæˆ–æ—ç™½", "text": "è¯¥æ®µå®Œæ•´æ–‡å­—"}} ]
4. è¦†ç›–å…¨éƒ¨æ–‡æœ¬ï¼Œä¸æ·»åŠ ä»»ä½•è§£é‡Šæˆ–é¢å¤–å†…å®¹ã€‚

å°è¯´æ–‡æœ¬ï¼š
{text}
"""
            try:
                response = client.chat.completions.create(
                    model=selected_llm,
                    messages=[
                        {"role": "system", "content": "ä½ å¿…é¡»åªè¾“å‡ºçº¯JSONï¼Œä¸è¦ä»»ä½•è¯´æ˜ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.3,
                    max_tokens=4096
                )
                content = response.choices[0].message.content.strip()
                # æ¸…ç†å¯èƒ½çš„ä»£ç å—
                if content.startswith("```"):
                    content = content.split("```")[1]
                    if content.startswith("json"):
                        content = content[4:]
                segments = json.loads(content)
                st.session_state.segments = segments
                st.session_state.full_text = text
                st.success(f"è¯†åˆ«å®Œæˆï¼å…± {len(segments)} æ®µï¼Œæ£€æµ‹åˆ°è§’è‰²ï¼š{[s['role'] for s in segments if s['role'] != 'æ—ç™½']}")
            except Exception as e:
                st.error(f"è¯†åˆ«å¤±è´¥ï¼š{e}")
                st.code(content if 'content' in locals() else "æ— è¾“å‡º")

# æ˜¾ç¤ºè§’è‰²è®¾ç½®ä¸ç”ŸæˆéŸ³é¢‘
if 'segments' in st.session_state:
    segments = st.session_state.segments
    roles = list(set(seg["role"] for seg in segments))

    st.header("ğŸ¤ è§’è‰²å£°éŸ³è®¾ç½®")
    col1, col2 = st.columns([1, 3])
    with col1:
        st.write("**è§’è‰²**")
    with col2:
        st.write("**åˆ†é…å£°éŸ³**")

    voice_map = {}
    for role in roles:
        default_idx = 6 if role == "æ—ç™½" else 0
        with col1:
            st.write(role)
        with col2:
            voice_map[role] = st.selectbox(f"å£°éŸ³ - {role}", voice_options, index=default_idx, key=f"voice_{role}")

    st.session_state.voice_map = voice_map

    if st.button("ğŸ”Š ç”Ÿæˆå®Œæ•´é…éŸ³", type="primary"):
        with st.spinner("æ­£åœ¨è°ƒç”¨äº‘ç«¯IndexTTS2ç”ŸæˆéŸ³é¢‘ï¼ˆå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰..."):
            audio_segments = []
            progress_bar = st.progress(0)
            for i, seg in enumerate(segments):
                role = seg["role"]
                text_seg = seg["text"].strip()
                if not text_seg:
                    continue
                voice = st.session_state.voice_map.get(role, voice_options[0])
                try:
                    # è°ƒç”¨äº‘ç«¯ IndexTTS2ï¼ˆå‡è®¾æ”¯æŒ OpenAI é£æ ¼çš„ audio/speechï¼‰
                    response = client.audio.speech.create(
                        model=tts_model,
                        voice=voice,          # å¦‚æœå®é™…å‚æ•°æ˜¯ speaker/style ç­‰ï¼Œè¯·ä¿®æ”¹
                        input=text_seg,
                        response_format="mp3"
                    )
                    audio_data = response.content
                    audio = AudioSegment.from_mp3(io.BytesIO(audio_data))
                    audio_segments.append(audio)
                except Exception as e:
                    st.error(f"ç¬¬ {i+1} æ®µï¼ˆ{role}ï¼‰ç”Ÿæˆå¤±è´¥ï¼š{e}")
                progress_bar.progress((i + 1) / len(segments))

            if audio_segments:
                # åˆå¹¶æ‰€æœ‰éŸ³é¢‘æ®µ
                combined = AudioSegment.empty()
                for seg in audio_segments:
                    combined += seg
                # ä¿å­˜å¹¶æä¾›é¢„è§ˆ/ä¸‹è½½
                output_bytes = io.BytesIO()
                combined.export(output_bytes, format="mp3")
                output_bytes.seek(0)
                st.audio(output_bytes, format="audio/mp3")
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½å®Œæ•´é…éŸ³MP3",
                    data=output_bytes,
                    file_name="AIé…éŸ³ç»“æœ.mp3",
                    mime="audio/mp3"
                )
                st.success("é…éŸ³ç”Ÿæˆå®Œæˆï¼")
            else:
                st.error("æ‰€æœ‰æ®µè½ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥APIæˆ–å£°éŸ³å‚æ•°")

st.info("æç¤ºï¼šå¦‚æœTTSå£°éŸ³å‚æ•°ä¸å®é™…æ¥å£ä¸ç¬¦ï¼ˆå¦‚éœ€ä½¿ç”¨speaker_idã€emotionç­‰ï¼‰ï¼Œè¯·ä¿®æ”¹ client.audio.speech.create ä¸­çš„å‚æ•°ã€‚")
