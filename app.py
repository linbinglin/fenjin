import streamlit as st
import json
from openai import OpenAI
import io
import os
import subprocess
import tempfile

st.set_page_config(page_title="AIå°è¯´é…éŸ³å·¥å…·", layout="wide")
st.title("AIå°è¯´é…éŸ³ç¨‹åºï¼ˆè‡ªéƒ¨ç½²äº‘ç«¯IndexTTS2ï¼‰")

# ä¾§è¾¹æ é…ç½®
st.sidebar.header("API é…ç½®")

# Yunwu.ai ç”¨äºè§’è‰²è¯†åˆ«
yunwu_api_key = st.sidebar.text_input("Yunwu.ai API Key (ç”¨äºè§’è‰²è¯†åˆ«)", type="password")
if not yunwu_api_key:
    st.sidebar.warning("è¯·å¡«å†™ Yunwu.ai Key ä»¥å¯ç”¨è§’è‰²è¯†åˆ«")

# è‡ªéƒ¨ç½² IndexTTS2 é…ç½®
tts_base_url = st.sidebar.text_input(
    "IndexTTS2 API Base URL",
    value="https://ffo5lqa2aapiq89w-7860.containerx-gpu.com/",
    help="å¡«å†™æ‚¨çš„äº‘ç«¯å®ä¾‹åœ°å€ï¼ˆåŒ…å«æœ«å°¾æ–œæ  / ï¼‰"
)
tts_api_key = st.sidebar.text_input("IndexTTS2 API Key (è‹¥æ— éœ€è®¤è¯å¯ç•™ç©º)", type="password", value="")
tts_model = st.sidebar.text_input("IndexTTS2 æ¨¡å‹åç§°", value="indextts2", help="å¸¸è§å€¼ï¼šindextts2ã€IndexTTS-2ã€tts-1 ç­‰ï¼Œè‹¥æŠ¥é”™è¯·å°è¯•ä¿®æ”¹")

if not tts_base_url:
    st.warning("è¯·åœ¨ä¾§è¾¹æ è¾“å…¥æ‚¨çš„ IndexTTS2 API Base URL")
    st.stop()

# LLM å®¢æˆ·ç«¯
if yunwu_api_key:
    llm_client = OpenAI(base_url="https://yunwu.ai/v1", api_key=yunwu_api_key)
else:
    llm_client = None

# TTS å®¢æˆ·ç«¯ï¼ˆè‡ªéƒ¨ç½²ï¼‰
tts_client = OpenAI(base_url=tts_base_url.rstrip("/"), api_key=tts_api_key or "none")

# LLM æ¨¡å‹é€‰æ‹©
llm_models = [
    "gpt-4o", "claude-3-5-sonnet-20240620", "deepseek-chat",
    "gemini-1.5-pro", "grok-beta", "doubao-lite-32k"
]
selected_llm = st.sidebar.selectbox("é€‰æ‹©ç”¨äºè§’è‰²è¯†åˆ«çš„AIæ¨¡å‹", llm_models)

# æ–‡ä»¶ä¸Šä¼ 
uploaded_file = st.file_uploader("ä¸Šä¼ å°è¯´TXTæ–‡ä»¶ï¼ˆåˆ†é•œå†…å®¹ï¼‰", type=["txt"])
if uploaded_file:
    text = uploaded_file.read().decode("utf-8")
    st.text_area("å°è¯´å…¨æ–‡é¢„è§ˆ", text, height=300)

    # è‡ªåŠ¨è¯†åˆ«è§’è‰²
    if st.button("ğŸ” è‡ªåŠ¨è¯†åˆ«è§’è‰²ä¸åˆ†æ®µ", type="primary"):
        if not llm_client:
            st.error("è¯·å…ˆå¡«å†™ Yunwu.ai API Key")
            st.stop()

        with st.spinner("AI æ­£åœ¨åˆ†ææ–‡æœ¬ï¼Œè¯†åˆ«è§’è‰²ä¸å°è¯..."):
            prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å°è¯´é…éŸ³è„šæœ¬åˆ†æå¸ˆã€‚è¯·å°†ä»¥ä¸‹å°è¯´æ–‡æœ¬åˆ†è§£ä¸ºé¡ºåºçš„é…éŸ³æ®µè½ã€‚

è¦æ±‚ï¼š
1. æ¯æ®µåªèƒ½æ˜¯â€œæ—ç™½â€ï¼ˆå™è¿°æ–‡å­—ï¼‰æˆ–æŸä¸ªè§’è‰²çš„å°è¯ã€‚
2. è‡ªåŠ¨è¯†åˆ«æ‰€æœ‰å‡ºç°çš„è§’è‰²åã€‚
3. è¾“å‡ºä¸¥æ ¼ä¸ºJSONæ•°ç»„ï¼Œæ ¼å¼ï¼š[ {{"role": "è§’è‰²åæˆ–æ—ç™½", "text": "è¯¥æ®µå®Œæ•´æ–‡å­—"}} ]
4. è¦†ç›–å…¨éƒ¨æ–‡æœ¬ï¼Œä¸æ·»åŠ ä»»ä½•è§£é‡Šæˆ–é¢å¤–å†…å®¹ã€‚

å°è¯´æ–‡æœ¬ï¼š
{text}
"""
            try:
                response = llm_client.chat.completions.create(
                    model=selected_llm,
                    messages=[
                        {"role": "system", "content": "ä½ å¿…é¡»åªè¾“å‡ºçº¯JSONï¼Œä¸è¦ä»»ä½•è¯´æ˜ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.3,
                    max_tokens=4096
                )
                content = response.choices[0].message.content.strip()
                if content.startswith("```"):
                    content = content.split("```")[1].strip()
                    if content.startswith("json"):
                        content = content[4:].strip()
                segments = json.loads(content)
                st.session_state.segments = segments
                st.session_state.full_text = text
                unique_roles = list(set(s['role'] for s in segments if s['role'] != 'æ—ç™½'))
                st.success(f"è¯†åˆ«å®Œæˆï¼å…± {len(segments)} æ®µï¼Œæ£€æµ‹åˆ°è§’è‰²ï¼š{unique_roles}")
            except Exception as e:
                st.error(f"è¯†åˆ«å¤±è´¥ï¼š{e}")

# ç”ŸæˆéŸ³é¢‘
if 'segments' in st.session_state:
    segments = st.session_state.segments

    st.header("ğŸ¤ å½“å‰è®¾ç½®ï¼šç»Ÿä¸€ä½¿ç”¨é»˜è®¤å£°çº¿ï¼ˆåç»­å¯æ‰©å±•å…‹éš†ï¼‰")
    st.info("IndexTTS2 é›¶æ ·æœ¬å…‹éš†èƒ½åŠ›æå¼ºï¼Œåç»­å¯ä¸ºæ¯ä¸ªè§’è‰²ä¸Šä¼ å‚è€ƒéŸ³é¢‘å®ç°ä¸åŒå£°éŸ³")

    if st.button("ğŸ”Š ç”Ÿæˆå®Œæ•´é…éŸ³", type="primary"):
        with st.spinner("æ­£åœ¨è°ƒç”¨æ‚¨çš„äº‘ç«¯IndexTTS2ç”Ÿæˆå¹¶åˆå¹¶éŸ³é¢‘..."):
            audio_bytes_list = []
            progress_bar = st.progress(0)
            for i, seg in enumerate(segments):
                text_seg = seg["text"].strip()
                if not text_seg:
                    continue
                try:
                    response = tts_client.audio.speech.create(
                        model=tts_model,
                        input=text_seg,
                        response_format="mp3"
                    )
                    audio_bytes_list.append(response.content)
                except Exception as e:
                    st.error(f"ç¬¬ {i+1} æ®µï¼ˆ{seg['role']}ï¼‰ç”Ÿæˆå¤±è´¥ï¼š{e}")
                progress_bar.progress((i + 1) / len(segments))

            if not audio_bytes_list:
                st.error("æ‰€æœ‰æ®µè½ç”Ÿæˆå¤±è´¥")
                st.stop()

            # ä½¿ç”¨ ffmpeg åˆå¹¶ï¼ˆä¸ä¾èµ– pydubï¼‰
            with tempfile.TemporaryDirectory() as tmpdir:
                input_paths = []
                for idx, audio_bytes in enumerate(audio_bytes_list):
                    path = os.path.join(tmpdir, f"seg{idx}.mp3")
                    with open(path, "wb") as f:
                        f.write(audio_bytes)
                    input_paths.append(path)

                list_path = os.path.join(tmpdir, "list.txt")
                with open(list_path, "w") as f:
                    for p in input_paths:
                        f.write(f"file '{p}'\n")

                output_path = os.path.join(tmpdir, "output.mp3")
                # å…ˆå°è¯•ç›´æ¥ copyï¼ˆæœ€å¿«ï¼‰ï¼Œå¤±è´¥åˆ™é‡æ–°ç¼–ç 
                result = subprocess.run([
                    "ffmpeg", "-y", "-f", "concat", "-safe", "0", "-i", list_path,
                    "-c", "copy", output_path
                ], capture_output=True)
                if result.returncode != 0:
                    st.warning("ç›´æ¥åˆå¹¶å¤±è´¥ï¼Œè‡ªåŠ¨åˆ‡æ¢ä¸ºé‡æ–°ç¼–ç åˆå¹¶")
                    subprocess.run([
                        "ffmpeg", "-y", "-f", "concat", "-safe", "0", "-i", list_path,
                        "-c:a", "libmp3lame", output_path
                    ], check=True)

                with open(output_path, "rb") as f:
                    combined_bytes = f.read()

            output_io = io.BytesIO(combined_bytes)
            st.audio(output_io, format="audio/mp3")
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½å®Œæ•´é…éŸ³MP3",
                data=output_io,
                file_name="AIé…éŸ³_IndexTTS2.mp3",
                mime="audio/mp3"
            )
            st.success("é…éŸ³ç”Ÿæˆå¹¶åˆå¹¶å®Œæˆï¼")

st.info("éƒ¨ç½²åè‹¥ä»æœ‰é—®é¢˜ï¼Œè¯·æˆªå›¾æœ€æ–°é”™è¯¯ã€‚å»ºè®®å…ˆç”¨æçŸ­æ–‡æœ¬ï¼ˆ1-2å¥ï¼‰æµ‹è¯•ï¼Œç¡®ä¿TTSæ¥å£æ­£å¸¸è¿”å›éŸ³é¢‘ã€‚")
