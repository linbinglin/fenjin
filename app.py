import streamlit as st
from openai import OpenAI
import re
import pandas as pd

# --- å·¥å…·å‡½æ•°ï¼šæ™ºèƒ½è¯­ä¹‰åˆ†å— (V11 å¢å¼ºç‰ˆ) ---
def smart_chunk_text(text, max_chars=1000):
    """å¯»æ‰¾æœ€ç¨³å›ºçš„æ ‡ç‚¹ç¬¦å·ï¼ˆã€‚ï¼ï¼Ÿ\nï¼‰è¿›è¡Œåˆ‡åˆ†ï¼Œç¡®ä¿æ¯ä¸€å—éƒ½æ˜¯å®Œæ•´çš„æ®µè½"""
    chunks = []
    while len(text) > max_chars:
        split_index = -1
        # ä¼˜å…ˆæ‰¾æ®µè½æœ«å°¾ï¼Œå…¶æ¬¡æ˜¯é•¿å¥æœ«å°¾
        for mark in ["\n", "ã€‚", "ï¼", "ï¼Ÿ"]:
            pos = text.rfind(mark, 0, max_chars)
            split_index = max(split_index, pos)
        
        if split_index == -1:
            split_index = max_chars
        else:
            split_index += 1 # åŒ…å«æ ‡ç‚¹ç¬¦å·
            
        chunks.append(text[:split_index].strip())
        text = text[split_index:]
    chunks.append(text.strip())
    return [c for c in chunks if c]

def get_pure_text(text):
    """ç²¾ç¡®æå–çº¯æ–‡æœ¬å†…å®¹ï¼Œç”¨äº 1:1 å¯¹è´¦"""
    text = re.sub(r'\d+[\.ã€]\s*', '', text)
    return "".join(text.split())

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="ç”µå½±è§£è¯´å¯¼æ¼” V11-è§†è§‰å•å…ƒç‰ˆ", layout="wide")

st.sidebar.title("âš™ï¸ å¯¼æ¼”å¼•æ“ V11")
api_key = st.sidebar.text_input("1. API Key", type="password")
base_url = st.sidebar.text_input("2. æ¥å£åœ°å€", value="https://blog.tuiwen.xyz/v1")
model_id = st.sidebar.text_input("3. Model ID", value="gpt-4o")

st.sidebar.divider()
st.sidebar.info("""
**ğŸï¸ V11 è§†è§‰åˆ‡åˆ†å‡†åˆ™ï¼š**
1. **ä¸»è¯­å³é•œå¤´**ï¼šäººç§°åˆ‡æ¢ï¼ˆå¦‚â€œæˆ‘â€è½¬â€œä»–â€ï¼‰å¿…é¡»æ–­å¼€ã€‚
2. **åŠ¨ä½œå³åˆ†é•œ**ï¼šä¸€ä¸ªæ ¸å¿ƒåŠ¨ä½œå®Œæˆåå¿…é¡»åˆ‡é•œã€‚
3. **å¯¹è¯ç‹¬ç«‹æ€§**ï¼šå°è¯ç»“æŸåçš„åŠ¨ä½œæå†™ä¸¥ç¦æ··åœ¨ä¸€èµ·ã€‚
4. **ç¡¬æ€§ 35 å­—**ï¼šå•è¡Œä¾ç„¶ç¦æ­¢è¶…è¿‡ 35 å­—ã€‚
""")

# --- ä¸»ç•Œé¢ ---
st.title("ğŸï¸ å…¨èƒ½æ–‡æ¡ˆÂ·ç”µå½±æ„Ÿåˆ†é•œç³»ç»Ÿ (V11)")
st.caption("é’ˆå¯¹â€œéŸ³ç”»ä¸åŒæ­¥â€ã€â€œå†…å®¹é‡å â€æ·±åº¦ä¼˜åŒ–ã€‚é€‚é…å…¨é¢˜ææ–‡æ¡ˆã€‚")

uploaded_file = st.file_uploader("ğŸ“‚ é€‰æ‹© TXT æ–‡æ¡ˆ", type=['txt'])

if uploaded_file is not None:
    raw_text = uploaded_file.getvalue().decode("utf-8")
    input_stream = "".join(raw_text.split())
    input_len = len(input_stream)

    st.subheader("ğŸ“Š è§†è§‰é€»è¾‘ç¨½æ ¸é¢æ¿")
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("åŸæ–‡æ€»å­—æ•°", f"{input_len} å­—")

    if st.button("ğŸš€ å¯åŠ¨è§†è§‰æ— æŸåˆ†é•œ"):
        if not api_key:
            st.error("è¯·é…ç½®ä¾§è¾¹æ å‚æ•°")
        else:
            try:
                actual_base = base_url.split('/chat')[0].strip()
                client = OpenAI(api_key=api_key, base_url=actual_base)
                
                # æ­¥éª¤ 1ï¼šæ™ºèƒ½åˆ†å—
                chunks = smart_chunk_text(input_stream)
                st.write(f"ğŸ“¦ å·²è¯†åˆ« {len(chunks)} ä¸ªç‹¬ç«‹å‰§æƒ…å—ï¼Œæ­£åœ¨è¿›è¡Œè§†è§‰å•å…ƒè§„åˆ’...")
                
                full_result = []
                current_shot_idx = 1
                
                progress_bar = st.progress(0)
                
                for idx, chunk in enumerate(chunks):
                    with st.spinner(f'æ­£åœ¨è§„åˆ’ç¬¬ {idx+1}/{len(chunks)} å—é•œå¤´...'):
                        # --- V11 è§†è§‰å¯¼æ¼” Prompt ---
                        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªé¡¶çº§çš„è§£è¯´è§†é¢‘å¯¼æ¼”ã€‚ä½ çš„ä»»åŠ¡æ˜¯æŠŠæ–‡æœ¬æµæ‹†è§£æˆâ€œç”»é¢é•œå¤´â€ã€‚

ã€è§†è§‰åˆ†é•œçº¢çº¿ã€‘ï¼š
1. **ä¸»è¯­å˜æ›´å³åˆ‡åˆ†**ï¼šåªè¦å¥å­çš„ä¸»è¯­ï¼ˆåŠ¨ä½œå‘å‡ºè€…ï¼‰å‘ç”Ÿäº†æ”¹å˜ï¼Œå¿…é¡»ç«‹å³ç»“æŸå½“å‰åˆ†é•œï¼Œå¼€å¯ä¸‹ä¸€ä¸ªç¼–å·ã€‚
2. **å°è¯ä¸åŠ¨ä½œåˆ†ç¦»**ï¼šè§’è‰²çš„ä¸€å¥å°è¯ç»“æŸåï¼Œç´§æ¥çš„å…¶ä»–è§’è‰²çš„ååº”æˆ–ç¯å¢ƒæå†™ï¼Œä¸¥ç¦æ”¾åœ¨åŒä¸€ä¸ªç¼–å·å†…ã€‚
3. **é•œåƒ 0 æŸè¿˜åŸ**ï¼šä½ åªæ˜¯è´Ÿè´£åŠ ç¼–å·å’Œæ¢è¡Œã€‚ä¸¥ç¦æ“…è‡ªä¿®æ”¹ã€æ¶¦è‰²ã€é‡å¤ã€æˆ–åˆå¹¶åŸæ–‡ä»»ä½•æ–‡å­—ã€‚åå·®å¿…é¡»ä¸º 0ã€‚
4. **é•¿åº¦ä¸è¯­æ„å¹³è¡¡**ï¼š
   - ç†æƒ³é•¿åº¦ï¼š25-35 å­—ã€‚
   - å¼ºåˆ¶ä¸Šé™ï¼š35 å­—ã€‚è‹¥å•å¥å°è¯è¶…é•¿ï¼Œè¯·åœ¨ä¸æ¼å­—çš„å‰æä¸‹åœ¨è¯­æ°”ç‚¹å¼ºè¡Œæ‹†åˆ†ã€‚
5. **æ‹’ç»ç¢ç‰‡åŒ–**ï¼šåœ¨ä¸»è¯­æœªå˜ã€åŠ¨ä½œè¿è´¯çš„å‰æä¸‹ï¼Œå°½é‡å¡«æ»¡ 25-35 å­—ã€‚

ã€è¾“å‡ºè¦æ±‚ã€‘ï¼š
- ä»ç¼–å· {current_shot_idx} å¼€å§‹ã€‚
- ä¸¥ç¦ä»»ä½•è§£é‡Šã€æ‹¬å·ã€ç”»é¢è¯ï¼Œåªè¾“å‡ºâ€œæ•°å­—.æ–‡æ¡ˆâ€ã€‚"""

                        response = client.chat.completions.create(
                            model=model_id,
                            messages=[
                                {"role": "system", "content": system_prompt},
                                {"role": "user", "content": f"è¯·å¯¹æ­¤æ–‡æœ¬å—è¿›è¡Œè§†è§‰å•å…ƒåˆ†é•œï¼Œä¸¥ç¦é‡å¤å’Œæ¼å­—ï¼š\n\n{chunk}"}
                            ],
                            temperature=0, 
                        )
                        
                        chunk_res = response.choices[0].message.content.strip()
                        full_result.append(chunk_res)
                        
                        # æ›´æ–°ä¸‹ä¸€å—çš„èµ·å§‹ç¼–å·
                        last_nums = re.findall(r'(\d+)[\.ã€]', chunk_res)
                        if last_nums:
                            current_shot_idx = int(last_nums[-1]) + 1
                        
                        progress_bar.progress((idx + 1) / len(chunks))

                # æ•°æ®åˆå¹¶ä¸å±•ç¤º
                final_result = "\n".join(full_result)
                output_stream = get_pure_text(final_result)
                output_len = len(output_stream)
                
                lines = [l.strip() for l in final_result.split('\n') if re.match(r'^\d+', l.strip())]
                count = len(lines)
                
                analysis_data = []
                for i, line in enumerate(lines):
                    content = re.sub(r'^\d+[\.ã€]\s*', '', line)
                    ln = len(content)
                    status = "âœ… ç†æƒ³" if 20 <= ln <= 35 else ("âŒ è¿‡é•¿" if ln > 35 else "ğŸŸ¡ åçŸ­")
                    analysis_data.append({"åºå·": i+1, "å†…å®¹é¢„è§ˆ": content[:20], "é•¿åº¦": ln, "çŠ¶æ€": status})
                df = pd.DataFrame(analysis_data)

                # çœ‹æ¿æ›´æ–°
                m2.metric("ç”Ÿæˆåˆ†é•œæ€»æ•°", f"{count} ç»„")
                m3.metric("å¤„ç†åæ€»å­—æ•°", f"{output_len} å­—")
                diff = output_len - input_len
                m4.metric("åå·®å€¼", f"{diff} å­—", delta_color="inverse")

                st.divider()

                # UI äº¤äº’
                c_a, c_b = st.columns([2, 1])
                with c_a:
                    st.subheader("ğŸ¬ è§†è§‰åˆ†é•œç¼–è¾‘å™¨ (æ— æŸè¿˜åŸ)")
                    if diff == 0: st.success("âœ… 100% é•œåƒè¿˜åŸæˆåŠŸ")
                    else: st.error(f"âš ï¸ åå·®ï¼š{diff} å­—ã€‚æç¤ºï¼šæ­£æ•°ä¸ºé‡å¤/è„‘è¡¥ï¼Œè´Ÿæ•°ä¸ºæ¼å­—ã€‚")
                    st.text_area("åˆ†é•œæ­£æ–‡", value=final_result, height=600)

                with c_b:
                    st.subheader("ğŸ“Š å®æ—¶è§†è§‰èŠ‚å¥åˆ†æ")
                    st.dataframe(df, use_container_width=True)
                    st.metric("å¹³å‡æ¯é•œåœç•™", f"{output_len/count:.1f} å­—")
                    st.download_button("ğŸ’¾ ä¸‹è½½æœ€ç»ˆåˆ†é•œç¨¿", final_result, "storyboard_v11.txt")

            except Exception as e:
                st.error(f"å¯¼æ¼”ç³»ç»Ÿè¿è¡Œå‡ºé”™ï¼š{str(e)}")
