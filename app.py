import streamlit as st
from openai import OpenAI
import re
import time

# ==========================================
# ğŸ¨ å…¨å±€æ ·å¼ä¸é…ç½®
# ==========================================
st.set_page_config(
    page_title="å¯¼æ¼”å¼•æ“ V11",
    page_icon="ğŸ¬",
    layout="wide"
)

# è‡ªå®šä¹‰CSSï¼Œä¸ºäº†å¤åˆ»æˆªå›¾ä¸­çš„å¤§å­—ä½“å’ŒMetricæ ·å¼
st.markdown("""
<style>
    [data-testid="stMetricValue"] {
        font-size: 24px;
        color: #333;
    }
    .big-font {
        font-size: 30px !important;
        font-weight: bold;
    }
    .stProgress > div > div > div > div {
        background-color: #007bff;
    }
</style>
""", unsafe_allow_html=True)

# ==========================================
# ğŸ§  æ ¸å¿ƒé€»è¾‘å‡½æ•°
# ==========================================

def flatten_text(text):
    """æ–‡æœ¬æ¸…æ´—ï¼šå»é™¤æ¢è¡Œï¼Œå‡†å¤‡â€˜é¢å›¢â€™"""
    text = text.replace("\n", " ").replace("\r", " ")
    text = re.sub(r'\d+[\.ã€]\s*', '', text) # å»é™¤åŸæœ‰åºå·
    return re.sub(r'\s+', ' ', text).strip()

def count_plot_blocks(text):
    """
    é€»è¾‘æ¨æ•²ï¼šæ¨¡æ‹Ÿæˆªå›¾ä¸­çš„'è¯†åˆ«å‰§æƒ…å—'ã€‚
    ç®€å•é€»è¾‘ï¼šæ ¹æ®åŒæ¢è¡Œç¬¦æ¥é¢„åˆ¤å¤§æ¦‚æœ‰å¤šå°‘ä¸ªè‡ªç„¶æ®µè½ã€‚
    """
    return len([b for b in text.split('\n\n') if b.strip()])

def calculate_deviation(original, generated):
    """
    ä¸¥è°¨è®¡ç®—åå·®å€¼ï¼š
    åŸæ–‡çº¯æ–‡æœ¬ vs ç”Ÿæˆå†…å®¹ï¼ˆå»æ‰åºå·åçš„ï¼‰çº¯æ–‡æœ¬
    """
    # æ¸…æ´—ç”Ÿæˆçš„å†…å®¹ï¼Œå»æ‰ "1. " è¿™ç§åºå·
    gen_clean = re.sub(r'^\d+[\.ã€]\s*', '', generated, flags=re.MULTILINE)
    gen_clean = gen_clean.replace('\n', '').replace(' ', '')
    
    org_clean = original.replace(' ', '').replace('\n', '')
    
    # ç®€å•çš„é•¿åº¦å·®è®¡ç®—
    return len(org_clean) - len(gen_clean)

# ==========================================
# ğŸ¬ ä¾§è¾¹æ  (å®Œç¾å¤åˆ»æˆªå›¾å·¦ä¾§)
# ==========================================
with st.sidebar:
    st.header("âš™ï¸ å¯¼æ¼”å¼•æ“ V11")
    
    api_key = st.text_input("API Key", type="password")
    base_url = st.text_input("æ¥å£åœ°å€", value="https://blog.tuiwen.xyz/v1")
    
    # æ¨¡å‹é€‰æ‹©
    model_id = st.text_input("Model ID", value="grok-4.1")
    
    st.markdown("---")
    
    # æˆªå›¾å·¦ä¸‹è§’çš„è“è‰²è¯´æ˜å—
    st.info("""
    **ğŸï¸ V11 è§†è§‰åˆ‡åˆ†å‡†åˆ™:**
    
    1. **ä¸»è¯­å³é•œå¤´**: äººç§°åˆ‡æ¢ï¼ˆå¦‚â€œæˆ‘â€è½¬â€œä»–â€ï¼‰å¿…é¡»æ–­å¼€ã€‚
    2. **åŠ¨ä½œå³åˆ†é•œ**: ä¸€ä¸ªæ ¸å¿ƒåŠ¨ä½œå®Œæˆåå¿…é¡»åˆ‡é•œã€‚
    3. **å¯¹è¯ç‹¬ç«‹æ€§**: å°è¯ç»“æŸåçš„åŠ¨ä½œæå†™ä¸¥ç¦æ··åœ¨ä¸€èµ·ã€‚
    4. **ç¡¬æ€§ 35 å­—**: å•è¡Œä¾ç„¶ç¦æ­¢è¶…è¿‡ 35 å­—ã€‚
    """)

# ==========================================
# ğŸ–¥ï¸ ä¸»ç•Œé¢ (å®Œç¾å¤åˆ»æˆªå›¾å¸ƒå±€)
# ==========================================

st.markdown("## ğŸï¸ å…¨èƒ½æ–‡æ¡ˆÂ·ç”µå½±æ„Ÿåˆ†é•œç³»ç»Ÿ (V11)")
st.caption("é’ˆå¯¹â€œéŸ³ç”»ä¸åŒæ­¥â€ã€â€œå†…å®¹é‡å â€æ·±åº¦ä¼˜åŒ–ã€‚é€‚é…å…¨é¢˜ææ–‡æ¡ˆã€‚")

# 1. æ–‡ä»¶ä¸Šä¼ 
uploaded_file = st.file_uploader("ğŸ“‚ é€‰æ‹© TXT æ–‡æ¡ˆ", type=['txt'])

if uploaded_file is not None:
    raw_content = uploaded_file.read().decode("utf-8")
    flat_content = flatten_text(raw_content)
    plot_blocks = count_plot_blocks(raw_content)
    
    # 2. è§†è§‰é€»è¾‘ç¨½æ ¸é¢æ¿ (UIæ ¸å¿ƒå¤åˆ»)
    st.markdown("### ğŸ“Š è§†è§‰é€»è¾‘ç¨½æ ¸é¢æ¿")
    
    # ä½¿ç”¨å ä½ç¬¦ï¼Œä»¥ä¾¿åç»­åŠ¨æ€æ›´æ–°æ•°æ®
    m1, m2, m3, m4 = st.columns(4)
    metric_origin = m1.metric("åŸæ–‡æ€»å­—æ•°", f"{len(flat_content)} å­—")
    metric_shots = m2.empty() # å ä½ï¼šç”Ÿæˆåˆ†é•œæ€»æ•°
    metric_processed = m3.empty() # å ä½ï¼šå¤„ç†åæ€»å­—æ•°
    metric_dev = m4.empty() # å ä½ï¼šåå·®å€¼
    
    # åˆå§‹åŒ–çŠ¶æ€
    metric_shots.metric("ç”Ÿæˆåˆ†é•œæ€»æ•°", "0 ç»„")
    metric_processed.metric("å¤„ç†åæ€»å­—æ•°", "å¾…å¤„ç†")
    metric_dev.metric("åå·®å€¼", "è®¡ç®—ä¸­...")

    # 3. å¯åŠ¨æŒ‰é’®ä¸è¿›åº¦æ¡
    if st.button("ğŸš€ å¯åŠ¨è§†è§‰æ— æŸåˆ†é•œ", type="primary"):
        if not api_key:
            st.error("ç¼ºå°‘ API Key")
        else:
            client = OpenAI(api_key=api_key, base_url=base_url)
            
            # --- æ¨¡æ‹Ÿæˆªå›¾ä¸­çš„è¿›åº¦æ¡æ•ˆæœ (å¢åŠ ä»ªå¼æ„Ÿ) ---
            progress_text = st.empty()
            bar = st.progress(0)
            
            progress_text.text(f"ğŸ“¦ å·²è¯†åˆ« {plot_blocks} ä¸ªç‹¬ç«‹å‰§æƒ…å—ï¼Œæ­£åœ¨è¿›è¡Œè§†è§‰å•å…ƒè§„åˆ’...")
            for i in range(100):
                time.sleep(0.01) # å‡è£…åœ¨æ€è€ƒï¼Œç»™ç”¨æˆ·å¿ƒç†ç¼“å†²
                bar.progress(i + 1)
            time.sleep(0.5)
            # ---------------------------------------

            st.markdown("### ğŸ“ è§†è§‰åˆ†é•œç¼–è¾‘å™¨ (æ— æŸè¿˜åŸ)")
            result_area = st.empty()
            full_response = ""
            
            # Prompt é€»è¾‘ (ä¿æŒ V2.0 çš„ä¸¥è°¨æ€§)
            system_prompt = f"""
            ä½ æ˜¯ç”±Pythonç¨‹åºè°ƒç”¨çš„ä¸“ä¸šåˆ†é•œå¼•æ“ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†è¾“å…¥çš„æ–‡æœ¬æµé‡ç»„ä¸ºæ ‡å‡†çš„è§†é¢‘åˆ†é•œåˆ—è¡¨ã€‚
            ã€å¼ºåˆ¶åŸåˆ™ã€‘
            1. **æ— æŸè¿˜åŸ**ï¼šå¿…é¡»åŒ…å«åŸæ–‡æ‰€æœ‰æ±‰å­—ï¼Œç¦æ­¢å¢åˆ ã€‚
            2. **Markdownåˆ—è¡¨**ï¼šè¾“å‡ºå¿…é¡»æ˜¯æ•°å­—åˆ—è¡¨æ ¼å¼ (1. xxx)ã€‚
            3. **æ¢è¡Œé€»è¾‘**ï¼šåœºæ™¯åˆ‡æ¢ã€å¯¹è¯åˆ‡æ¢ã€äººç§°åˆ‡æ¢å¿…é¡»æ¢è¡Œã€‚
            4. **å•è¡Œé™åˆ¶**ï¼šå•è¡Œå°½é‡æ§åˆ¶åœ¨35å­—ä»¥å†…ï¼Œé•¿éš¾å¥éœ€æ ¹æ®è¯­ä¹‰åˆ‡åˆ†ã€‚
            
            ç°åœ¨ï¼Œè¯·å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œåˆ†é•œï¼š
            """
            
            try:
                stream = client.chat.completions.create(
                    model=model_id,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": flat_content}
                    ],
                    stream=True,
                    temperature=0.1
                )
                
                # æµå¼è¾“å‡º
                for chunk in stream:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        full_response += content
                        result_area.markdown(full_response)
                        
                        # å®æ—¶æ›´æ–°â€œåˆ†é•œæ€»æ•°â€
                        current_shots = len(full_response.split('\n'))
                        metric_shots.metric("ç”Ÿæˆåˆ†é•œæ€»æ•°", f"{current_shots} ç»„")

                # --- ä»»åŠ¡å®Œæˆåçš„ä¸¥è°¨æ ¸ç®— ---
                
                # 1. è®¡ç®—å¤„ç†åå­—æ•° (å»æ‰åºå·)
                final_clean_text = re.sub(r'^\d+[\.ã€]\s*', '', full_response, flags=re.MULTILINE)
                final_clean_text = final_clean_text.replace('\n', '')
                metric_processed.metric("å¤„ç†åæ€»å­—æ•°", f"{len(final_clean_text)} å­—")
                
                # 2. è®¡ç®—åå·®å€¼
                deviation = len(flat_content.replace(' ', '')) - len(final_clean_text.replace(' ', ''))
                
                if deviation == 0:
                    metric_dev.metric("åå·®å€¼", "0 å­—", delta="å®Œç¾æ— æŸ", delta_color="normal")
                    st.success("âœ… 100% é•œåƒè¿˜åŸæˆåŠŸ")
                else:
                    metric_dev.metric("åå·®å€¼", f"{deviation} å­—", delta="å­˜åœ¨é—æ¼/å¢æ·»", delta_color="inverse")
                    st.warning(f"âš ï¸ è­¦å‘Šï¼šåŸæ–‡ä¸åˆ†é•œå­˜åœ¨ {deviation} å­—çš„åå·®ï¼Œè¯·æ£€æŸ¥AIæ˜¯å¦å·æ‡’ã€‚")
                    
            except Exception as e:
                st.error(f"å‘ç”Ÿé”™è¯¯: {e}")

else:
    # åˆå§‹ç©ºçŠ¶æ€å ä½
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§é…ç½® API å¹¶ä¸Šä¼ æ–‡ä»¶")
    
    # ä»…ä»…ä¸ºäº†å±•ç¤ºæ•ˆæœï¼Œæœªä¸Šä¼ æ–‡ä»¶æ—¶æ˜¾ç¤ºç©ºçš„é¢æ¿
    st.markdown("### ğŸ“Š è§†è§‰é€»è¾‘ç¨½æ ¸é¢æ¿")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("åŸæ–‡æ€»å­—æ•°", "0 å­—")
    c2.metric("ç”Ÿæˆåˆ†é•œæ€»æ•°", "0 ç»„")
    c3.metric("å¤„ç†åæ€»å­—æ•°", "0 å­—")
    c4.metric("åå·®å€¼", "0 å­—")
    
    st.markdown("---")
    # è¿›åº¦æ¡å ä½
    st.markdown("Wait for upload...")
    st.progress(0)
