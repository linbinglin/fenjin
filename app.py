import streamlit as st
from openai import OpenAI
import re
import pandas as pd

# ==========================================
# 1. æ ¸å¿ƒå·¥å…·å‡½æ•°ï¼šç¡®ä¿ 1:1 åƒç´ çº§è®¡ç®—
# ==========================================

def get_pure_text(text):
    """æå–çº¯å‡€æ–‡æ¡ˆå†…å®¹ï¼ˆä¸å«ç¼–å·ï¼‰"""
    if not text: return ""
    # å½»åº•æ¸…é™¤æ‰€æœ‰è¡Œé¦–æ•°å­—ç¼–å·æ ¼å¼
    text = re.sub(r'^\s*\d+[\.ã€\s]\s*', '', text, flags=re.MULTILINE)
    # å½»åº•æ¸…é™¤æ‰€æœ‰ç©ºç™½ç¬¦
    return "".join(text.split())

def reindex_text(text):
    """ä¸€é”®å¼ºåˆ¶é‡æ’åºå·"""
    lines = text.split('\n')
    valid_lines = []
    count = 1
    for line in lines:
        content = re.sub(r'^\s*\d+[\.ã€\s]\s*', '', line).strip()
        if content:
            valid_lines.append(f"{count}.{content}")
            count += 1
    return "\n".join(valid_lines)

# ==========================================
# 2. é¡µé¢é…ç½®ä¸åˆå§‹åŒ–
# ==========================================

st.set_page_config(page_title="å…¨èƒ½åˆ†é•œå¤§å¸ˆ V17", layout="wide")

if 'storyboard_output' not in st.session_state:
    st.session_state.storyboard_output = ""
if 'raw_clean_text' not in st.session_state:
    st.session_state.raw_clean_text = ""

with st.sidebar:
    st.title("âš™ï¸ ç³»ç»Ÿå¼•æ“è®¾ç½®")
    api_key = st.text_input("1. API Key", type="password")
    base_url = st.text_input("2. æ¥å£åœ°å€", value="https://blog.tuiwen.xyz/v1")
    model_id = st.text_input("3. Model ID", value="gpt-4o")
    
    st.divider()
    st.markdown("""
    **ğŸï¸ å¯¼æ¼”çº¢çº¿ (V17)ï¼š**
    - **å•é•œæ­»çº¿**ï¼šç»ä¸å‡†è¶… 35 å­—ã€‚
    - **ç¦æ­¢è„‘è¡¥**ï¼šä¸¥ç¦é‡å¤ã€æ”¹å†™ã€å¢æ·»ã€‚
    - **å¼ºåˆ¶åˆ‡åˆ†**ï¼šè¯­ä¹‰æœä»é•¿åº¦ã€‚
    """)

# ==========================================
# 3. ä¸»ç•Œé¢é€»è¾‘
# ==========================================

st.title("ğŸ¬ ç”µå½±è§£è¯´Â·ä¸‡èƒ½æ— æŸåˆ†é•œç³»ç»Ÿ (V17)")
st.caption("é’ˆå¯¹é•¿æ–‡æ¡ˆå¹»è§‰é‡å¤ã€åˆ†é•œè¿‡é•¿ã€å­—æ•°åå·®æ·±åº¦ä¼˜åŒ–ã€‚")

file = st.file_uploader("ğŸ“‚ ä¸Šä¼ æ–‡æ¡ˆ TXT æ–‡ä»¶", type=['txt'])

if file:
    raw_text = file.getvalue().decode("utf-8")
    # é”å®šåŸå§‹å­—ç¬¦æµ
    st.session_state.raw_clean_text = "".join(raw_text.split())
    input_len = len(st.session_state.raw_clean_text)

    st.subheader("ğŸ“Š æ–‡æ¡ˆé€»è¾‘æ ¡éªŒçœ‹æ¿")
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("åŸæ–‡æ€»å­—æ•°", f"{input_len} å­—")

    if st.button("ğŸš€ å¯åŠ¨é•œåƒçº§åˆ†é•œå¤„ç†"):
        if not api_key:
            st.error("è¯·é…ç½®ä¾§è¾¹æ å‚æ•°")
        else:
            try:
                # ä¿®å¤ URL è·¯å¾„
                client = OpenAI(api_key=api_key, base_url=base_url.strip())
                
                # ç‰©ç†åˆ‡å‰²ï¼šæ¯ 800 å­—ä¸€å—ï¼Œå‡å° AI çš„è®¤çŸ¥è´Ÿæ‹…ï¼Œé˜²æ­¢å¹»è§‰
                text_flow = st.session_state.raw_clean_text
                chunks = [text_flow[i:i+800] for i in range(0, len(text_flow), 800)]
                
                final_results = []
                idx_counter = 1
                bar = st.progress(0)
                
                for i, chunk in enumerate(chunks):
                    with st.spinner(f"æ­£åœ¨é•œåƒå¤„ç†ç¬¬ {i+1}/{len(chunks)} æ®µ..."):
                        # V17 å¼ºåˆ¶é•œåƒæŒ‡ä»¤ï¼šä¸å‡†å½“å¯¼æ¼”ï¼Œåªå‡†å½“åˆ‡å‰²æœº
                        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„æ–‡æœ¬åˆ‡å‰²æœºã€‚
ä½ çš„å”¯ä¸€ä»»åŠ¡æ˜¯å°†ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬æµï¼ŒæŒ‰é¡ºåºæ’å…¥ç¼–å·å¹¶æ¢è¡Œã€‚

ã€ç¡¬æ€§è¦æ±‚ã€‘ï¼š
1. **ç»å¯¹å­—æ•°å¹³è¡¡**ï¼šæ¯ä¸ªåˆ†é•œç¼–å·åçš„æ–‡å­—å†…å®¹ï¼Œå¿…é¡»åœ¨ 20-35 ä¸ªå­—ä¹‹é—´ã€‚
2. **å¼ºåˆ¶æ–­å¥**ï¼šå³ä¾¿ä¸€å¥è¯æ²¡å†™å®Œï¼Œåªè¦å­—æ•°æ¥è¿‘ 35 ä¸ªå­—ï¼Œå¿…é¡»ç«‹å³æˆªæ–­å¼€å¯æ–°ç¼–å·ã€‚
3. **é›¶å®¹å¿è„‘è¡¥**ï¼šä¸¥ç¦å¢åŠ ã€åˆ å‡ã€æ¶¦è‰²ã€æ€»ç»“æˆ–é‡å¤åŸæ–‡ä»»ä½•å­—ç¬¦ã€‚ä½ è¾“å‡ºçš„æ¯ä¸€ä¸ªå­—å¿…é¡»åœ¨åŸæ–‡ä¸­èƒ½æ‰¾åˆ° 1:1 çš„å¯¹åº”ã€‚
4. **ç¼–å·é”šç‚¹**ï¼šä»ç¬¬ {idx_counter} å·å¼€å§‹ã€‚

ã€ç¤ºä¾‹ã€‘ï¼š
1.æˆ‘æ˜¯åæ»¡äº¬åŸçš„ç¥ç§˜ç”»å¸ˆä¸€ç¬”ä¸€
2.åˆ’çš†èƒ½å‹¾åŠ¨ç”·å­æƒ…æ¬²ä¸–é—´å¥³å­
ï¼ˆæ³¨æ„ï¼šä¸ºäº†æ­»å®ˆå­—æ•°ï¼Œå¯ä»¥ç‰ºç‰²è¯­ä¹‰å®Œæ•´æ€§ï¼‰"""

                        response = client.chat.completions.create(
                            model=model_id,
                            messages=[
                                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ²¡æœ‰æ„Ÿæƒ…çš„æ–‡æœ¬é•œåƒåˆ‡å‰²æœºï¼Œåªè¾“å‡ºç¼–å·åˆ—è¡¨ã€‚"},
                                {"role": "user", "content": chunk}
                            ],
                            temperature=0
                        )
                        res_content = response.choices[0].message.content.strip()
                        final_results.append(res_content)
                        
                        # æ›´æ–°ä¸‹ä¸€æ®µçš„åºå·
                        found_nums = re.findall(r'(\d+)[\.ã€]', res_content)
                        if found_nums:
                            idx_counter = int(found_nums[-1]) + 1
                        bar.progress((i+1)/len(chunks))

                st.session_state.storyboard_output = "\n".join(final_results)
                st.success("é•œåƒåˆ†é•œå®Œæˆï¼")
            except Exception as e:
                st.error(f"å¤„ç†å¤±è´¥ï¼š{str(e)}")

# ==========================================
# 4. ç¼–è¾‘ä¸ç²¾å¯†åˆ†æåŒº
# ==========================================

if st.session_state.storyboard_output:
    st.divider()
    col_l, col_r = st.columns([2, 1])
    
    with col_l:
        st.subheader("ğŸ“ å¯¼æ¼”ç²¾ä¿®åŒº")
        # å®æ—¶åŒæ­¥ç¼–è¾‘å™¨å†…å®¹
        current_text = st.text_area(
            "æ‰‹åŠ¨è°ƒæ•´å†…å®¹ï¼ˆæŒ‰å›è½¦å¢åŠ åˆ†é•œï¼Œåˆ é™¤åˆå¹¶ï¼‰ï¼š",
            value=st.session_state.storyboard_output,
            height=600
        )
        
        c1, c2 = st.columns(2)
        if c1.button("ğŸ”¢ æ ¡å‡†å¹¶é‡æ’åºå·"):
            st.session_state.storyboard_output = reindex_text(current_text)
            st.rerun()
        
        c2.download_button("ğŸ’¾ ä¸‹è½½å…¨æœ¬åˆ†é•œç¨¿", st.session_state.storyboard_output, "final_storyboard.txt")

    with col_r:
        st.subheader("ğŸ“Š èŠ‚å¥èŠ‚å¥å®æ—¶ç›‘æ§")
        # è®¡ç®—å½“å‰ç¼–è¾‘å™¨å†…çš„çº¯å­—æ•°
        clean_output = get_pure_text(current_text)
        out_len = len(clean_output)
        diff = out_len - len(st.session_state.raw_clean_text)
        
        # ç»Ÿè®¡åˆ†é•œè¡Œ
        shot_lines = [l for l in current_text.split('\n') if re.match(r'^\d+', l.strip())]
        
        st.metric("ç”Ÿæˆåˆ†é•œæ€»æ•°", f"{len(shot_lines)} ç»„")
        st.metric("å½“å‰è¿˜åŸå­—æ•°", f"{out_len} å­—")
        
        if diff == 0:
            st.success("âœ… å­—æ•° 1:1 æ— æŸè¿˜åŸ")
        else:
            st.error(f"âŒ åå·®ï¼š{diff} å­—")
            st.caption("æ­£æ•°è¡¨ç¤º AI è„‘è¡¥æˆ–é‡å¤äº†å†…å®¹ï¼Œè´Ÿæ•°è¡¨ç¤ºæ¼å­—ã€‚")

        # èŠ‚å¥è¡¨é¢„è§ˆ
        analysis = []
        for i, line in enumerate(shot_lines):
            txt = re.sub(r'^\d+[\.ã€\s]\s*', '', line)
            ln = len(txt)
            analysis.append({"é•œ": i+1, "å­—æ•°": ln, "çŠ¶æ€": "âœ…" if ln <= 35 else "âŒå¤ªé•¿"})
        
        st.dataframe(pd.DataFrame(analysis), height=400, use_container_width=True)
