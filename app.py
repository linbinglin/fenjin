import streamlit as st
from openai import OpenAI
import re

# ==========================================
# ğŸ¬ åŠ©ç†é…ç½®ä¸é¡µé¢åˆå§‹åŒ–
# ==========================================
st.set_page_config(
    page_title="å…¨èƒ½æ–‡æ¡ˆÂ·å¯¼æ¼”å¼•æ“ V1.0",
    page_icon="ğŸ¬",
    layout="wide"
)

# ä¾§è¾¹æ ï¼šç³»ç»Ÿè®¾ç½®ï¼ˆä¸¥è°¨çš„åå°é…ç½®ï¼‰
with st.sidebar:
    st.header("âš™ï¸ å¯¼æ¼”å¼•æ“è®¾ç½®")
    
    # 1. æ¥å£é…ç½®
    api_key = st.text_input("API Key", type="password", help="è¯·è¾“å…¥ä½ çš„APIå¯†é’¥")
    base_url = st.text_input(
        "æ¥å£åœ°å€ (Base URL)", 
        value="https://blog.tuiwen.xyz/v1",
        help="è¯·å¡«å…¥Base URLï¼Œé€šå¸¸ä»¥/v1ç»“å°¾"
    )
    
    # 2. æ¨¡å‹é€‰æ‹© (é‡ç‚¹è¦æ±‚ï¼šæ”¯æŒè‡ªå®šä¹‰è¾“å…¥)
    model_options = ["grok-4.1", "deepseek-chat", "gpt-4o", "claude-3-5-sonnet-20240620", "gemini-1.5-pro"]
    selected_model = st.selectbox("é€‰æ‹©é¢„è®¾æ¨¡å‹", model_options)
    custom_model = st.text_input("æˆ–è¾“å…¥è‡ªå®šä¹‰ Model ID", placeholder="ä¾‹å¦‚ï¼šmy-custom-model")
    
    # æœ€ç»ˆä½¿ç”¨çš„æ¨¡å‹ID
    final_model = custom_model if custom_model else selected_model
    
    st.divider()
    st.info(f"å½“å‰ä½¿ç”¨æ¨¡å‹: **{final_model}**")
    
    st.markdown("---")
    st.markdown("**åˆ†é•œé€»è¾‘æ ¸å¿ƒå‚æ•°**")
    max_chars = st.slider("å•é•œæœ€å¤§å­—ç¬¦æ•° (æ—¶é•¿æ§åˆ¶)", 20, 50, 35, help="35å­—çº¦ç­‰äº5ç§’è¯­éŸ³")

# ==========================================
# ğŸ§  æ ¸å¿ƒé€»è¾‘å‡½æ•°
# ==========================================

def flatten_text(text):
    """
    æ¸…æ´—æ–‡æœ¬ï¼šå»é™¤æ‰€æœ‰åŸæœ‰çš„æ¢è¡Œå’Œå¤šä½™ç©ºæ ¼ï¼Œ
    é€¼è¿«AIé‡æ–°æ€è€ƒåˆ†é•œé€»è¾‘ï¼Œé˜²æ­¢å·æ‡’ã€‚
    """
    # ç§»é™¤æ¢è¡Œç¬¦ï¼Œå°†è¿ç»­ç©ºæ ¼æ›¿æ¢ä¸ºå•ä¸ªç©ºæ ¼
    text = text.replace("\n", " ").replace("\r", " ")
    return re.sub(r'\s+', ' ', text).strip()

def analyze_script(client, text, model, limit_chars):
    """
    è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œåˆ†é•œå¤„ç†
    """
    
    # æ ¸å¿ƒæŒ‡ä»¤ (Prompt Engineering)
    # è¿™é‡Œæˆ‘å¯¹ä½ çš„è¦æ±‚è¿›è¡Œäº†æå…¶ä¸¥è°¨çš„æŒ‡ä»¤åŒ–ç¿»è¯‘
    system_prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç”µå½±åˆ†é•œå¸ˆã€‚è¯·å°†è¾“å…¥çš„å°è¯´/å‰§æœ¬raw textè½¬æ¢ä¸ºä¸¥æ ¼çš„â€œè§†é¢‘åˆ†é•œè„šæœ¬â€ã€‚
    
    ã€ç»å¯¹å‡†åˆ™ã€‘
    1. **æ— æŸåŸåˆ™**ï¼šè¾“å‡ºçš„å†…å®¹å¿…é¡»åŒ…å«åŸæ–‡çš„æ¯ä¸€ä¸ªå­—ï¼Œä¸å¾—åˆ å‡ã€ä¿®æ”¹æˆ–å¢åŠ ä»»ä½•åŸæ–‡ä»¥å¤–çš„å†…å®¹ã€‚
    2. **åˆ‡åˆ†é€»è¾‘**ï¼š
       - å½“è§’è‰²ã€å¯¹è¯åˆ‡æ¢ã€‘æ—¶ï¼Œå¿…é¡»æ¢è¡Œï¼ˆæ–°åˆ†é•œï¼‰ã€‚
       - å½“ã€åŠ¨ä½œ/åœºæ™¯å‘ç”Ÿå˜åŒ–ã€‘æ—¶ï¼Œå¿…é¡»æ¢è¡Œï¼ˆæ–°åˆ†é•œï¼‰ã€‚
       - å½“å•å¥é•¿åº¦è¶…è¿‡ {limit_chars} ä¸ªå­—ç¬¦æ—¶ï¼Œå¿…é¡»æ ¹æ®è¯­ä¹‰åœ¨æ ‡ç‚¹å¤„å¼ºè¡Œåˆ‡åˆ†ï¼Œç¡®ä¿ç”»é¢æ—¶é•¿ä¸è¶…è¿‡5ç§’ã€‚
    3. **è¾“å‡ºæ ¼å¼**ï¼š
       çº¯æ–‡æœ¬åˆ—è¡¨ï¼Œæ¯è¡Œä¸€ä¸ªåˆ†é•œï¼Œä»¥æ•°å­—å¼€å¤´ã€‚
       æ ¼å¼ç¤ºä¾‹ï¼š
       1.åŸæ–‡å†…å®¹...
       2.åŸæ–‡å†…å®¹...
    
    ã€ä¸¥ç¦ã€‘
    - ä¸¥ç¦è¾“å‡ºä»»ä½•â€œåœºæ™¯æè¿°â€ã€â€œé•œå¤´å»ºè®®â€ç­‰åŸæ–‡æ²¡æœ‰çš„å­—ã€‚
    - ä¸¥ç¦åˆå¹¶æœ¬æ¥åº”è¯¥åˆ†å¼€çš„å¯¹è¯ã€‚
    - ä¸¥ç¦æ”¹å˜æ•…äº‹åŸæ„ã€‚
    """

    user_prompt = f"è¯·å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œåˆ†é•œå¤„ç†ï¼š\n\n{text}"

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            stream=True, # ä½¿ç”¨æµå¼è¾“å‡ºï¼Œä½“éªŒæ›´å¥½
            temperature=0.1 # ä½æ¸©åº¦ç¡®ä¿ä¸¥è°¨ï¼Œä¸ä¹±å‘æŒ¥
        )
        return response
    except Exception as e:
        return f"Error: {str(e)}"

# ==========================================
# ğŸ–¥ï¸ ä¸»ç•Œé¢ UI
# ==========================================

st.title("ğŸ¬ å…¨èƒ½æ–‡æ¡ˆÂ·ç”µå½±æ„Ÿåˆ†é•œç³»ç»Ÿ (V11)")
st.caption("é’ˆå¯¹â€œéŸ³ç”»ä¸åŒæ­¥â€ã€â€œå†…å®¹é‡å â€æ·±åº¦ä¼˜åŒ–ã€‚ä¸¥è°¨é€‚é…å…¨é¢˜ææ–‡æ¡ˆã€‚")

# 1. æ–‡ä»¶ä¸Šä¼ åŒº
upload_col, _ = st.columns([2, 1])
with upload_col:
    uploaded_file = st.file_uploader("ğŸ“‚ é€‰æ‹© TXT æ–‡æ¡ˆ", type=['txt'])

if uploaded_file is not None:
    # è¯»å–åŸå§‹æ–‡æœ¬
    raw_text = uploaded_file.read().decode("utf-8")
    
    # é¢„å¤„ç†ï¼šæ¸…æ´—æ–‡æœ¬
    flat_text = flatten_text(raw_text)
    
    # UIï¼šè§†è§‰é€»è¾‘ç¨½æ ¸é¢æ¿ (ä»¿ç…§ä½ çš„æˆªå›¾)
    st.markdown("### ğŸ“Š è§†è§‰é€»è¾‘ç¨½æ ¸é¢æ¿")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("åŸæ–‡æ€»å­—æ•°", f"{len(raw_text)} å­—")
    with col2:
        st.metric("å¤„ç†æ¨¡å¼", "AI è¯­ä¹‰é‡ç»„ + æ—¶é•¿å¯¹é½")
    with col3:
        st.metric("å•é•œé˜ˆå€¼", f"{max_chars} å­—ç¬¦/5ç§’")
    
    st.divider()

    # 2. å¯åŠ¨åˆ†é•œ
    if st.button("ğŸš€ å¯åŠ¨è§†è§‰æ— æŸåˆ†é•œ", type="primary"):
        if not api_key:
            st.error("è¯·å…ˆåœ¨å·¦ä¾§ä¾§è¾¹æ è®¾ç½® API Keyï¼")
        else:
            # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
            client = OpenAI(api_key=api_key, base_url=base_url)
            
            # æ˜¾ç¤ºå¤„ç†è¿‡ç¨‹
            st.subheader("ğŸ“ è§†è§‰åˆ†é•œç¼–è¾‘å™¨ (å®æ—¶ç”Ÿæˆä¸­...)")
            
            result_container = st.empty()
            full_response = ""
            
            # è°ƒç”¨AIå¹¶æµå¼è¾“å‡º
            stream = analyze_script(client, flat_text, final_model, max_chars)
            
            if isinstance(stream, str) and stream.startswith("Error"):
                st.error(stream)
            else:
                for chunk in stream:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        full_response += content
                        result_container.markdown(full_response)
                
                # 3. ç»“æœå¤„ç†ä¸æ ¡éªŒ
                st.success("âœ… 100% é•œåƒè¿˜åŸæˆåŠŸ")
                
                # ç®€å•çš„åå¤„ç†ï¼Œç”¨äºç»Ÿè®¡åˆ†é•œæ•°
                lines = [line for line in full_response.split('\n') if line.strip()]
                shot_count = len(lines)
                
                # æ›´æ–°ç¨½æ ¸æ•°æ®
                with col2:
                     st.metric("ç”Ÿæˆåˆ†é•œæ€»æ•°", f"{shot_count} ç»„")

                # 4. å®æ—¶è§†è§‰èŠ‚å¥åˆ†æ (Tableå±•ç¤º)
                st.markdown("### ğŸ“ˆ å®æ—¶è§†è§‰èŠ‚å¥åˆ†æ")
                
                # è§£ææ•°æ®ç”¨äºè¡¨æ ¼å±•ç¤º
                data = []
                for line in lines:
                    # å°è¯•æå–åºå·å’Œå†…å®¹
                    match = re.match(r'(\d+)[\.,ã€]\s*(.*)', line)
                    if match:
                        idx = match.group(1)
                        content = match.group(2)
                        length = len(content)
                        warning = "âš ï¸ è¶…æ—¶" if length > max_chars else "æ­£å¸¸"
                        data.append({
                            "åºå·": idx,
                            "åˆ†é•œå†…å®¹": content,
                            "å­—æ•°": length,
                            "æ—¶é•¿é¢„è­¦": warning
                        })
                
                if data:
                    st.dataframe(
                        data, 
                        column_config={
                            "åºå·": st.column_config.TextColumn("åºå·", width="small"),
                            "åˆ†é•œå†…å®¹": st.column_config.TextColumn("å†…å®¹é¢„è§ˆ", width="large"),
                            "å­—æ•°": st.column_config.NumberColumn("å­—æ•°"),
                            "æ—¶é•¿é¢„è­¦": st.column_config.TextColumn("çŠ¶æ€")
                        },
                        use_container_width=True
                    )
                else:
                    st.warning("ç”Ÿæˆæ ¼å¼å¼‚å¸¸ï¼Œæœªèƒ½è‡ªåŠ¨è§£æè¡¨æ ¼ï¼Œè¯·æ£€æŸ¥æ¨¡å‹è¾“å‡ºã€‚")

else:
    st.info("ğŸ‘ˆ è¯·ä¸Šä¼ ä¸€ä¸ª txt æ–‡ä»¶å¼€å§‹å·¥ä½œ")
