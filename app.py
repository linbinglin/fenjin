import streamlit as st
from openai import OpenAI
import re
import time
import math

# ====================
# 1. é¡µé¢é…ç½®ä¸æ ·å¼
# ====================
st.set_page_config(
    page_title="å…¨èƒ½æ–‡æ¡ˆÂ·ç”µå½±æ„Ÿåˆ†é•œç³»ç»Ÿ (V13 Stable)",
    page_icon="ğŸ¬",
    layout="wide"
)

st.markdown("""
<style>
    .main-header {font-size: 2rem; font-weight: bold; margin-bottom: 1rem;}
    .stat-box {
        background-color: #f8f9fa;
        padding: 20px;
        border-radius: 8px;
        text-align: center;
        border: 1px solid #e0e0e0;
        box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }
    .stat-value {font-size: 2.2rem; font-weight: bold; color: #333;}
    .stat-label {font-size: 0.9rem; color: #666; margin-top: 5px;}
    textarea {
        font-family: 'Courier New', Courier, monospace; 
        font-size: 16px !important;
    }
    .stProgress > div > div > div > div {
        background-color: #00CC66;
    }
</style>
""", unsafe_allow_html=True)

# ====================
# 2. ä¾§è¾¹æ é…ç½®
# ====================
with st.sidebar:
    st.markdown("### âš™ï¸ å¯¼æ¼”å¼•æ“ V13 è®¾ç½®")
    api_key = st.text_input("API Key", type="password")
    base_url = st.text_input("æ¥å£åœ°å€ (Base URL)", value="https://blog.tuiwen.xyz/v1")
    
    model_options = ["deepseek-chat", "gpt-4o", "claude-3-5-sonnet", "gemini-pro", "grok-beta", "è‡ªå®šä¹‰"]
    selected_model = st.selectbox("Model ID (æ¨¡å‹é€‰æ‹©)", model_options)
    
    if selected_model == "è‡ªå®šä¹‰":
        model_id = st.text_input("è¯·è¾“å…¥è‡ªå®šä¹‰æ¨¡å‹åç§°", value="grok-4.1")
    else:
        model_id = selected_model
        
    st.info("â„¹ï¸ V13æ›´æ–°ï¼šå·²å¯ç”¨å¼ºåˆ¶åˆ‡ç‰‡æ¨¡å¼ï¼Œå½»åº•è§£å†³é•¿æ–‡æˆªæ–­é—®é¢˜ã€‚")

# ====================
# 3. æ ¸å¿ƒå·¥å…·å‡½æ•°
# ====================

def clean_text_for_count(text):
    """çº¯å‡€å­—æ•°ç»Ÿè®¡ï¼ˆå»é™¤æ‰€æœ‰æ ‡ç‚¹ç¬¦å·å’Œç©ºæ ¼ï¼‰"""
    if not text: return ""
    pattern = re.compile(r'[^\u4e00-\u9fa5a-zA-Z0-9]')
    return re.sub(pattern, '', text)

def safe_split_text(text, limit=600):
    """
    ã€å¼ºåˆ¶åˆ†å—ç®—æ³• V2ã€‘
    ä¼˜å…ˆæŒ‰æ ‡ç‚¹åˆ‡åˆ†ï¼Œå¦‚æœå•å¥è¿‡é•¿æˆ–æ‰¾ä¸åˆ°æ ‡ç‚¹ï¼Œåˆ™å¼ºåˆ¶æŒ‰é•¿åº¦åˆ‡åˆ†ã€‚
    ç¡®ä¿ä¸ä¼šå› ä¸ºä¸€æ®µè¯å¤ªé•¿å¯¼è‡´åªæœ‰ 1 ä¸ª chunkã€‚
    """
    chunks = []
    current_chunk = ""
    
    # 1. é¢„å¤„ç†ï¼šå°†å¸¸è§çš„ç»“æŸæ ‡ç‚¹ç»Ÿä¸€æ›¿æ¢ï¼Œæ–¹ä¾¿åˆ‡å‰²
    # ä¿æŠ¤æ€§æ›¿æ¢ï¼Œé˜²æ­¢ split æ¶ˆè€—æ‰æ ‡ç‚¹
    text = text.replace("ã€‚", "ã€‚|").replace("ï¼", "ï¼|").replace("ï¼Ÿ", "ï¼Ÿ|").replace("\n", "|")
    
    # 2. åˆæ­¥åˆ‡å‰²
    sentences = text.split("|")
    
    for sentence in sentences:
        if not sentence: continue
        
        # å¦‚æœå½“å‰å— + æ–°å¥å­ è¶…è¿‡é™åˆ¶ï¼Œå°±å°åŒ…
        if len(current_chunk) + len(sentence) > limit:
            if current_chunk:
                chunks.append(current_chunk)
                current_chunk = ""
            
            # æç«¯æƒ…å†µï¼šå¦‚æœå•å¥æœ¬èº«å°±è¶…è¿‡ limit (æ¯”å¦‚500å­—æ²¡æ ‡ç‚¹)ï¼Œå¼ºåˆ¶åˆ‡æ–­
            if len(sentence) > limit:
                # å¼ºåˆ¶åˆ‡ç‰‡
                for i in range(0, len(sentence), limit):
                    chunks.append(sentence[i:i+limit])
            else:
                current_chunk = sentence
        else:
            current_chunk += sentence
            
    if current_chunk:
        chunks.append(current_chunk)
        
    return chunks

def process_chunk_with_retry(client, model, text_chunk, chunk_index, total_chunks):
    """
    å•ä¸ªåˆ†å—å¤„ç†ï¼Œå¢åŠ é‡è¯•æœºåˆ¶
    """
    system_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„æ–‡æ¡ˆåˆ†é•œå‘˜ã€‚è¯·å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œåˆ†é•œå¤„ç†ã€‚

ã€é‡è¦æŒ‡ä»¤ã€‘ï¼š
1. **å¿…é¡»æ— æŸè¿˜åŸ**ï¼šä¸å¾—åˆ å‡åŸæ–‡ä»»ä½•æ–‡å­—ï¼Œä¸å¾—æ€»ç»“ï¼Œä¸å¾—æ·»åŠ åŸæ–‡æ²¡æœ‰çš„æè¿°ã€‚
2. **åˆå¹¶çŸ­å¥**ï¼šè¯·å°½é‡å°†åŒä¸€åœºæ™¯ä¸‹çš„åŠ¨ä½œå’ŒçŸ­å¯¹è¯åˆå¹¶ï¼Œæ¯è¡Œåˆ†é•œæ§åˆ¶åœ¨ **30-45ä¸ªå­—ç¬¦**ã€‚
3. **æ ¼å¼ä¸¥æ ¼**ï¼šæ¯è¡Œä»¥æ•°å­—å¼€å¤´ï¼Œçº¯æ–‡æœ¬è¾“å‡ºã€‚
   ä¾‹å¦‚ï¼š
   1.8å²é‚£å¹´å®¶é‡Œç©·å¾—æ­ä¸å¼€é”…äº†
   2.æ€€å­•çš„æ¯äº²å¸¦ç€æˆ‘åœ¨å¯ºå¤–ä¹è®¨

ã€å½“å‰è¿›åº¦ã€‘ï¼š
è¿™æ˜¯å…¨ç¯‡æ–‡æ¡ˆçš„ç¬¬ {chunk_index + 1} / {total_chunks} éƒ¨åˆ†ã€‚è¯·åªå¤„ç†è¿™éƒ¨åˆ†æ–‡æœ¬ï¼Œä¸è¦è‡ªè¡Œç»“æŸæ•…äº‹ã€‚

å¾…å¤„ç†æ–‡æœ¬ï¼š
"""
    
    max_retries = 3
    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": text_chunk}
                ],
                stream=False,
                temperature=0.3 # ä½æ¸©ä¿è¯å‡†ç¡®æ€§
            )
            content = response.choices[0].message.content
            if content:
                return content
        except Exception as e:
            if attempt == max_retries - 1:
                return f"Error: {e}"
            time.sleep(2)
    return "Error: Timeout"

# ====================
# 4. ä¸»é€»è¾‘
# ====================

st.markdown('<div class="main-header">ğŸ¬ å…¨èƒ½æ–‡æ¡ˆÂ·ç”µå½±æ„Ÿåˆ†é•œç³»ç»Ÿ (V13 Stable)</div>', unsafe_allow_html=True)

uploaded_file = st.file_uploader("ğŸ“‚ é€‰æ‹© TXT æ–‡æ¡ˆ", type=['txt'])

if uploaded_file and api_key:
    raw_content = uploaded_file.read().decode("utf-8")
    # å»é™¤åŸæ–‡æ¢è¡Œï¼Œå¼ºåˆ¶å˜ä¸ºä¸€æ•´æ®µï¼Œäº¤ç»™ç®—æ³•é‡æ–°åˆ‡å‰²
    clean_input = raw_content.replace("\n", "").replace("\r", "").strip()
    
    # åŸæ–‡ç»Ÿè®¡
    original_clean_len = len(clean_text_for_count(clean_input))
    
    st.info(f"ğŸ“„ åŸæ–‡å·²åŠ è½½ï¼Œå…± {len(clean_input)} å­—ç¬¦ã€‚æ­£åœ¨å‡†å¤‡åˆ†å—å¤„ç†...")

    if st.button("ğŸš€ å¯åŠ¨è§†è§‰æ— æŸåˆ†é•œ", type="primary"):
        
        # 1. å¼ºåˆ¶åˆ†å— (å…³é”®æ­¥éª¤)
        # è®¾å®š limit=600ï¼Œä¿è¯7000å­—è‡³å°‘ä¼šè¢«åˆ‡æˆ 12-13 å—
        chunks = safe_split_text(clean_input, limit=600)
        total_chunks = len(chunks)
        
        # è¿›åº¦æ˜¾ç¤ºåŒº
        progress_bar = st.progress(0)
        status_box = st.empty()
        result_area = st.empty()
        
        full_result_lines = []
        client = OpenAI(api_key=api_key, base_url=base_url)
        
        start_time = time.time()
        
        # 2. é€å—å¤„ç†
        for i, chunk in enumerate(chunks):
            status_box.markdown(f"""
            ### ğŸ”„ æ­£åœ¨å¤„ç†ç¬¬ {i+1} / {total_chunks} å‰§æƒ…å—
            - å½“å‰å—å­—æ•°ï¼š{len(chunk)}
            - å·²ç”Ÿæˆåˆ†é•œï¼š{len(full_result_lines)} ç»„
            """)
            
            chunk_result = process_chunk_with_retry(client, model_id, chunk, i, total_chunks)
            
            if "Error" in chunk_result:
                st.error(f"å¤„ç†ç¬¬ {i+1} å—æ—¶å¤±è´¥: {chunk_result}")
                break
            
            # æ¸…æ´—æ¯ä¸€å—çš„ç»“æœ (å»æ‰AIç”Ÿæˆçš„åºå·ï¼Œé˜²æ­¢æ–­å±‚)
            lines = chunk_result.split('\n')
            for line in lines:
                # æ­£åˆ™ï¼šå»æ‰è¡Œé¦–çš„ "1." "1ã€" ç­‰
                clean_line = re.sub(r'^\d+[.ã€]\s*', '', line).strip()
                if clean_line:
                    full_result_lines.append(clean_line)
            
            # å®æ—¶æ›´æ–°è¿›åº¦æ¡
            progress_bar.progress((i + 1) / total_chunks)
            
        # 3. æœ€ç»ˆæ±‡æ€»
        if full_result_lines:
            # è‡ªåŠ¨é‡æ–°ç¼–å·
            final_output = ""
            final_clean_text = ""
            for idx, line in enumerate(full_result_lines):
                final_output += f"{idx + 1}.{line}\n"
                final_clean_text += line
                
            final_clean_len = len(clean_text_for_count(final_clean_text))
            deviation = final_clean_len - original_clean_len
            
            # ä¿å­˜åˆ° session
            st.session_state['result'] = final_output
            st.session_state['orig_len'] = original_clean_len
            st.session_state['final_len'] = final_clean_len
            st.session_state['deviation'] = deviation
            st.session_state['shots'] = len(full_result_lines)
            st.session_state['chunks'] = total_chunks
            
            status_box.empty()
            st.rerun()

# ====================
# 5. ç»“æœå±•ç¤º
# ====================

if 'result' in st.session_state:
    result = st.session_state['result']
    orig_len = st.session_state['orig_len']
    final_len = st.session_state['final_len']
    deviation = st.session_state['deviation']
    shots = st.session_state['shots']
    chunks = st.session_state['chunks']

    st.markdown("---")
    st.success(f"âœ… å¤„ç†å®Œæˆï¼å·²å°† {orig_len} å­—æ‹†åˆ†ä¸º {chunks} ä¸ªç‹¬ç«‹å‰§æƒ…å—è¿›è¡Œå¤„ç†ã€‚")
    st.progress(1.0)

    # æ•°æ®é¢æ¿
    c1, c2, c3, c4 = st.columns(4)
    with c1:
        st.markdown(f'<div class="stat-box"><div class="stat-label">åŸæ–‡çº¯å­—æ•°</div><div class="stat-value">{orig_len}</div></div>', unsafe_allow_html=True)
    with c2:
        st.markdown(f'<div class="stat-box"><div class="stat-label">ç”Ÿæˆåˆ†é•œæ€»æ•°</div><div class="stat-value">{shots} ç»„</div></div>', unsafe_allow_html=True)
    with c3:
        st.markdown(f'<div class="stat-box"><div class="stat-label">å¤„ç†åçº¯å­—æ•°</div><div class="stat-value">{final_len}</div></div>', unsafe_allow_html=True)
    with c4:
        # åå·®é¢œè‰²é€»è¾‘
        if deviation == 0:
            color = "#28a745" # Green
            msg = "å®Œç¾æ— æŸ"
        elif abs(deviation) < 50:
            color = "#ffc107" # Yellow
            msg = "è½»å¾®åå·®"
        else:
            color = "#dc3545" # Red
            msg = "ä¸¥é‡åå·®"
            
        st.markdown(f'<div class="stat-box"><div class="stat-label">åå·®å€¼ ({msg})</div><div class="stat-value" style="color:{color}">{deviation} å­—</div></div>', unsafe_allow_html=True)

    if abs(deviation) > 100:
        st.error(f"âš ï¸ ä¾ç„¶å­˜åœ¨å­—æ•°åå·®ï¼Ÿå»ºè®®ï¼šå°è¯•æ›´æ¢æ¨¡å‹ï¼ˆæ¨èä½¿ç”¨ Claude-3.5 æˆ– GPT-4oï¼‰ï¼Œéƒ¨åˆ†å°å‚æ•°æ¨¡å‹åœ¨é•¿æ–‡æœ¬å¤„ç†æ—¶å®¹æ˜“ä¸¢å­—ã€‚")

    st.markdown("### ğŸ“ è§†è§‰åˆ†é•œç¼–è¾‘å™¨ (æ— æŸè¿˜åŸ)")
    st.text_area("ç”Ÿæˆç»“æœ", value=result, height=800)
    
    st.download_button("ğŸ“¥ ä¸‹è½½åˆ†é•œè„šæœ¬", result, "storyboard_v13.txt")
