import streamlit as st
from openai import OpenAI
import re

# ================= é¡µé¢é…ç½® =================
st.set_page_config(
    page_title="AI åˆ†é•œåˆ†æ‰¹ç”Ÿæˆå™¨",
    page_icon="ğŸ¬",
    layout="wide"
)

# ================= Session State åˆå§‹åŒ– (ç”¨äºè®°å¿†çŠ¶æ€) =================
if 'processed_result' not in st.session_state:
    st.session_state.processed_result = ""  # å­˜å‚¨å·²ç”Ÿæˆçš„æœ€ç»ˆç»“æœ
if 'current_index' not in st.session_state:
    st.session_state.current_index = 0      # å½“å‰å¤„ç†åˆ°ç¬¬å‡ ä¸ªåˆ†é•œ
if 'source_scenes' not in st.session_state:
    st.session_state.source_scenes = []     # æ‹†è§£åçš„æºæ–‡æ¡ˆåˆ—è¡¨
if 'is_processing' not in st.session_state:
    st.session_state.is_processing = False

# ================= ä¾§è¾¹æ è®¾ç½® =================
with st.sidebar:
    st.title("âš™ï¸ å‚æ•°è®¾ç½®")
    
    st.subheader("1. æ¥å£é…ç½®")
    api_base = st.text_input(
        "Base URL", 
        value="https://blog.tuiwen.xyz/v1", 
        help="ç¬¬ä¸‰æ–¹ä¸­è½¬åœ°å€ï¼Œæœ«å°¾é€šå¸¸éœ€è¦/v1"
    )
    api_key = st.text_input("API Key", type="password")
    
    st.subheader("2. æ¨¡å‹é€‰æ‹©")
    # æ”¯æŒè‡ªå®šä¹‰æ¨¡å‹IDï¼Œä¼˜å…ˆè¯»å–æ‰‹åŠ¨è¾“å…¥
    model_options = ["gpt-4o", "claude-3-5-sonnet-20240620", "deepseek-chat", "gemini-pro"]
    selected_model = st.selectbox("é¢„è®¾æ¨¡å‹", model_options)
    custom_model = st.text_input("æˆ–æ‰‹åŠ¨è¾“å…¥ Model ID", placeholder="ä¾‹å¦‚: gpt-4o-2024-08-06")
    final_model = custom_model if custom_model else selected_model
    
    st.divider()
    
    st.subheader("3. æ‰¹å¤„ç†æ§åˆ¶")
    batch_size = st.slider(
        "æ¯æ¬¡è®©AIå¤„ç†å‡ ä¸ªåˆ†é•œï¼Ÿ", 
        min_value=1, 
        max_value=10, 
        value=3, 
        help="å»ºè®®è®¾ä¸º3-5ä¸ªã€‚æ•°é‡è¶Šå°‘ï¼ŒAIæè¿°è¶Šè¯¦ç»†ï¼Œä¸æ˜“å·æ‡’ï¼›æ•°é‡è¶Šå¤šï¼Œé€Ÿåº¦è¶Šå¿«ä½†å®¹æ˜“ç®€ç•¥ã€‚"
    )

    st.divider()
    st.subheader("4. è§’è‰²è®¾å®š (å¿…é¡»)")
    character_profile = st.text_area(
        "äººç‰©å°ä¼ /å¤–è²Œæå†™",
        height=200,
        placeholder="èµµæ¸…æœˆï¼šæ¸…å†·ç¾äººï¼Œä¸€èº«ç™½è‰²åˆºç»£ç»«ç½—çº±è¡£...\nèµµçµæ›¦ï¼šæ˜è‰³å¼ æ‰¬ï¼Œé»„è‰²å¦†èŠ±è¥¦è£™..."
    )

# ================= æ ¸å¿ƒå‡½æ•° =================

def parse_source_text(text):
    """
    æ™ºèƒ½è§£æä¸Šä¼ çš„æ–‡æœ¬ï¼Œå°è¯•æŒ‰åºå·æ‹†åˆ†ä¸ºåˆ—è¡¨ã€‚
    æ”¯æŒæ ¼å¼ï¼š1. / 1ã€ / NO.1 / 1
    """
    # ç»Ÿä¸€æ¢è¡Œç¬¦
    text = text.replace("\r\n", "\n")
    # æ­£åˆ™ï¼šåŒ¹é…è¡Œé¦–çš„æ•°å­—åŠ æ ‡ç‚¹ï¼Œä¾‹å¦‚ "1." "1ã€" "1 "
    # split ä¼šä¿ç•™åˆ†å‰²ç¬¦ï¼Œæˆ‘ä»¬éœ€è¦é‡æ–°æ‹¼æ¥
    pattern = r'(^|\n)(\d+[.ã€:ï¼š\s])'
    segments = re.split(pattern, text)
    
    scenes = []
    current_scene = ""
    
    for segment in segments:
        if not segment: continue
        # å¦‚æœæ˜¯æ•°å­—å¼€å¤´ï¼ˆåŒ¹é…ç»“æœï¼‰ï¼Œè¯´æ˜æ˜¯æ–°åˆ†é•œçš„å¼€å§‹
        if re.match(r'\d+[.ã€:ï¼š\s]', segment):
             # æŠŠä¹‹å‰çš„å­˜å…¥
            if current_scene.strip():
                scenes.append(current_scene.strip())
            current_scene = segment
        elif segment.strip() == "":
            continue # è·³è¿‡ç©ºè¡Œ
        else:
            # æ‹¼æ¥å†…å®¹
            current_scene += segment
            
    # å­˜å…¥æœ€åä¸€ä¸ª
    if current_scene.strip():
        scenes.append(current_scene.strip())
        
    # å¦‚æœæ­£åˆ™è§£æå¤±è´¥ï¼ˆåˆ—è¡¨ä¸ºç©ºæˆ–åªæœ‰1ä¸ªï¼‰ï¼Œè¯´æ˜ç”¨æˆ·å¯èƒ½æ²¡æ ‡å·ï¼Œå°è¯•æŒ‰ç©ºè¡Œå¼ºè¡Œæ‹†
    if len(scenes) < 2:
        scenes = [line.strip() for line in text.split('\n') if line.strip()]
        
    return scenes

def generate_prompt(batch_scenes, profile):
    """æ„å»ºå‘é€ç»™AIçš„ Prompt"""
    scene_text = "\n\n".join(batch_scenes)
    
    return f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åˆ†é•œå¸ˆã€‚ä½ éœ€è¦å¤„ç†ä»¥ä¸‹ã€åˆ†é•œæ–‡æ¡ˆç‰‡æ®µã€‘ã€‚
è¿™æ˜¯ç”¨æˆ·å·²ç»æ•´ç†å¥½çš„åºå·ï¼Œä½†å¯èƒ½éœ€è¦æ ¹æ®æ—¶é•¿è¿›ä¸€æ­¥æ‹†åˆ†ã€‚

### æ ¸å¿ƒä»»åŠ¡ï¼š
1. **åˆ†ææ–‡æ¡ˆæ—¶é•¿**ï¼šè§†é¢‘ç”Ÿæˆé™åˆ¶æ¯å›¾5ç§’ï¼ˆçº¦40å­—ï¼‰ã€‚å¦‚æœå•æ¡æ–‡æ¡ˆè¿‡é•¿ï¼Œè¯·åœ¨ä¿æŒåŸåºå·åŸºç¡€ä¸Šæ‹†åˆ†ä¸º X-1, X-2ã€‚
2. **ç”»é¢æè¿° (Midjourney)**ï¼šåªæè¿°é™æ€åœºæ™¯ã€äººç‰©çŠ¶æ€ã€æ„å›¾ã€å…‰å½±ã€‚å¿…é¡»åŒ…å«ã€è§’è‰²è®¾å®šã€‘ä¸­çš„å¤–è²ŒTagã€‚ä¸¥ç¦å¤§å¹…åº¦åŠ¨ä½œæå†™ã€‚
3. **è§†é¢‘æè¿° (å³æ¢¦AI)**ï¼šåŸºäºç”»é¢å›¾ï¼Œæè¿°å…·ä½“çš„äººç‰©åŠ¨ä½œã€è¿é•œã€åŠ¨æ€å˜åŒ–ã€‚
4. **ä¸¥æ ¼æ ¼å¼**ï¼šè¯·ç›´æ¥è¾“å‡ºç»“æœï¼Œä¸è¦åºŸè¯ã€‚

### è§’è‰²è®¾å®šï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆå¤–è²Œï¼‰ï¼š
{profile}

### å¾…å¤„ç†çš„åˆ†é•œæ–‡æ¡ˆï¼š
{scene_text}

### è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
NO.1 æ–‡æ¡ˆï¼šxxxx
ç”»é¢æè¿°ï¼š[åœºæ™¯]ï¼Œ[é™æ€çŠ¶æ€]ï¼Œ(è§’è‰²åï¼Œå¤–è²ŒTag...)
è§†é¢‘ç”Ÿæˆï¼š[åŠ¨ä½œ]ï¼Œ[è¿é•œ]
    """

# ================= ä¸»ç•Œé¢é€»è¾‘ =================

st.title("ğŸ¬ AI æ™ºèƒ½åˆ†é•œ - åˆ†æ‰¹ç”Ÿæˆç‰ˆ")
st.markdown("ä¸Šä¼ å·²ç¼–å·çš„åˆ†é•œç¨¿ï¼Œ**åˆ†æ‰¹æ¬¡**å‘é€ç»™AIï¼Œé˜²æ­¢å†…å®¹ä¸­æ–­ï¼Œä¿è¯æ¯ä¸ªé•œå¤´çš„æè¿°è´¨é‡ã€‚")

# 1. æ–‡ä»¶ä¸Šä¼ 
uploaded_file = st.file_uploader("ğŸ“‚ ä¸Šä¼ æ•´ç†å¥½çš„åˆ†é•œ (.txt)", type=["txt"])

if uploaded_file:
    # åªæœ‰å½“æ–‡ä»¶æ”¹å˜æ—¶æ‰é‡æ–°è§£æ
    file_content = uploaded_file.getvalue().decode("utf-8")
    
    # å¦‚æœè¿˜æ²¡æœ‰è§£æè¿‡ï¼Œæˆ–è€…è§£æçš„å†…å®¹ä¸ºç©ºï¼Œåˆ™æ‰§è¡Œè§£æ
    if not st.session_state.source_scenes:
        st.session_state.source_scenes = parse_source_text(file_content)
        st.toast(f"âœ… æˆåŠŸè§£æå‡º {len(st.session_state.source_scenes)} ä¸ªåˆ†é•œç‰‡æ®µ", icon="ğŸ‰")

    # æ˜¾ç¤ºè§£ææ¦‚å†µ
    total_scenes = len(st.session_state.source_scenes)
    progress = st.session_state.current_index / total_scenes if total_scenes > 0 else 0
    
    st.write(f"ğŸ“Š å½“å‰è¿›åº¦ï¼š**{st.session_state.current_index} / {total_scenes}**")
    st.progress(progress)

    # 2. ç”Ÿæˆæ§åˆ¶åŒº
    col1, col2 = st.columns([1, 2])
    
    with col1:
        # åˆ¤æ–­æ˜¯å¦å…¨éƒ¨å®Œæˆ
        if st.session_state.current_index < total_scenes:
            btn_label = "ğŸš€ å¼€å§‹ç”Ÿæˆ" if st.session_state.current_index == 0 else "â­ï¸ ç»§ç»­ç”Ÿæˆä¸‹ä¸€æ‰¹"
            if st.button(btn_label, type="primary"):
                if not api_key or not character_profile:
                    st.error("è¯·å…ˆåœ¨å·¦ä¾§å¡«å†™ API Key å’Œ è§’è‰²è®¾å®šï¼")
                else:
                    # å‡†å¤‡å½“å‰æ‰¹æ¬¡çš„æ•°æ®
                    start_idx = st.session_state.current_index
                    end_idx = min(start_idx + batch_size, total_scenes)
                    current_batch = st.session_state.source_scenes[start_idx:end_idx]
                    
                    # è°ƒç”¨ AI
                    client = OpenAI(api_key=api_key, base_url=api_base)
                    
                    user_prompt = generate_prompt(current_batch, character_profile)
                    
                    st.session_state.is_processing = True
                    
                    try:
                        # æ˜¾ç¤ºæ­£åœ¨å¤„ç†çš„å†…å®¹
                        with st.spinner(f"æ­£åœ¨åˆ†æç¬¬ {start_idx+1} åˆ° {end_idx} ä¸ªåˆ†é•œ..."):
                            response_container = st.empty()
                            full_response = ""
                            
                            stream = client.chat.completions.create(
                                model=final_model,
                                messages=[
                                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„AIåˆ†é•œåŠ©æ‰‹ï¼Œä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·è¦æ±‚è¾“å‡ºæ ¼å¼ã€‚"},
                                    {"role": "user", "content": user_prompt}
                                ],
                                stream=True,
                                temperature=0.7
                            )
                            
                            # æµå¼è¾“å‡ºå½“å‰æ‰¹æ¬¡ç»“æœ
                            for chunk in stream:
                                if chunk.choices[0].delta.content:
                                    content = chunk.choices[0].delta.content
                                    full_response += content
                                    response_container.markdown(f"**å½“å‰æ‰¹æ¬¡é¢„è§ˆï¼š**\n\n{full_response}")
                            
                            # è¿½åŠ åˆ°æ€»ç»“æœä¸­
                            st.session_state.processed_result += f"\n\n--- æ‰¹æ¬¡ ({start_idx+1}-{end_idx}) ---\n\n" + full_response
                            
                            # æ›´æ–°ç´¢å¼•
                            st.session_state.current_index = end_idx
                            st.rerun() # åˆ·æ–°é¡µé¢æ›´æ–°è¿›åº¦æ¡å’ŒæŒ‰é’®çŠ¶æ€
                            
                    except Exception as e:
                        st.error(f"å‘ç”Ÿé”™è¯¯: {str(e)}")
        else:
            st.success("ğŸ‰ æ‰€æœ‰åˆ†é•œå·²å…¨éƒ¨å¤„ç†å®Œæ¯•ï¼")
            if st.button("ğŸ”„ é‡ç½®æ‰€æœ‰è¿›åº¦"):
                st.session_state.current_index = 0
                st.session_state.processed_result = ""
                st.rerun()

    # 3. ç»“æœå±•ç¤ºåŒº
    st.divider()
    st.subheader("ğŸ“ æœ€ç»ˆå®Œæ•´ç»“æœ")
    
    # æä¾›ä¸‹è½½æŒ‰é’®
    st.download_button(
        label="ğŸ’¾ ä¸‹è½½å®Œæ•´åˆ†é•œæè¿° (.txt)",
        data=st.session_state.processed_result,
        file_name="ai_storyboard_output.txt",
        mime="text/plain"
    )
    
    # æ˜¾ç¤ºæ–‡æœ¬æ¡†ï¼ˆåªè¯»ï¼‰
    st.text_area(
        "ç»“æœé¢„è§ˆï¼ˆå¯æ‰‹åŠ¨ç¼–è¾‘å¤åˆ¶ï¼‰", 
        value=st.session_state.processed_result, 
        height=600
    )

else:
    st.info("ğŸ‘ˆ è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼ æ–‡æ¡ˆæ–‡ä»¶")
