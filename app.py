import streamlit as st
from openai import OpenAI
import re

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="AI ç”µå½±è§£è¯´åˆ†é•œåŠ©æ‰‹",
    page_icon="ğŸ¬",
    layout="wide"
)

# --- è¾…åŠ©å‡½æ•°ï¼šè®¡ç®—å­—æ•°ï¼ˆä¸å«æ ‡ç‚¹ï¼‰ ---
def count_valid_chars(text):
    """
    ç»Ÿè®¡æ–‡æœ¬ä¸­çš„æœ‰æ•ˆå­—ç¬¦æ•°ï¼ˆæ±‰å­—ã€å­—æ¯ã€æ•°å­—ï¼‰ï¼Œæ’é™¤æ ‡ç‚¹ç¬¦å·å’Œç©ºæ ¼ã€‚
    """
    if not text:
        return 0
    # ä½¿ç”¨æ­£åˆ™æ›¿æ¢æ‰æ‰€æœ‰æ ‡ç‚¹ç¬¦å·å’Œç©ºç™½å­—ç¬¦
    # \w åŒ¹é…å­—æ¯æ•°å­—ä¸‹åˆ’çº¿ï¼Œ\u4e00-\u9fa5 åŒ¹é…æ±‰å­—
    # åå‘é€»è¾‘ï¼šå°†ä¸æ˜¯æ±‰å­—ã€å­—æ¯ã€æ•°å­—çš„å†…å®¹æ›¿æ¢ä¸ºç©º
    clean_text = re.sub(r'[^\w\u4e00-\u9fa50-9]', '', text)
    return len(clean_text)

# --- ä¾§è¾¹æ ï¼šé…ç½®è®¾ç½® ---
st.sidebar.header("âš™ï¸ å‚æ•°é…ç½®")

# 1. API é…ç½®
base_url = st.sidebar.text_input(
    "API Base URL (ä¸­è½¬æ¥å£åœ°å€)", 
    value="https://blog.tuiwen.xyz/v1",
    help="è¯·å¡«å†™Base URLï¼Œé€šå¸¸ä»¥ /v1 ç»“å°¾ã€‚æ³¨æ„ï¼šä»£ç ä¼šè‡ªåŠ¨è¿½åŠ  /chat/completions"
)

api_key = st.sidebar.text_input(
    "API Key (å¯†é’¥)", 
    type="password",
    help="è¯·è¾“å…¥æ‚¨çš„ API Key"
)

# 2. æ¨¡å‹é€‰æ‹© (é‡ç‚¹éœ€æ±‚ 2 & 3)
model_id = st.sidebar.text_input(
    "Model ID (æ¨¡å‹åç§°)", 
    value="gpt-4o",
    placeholder="ä¾‹å¦‚: gpt-4o, deepseek-chat, claude-3-5-sonnet",
    help="è¯·è¾“å…¥æ‚¨æƒ³ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼Œæ”¯æŒ DeepSeek, GPT-4o, Claude ç­‰"
)

# --- ä¸»ç•Œé¢ ---
st.title("ğŸ¬ AI ç”µå½±è§£è¯´åˆ†é•œç”Ÿæˆå™¨")
st.markdown("### é€å­—é€å¥åˆ†æï¼Œç²¾å‡†å¡ç‚¹ 5 ç§’åˆ†é•œ")

# 1. æ–‡ä»¶ä¸Šä¼  (ä»£ç è¦æ±‚ 1)
uploaded_file = st.file_uploader("ğŸ“‚ é€‰æ‹©æœ¬åœ° TXT æ–‡æ¡£", type=["txt"])

if uploaded_file is not None:
    # è¯»å–æ–‡ä»¶
    raw_text = uploaded_file.read().decode("utf-8")
    
    # --- é¢„å¤„ç†ï¼šåˆ é™¤åŸæ®µè½ (é‡ç‚¹éœ€æ±‚ 7) ---
    # å°†æ–‡æœ¬å‹ç¼©æˆä¸€è¡Œï¼Œé˜²æ­¢ AI å·æ‡’ç›´æ¥ç”¨åŸæ–‡æ®µè½
    flattened_text = raw_text.replace('\n', '').replace('\r', '').strip()
    
    # ç»Ÿè®¡åŸæ–‡æœ‰æ•ˆå­—æ•°
    input_count = count_valid_chars(flattened_text)

    # --- æ˜¾ç¤ºåŸæ–‡ä¿¡æ¯é¢æ¿ (æ–°å¢åŠŸèƒ½) ---
    st.info(f"ğŸ“„ åŸæ–‡å·²åŠ è½½ | æœ‰æ•ˆå­—æ•° (ä¸å«æ ‡ç‚¹): **{input_count}** å­—")
    
    with st.expander("ç‚¹å‡»æŸ¥çœ‹å¤„ç†å‰çš„â€œè¢«å‹ç¼©â€åŸæ–‡ (ç”¨äºé˜²AIå·æ‡’)"):
        st.write(flattened_text)

    # ç”ŸæˆæŒ‰é’®
    if st.button("ğŸš€ å¼€å§‹ç”Ÿæˆåˆ†é•œ", type="primary"):
        if not api_key:
            st.error("âŒ è¯·åœ¨å·¦ä¾§ä¾§è¾¹æ è¾“å…¥ API Key")
            st.stop()
        
        if not flattened_text:
            st.error("âŒ æ–‡æœ¬å†…å®¹ä¸ºç©º")
            st.stop()

        # --- æ„å»º Prompt (æ ¸å¿ƒé€»è¾‘) ---
        # ä¸¥æ ¼æŒ‰ç…§ä½ çš„ 1-8 ç‚¹éœ€æ±‚ç¼–å†™ Prompt
        system_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¼˜ç§€çš„ç”µå½±è§£è¯´åˆ†é•œå‘˜ã€‚è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„æ–‡æœ¬ç”Ÿæˆåˆ†é•œè„šæœ¬ã€‚

ã€é‡è¦åŸåˆ™ã€‘
1. **å®Œæ•´æ€§**ï¼šæ•´ç†åçš„å†…å®¹ä¸å¯é—æ¼åŸæ–‡ä¸­çš„ä»»ä½•ä¸€å¥è¯ï¼Œä¸€ä¸ªå­—ã€‚ä¸èƒ½æ”¹å˜åŸæ–‡æ•…äº‹ç»“æ„ï¼Œç¦æ­¢æ·»åŠ åŸæ–‡ä»¥å¤–ä»»ä½•å†…å®¹ã€‚
2. **æ—¶é•¿æ§åˆ¶**ï¼šå¿…é¡»è€ƒè™‘åˆ°é…éŸ³æ—¶é•¿ã€‚ä¸€ä¸ªåˆ†é•œåªèƒ½åœç•™äº”ç§’é’Ÿï¼Œçº¦35ä¸ªå­—ç¬¦ã€‚å¦‚æœåŸæ–‡å¥å­è¿‡é•¿ï¼Œå¿…é¡»å¼ºè¡Œæ‹†åˆ†æˆä¸‹ä¸€è¡Œåˆ†é•œã€‚
3. **åˆ†æ®µé€»è¾‘**ï¼š
   - è§’è‰²å¯¹è¯åˆ‡æ¢ -> ä¸‹ä¸€ä¸ªåˆ†é•œ
   - åœºæ™¯åˆ‡æ¢ -> ä¸‹ä¸€ä¸ªåˆ†é•œ
   - åŠ¨ä½œç”»é¢æ”¹å˜ -> ä¸‹ä¸€ä¸ªåˆ†é•œ
   - å•å¥è¶…è¿‡35å­— -> ä¸‹ä¸€ä¸ªåˆ†é•œ

ã€è¾“å‡ºæ ¼å¼ã€‘
è¯·ç›´æ¥è¾“å‡ºåˆ†é•œåˆ—è¡¨ï¼Œæ ¼å¼å¦‚ä¸‹ï¼ˆçº¯æ•°å­—åŠ ç‚¹ï¼‰ï¼š
1.ç¬¬ä¸€æ®µæ–‡æ¡ˆ
2.ç¬¬äºŒæ®µæ–‡æ¡ˆ
...

ã€å¾…å¤„ç†æ–‡æœ¬ã€‘
{flattened_text}

è¯·æ³¨æ„ï¼šç”¨æˆ·ä¸Šä¼ çš„æ–‡æœ¬å·²ç»å»é™¤äº†æ®µè½ï¼Œä½ éœ€è¦æ ¹æ®è¯­ä¹‰é‡æ–°ç†è§£å¹¶æŒ‰ç…§ä¸Šè¿°é€»è¾‘è¿›è¡Œâ€œå¾®åˆ›â€åˆ†æ®µã€‚
"""

        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        client = OpenAI(api_key=api_key, base_url=base_url)
        
        st.divider()
        st.subheader("ğŸ¥ åˆ†é•œç”Ÿæˆç»“æœ")
        
        result_container = st.empty()
        full_response = ""

        try:
            # æµå¼è¾“å‡º (Streamlit Cloud ä½“éªŒæ›´å¥½)
            stream = client.chat.completions.create(
                model=model_id,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„ç”µå½±åˆ†é•œä¸æ—¶åºæ§åˆ¶ä¸“å®¶ã€‚"},
                    {"role": "user", "content": system_prompt}
                ],
                stream=True,
                temperature=0.7 # ç¨å¾®é™ä½åˆ›é€ æ€§ï¼Œä¿è¯å¿ å®åŸæ–‡
            )

            # æ¥æ”¶æµ
            for chunk in stream:
                if chunk.choices[0].delta.content is not None:
                    content = chunk.choices[0].delta.content
                    full_response += content
                    result_container.markdown(full_response)
            
            # --- åå¤„ç†ï¼šç»“æœå­—æ•°ç»Ÿè®¡ (æ–°å¢åŠŸèƒ½) ---
            # å»æ‰åºå· (1. 2. ç­‰) å†ç»Ÿè®¡ï¼Œä»¥å…å½±å“å­—æ•°å¯¹æ¯”
            # æ­£åˆ™ï¼šå»é™¤è¡Œé¦–çš„æ•°å­—å’Œç‚¹
            content_for_count = re.sub(r'^\d+\.', '', full_response, flags=re.MULTILINE)
            output_count = count_valid_chars(content_for_count)
            
            # --- ç»“æœå¯¹æ¯”é¢æ¿ ---
            st.divider()
            col1, col2, col3 = st.columns(3)
            col1.metric("åŸæ–‡æœ‰æ•ˆå­—æ•°", input_count)
            col2.metric("åˆ†é•œæœ‰æ•ˆå­—æ•°", output_count)
            
            diff = output_count - input_count
            if diff == 0:
                col3.success("âœ… å­—æ•°å®Œç¾åŒ¹é…")
            elif abs(diff) < 5:
                col3.warning(f"âš ï¸ å·®å¼‚å¾®å° ({diff}å­—)")
            else:
                col3.error(f"âŒ å­—æ•°å·®å¼‚è¾ƒå¤§ ({diff}å­—)ï¼Œè¯·æ£€æŸ¥AIæ˜¯å¦é—æ¼")

        except Exception as e:
            st.error(f"å‘ç”Ÿé”™è¯¯: {str(e)}")
            st.markdown("å»ºè®®æ£€æŸ¥ï¼š\n1. API Key æ˜¯å¦æ­£ç¡®\n2. æ¨¡å‹åç§°æ˜¯å¦å­˜åœ¨\n3. ä½™é¢æ˜¯å¦å……è¶³")
