import streamlit as st
from openai import OpenAI
import io
import re
import pandas as pd

st.set_page_config(page_title="AIç”µå½±è§£è¯´å¯¼æ¼”ç³»ç»Ÿ Pro", layout="wide")

# --- åˆå§‹åŒ–å…¨å±€çŠ¶æ€ ---
if 'raw_stream' not in st.session_state: st.session_state.raw_stream = ""
if 'storyboard_output' not in st.session_state: st.session_state.storyboard_output = ""
if 'batch_results' not in st.session_state: st.session_state.batch_results = []
if 'current_idx' not in st.session_state: st.session_state.current_idx = 0

# --- ä¾§è¾¹æ  ---
st.sidebar.title("ğŸ¬ å¯¼æ¼”å·¥ä½œå°")
api_key = st.sidebar.text_input("è¾“å…¥ API Key", type="password")
base_url = st.sidebar.text_input("æ¥å£åœ°å€", value="https://blog.tuiwen.xyz/v1")
model_id = st.sidebar.text_input("æ¨¡å‹ ID", value="gpt-4o")

st.title("ğŸ“½ï¸ ç”µå½±è§£è¯´å…¨æµç¨‹å¯¼æ¼”åˆ†é•œç³»ç»Ÿ")
st.markdown("---")

# ================= Step 1: ç‰©ç†æ‹†è§£ä¸æ— æŸåˆ†é•œ =================
st.header("Step 1: æ™ºèƒ½æ— æŸåˆ†é•œæ‹†è§£")

uploaded_file = st.file_uploader("ä¸Šä¼ æ–‡æ¡ˆ (TXT)", type=['txt'])

if uploaded_file:
    # ç‰©ç†ç²‰ç¢ï¼šåˆå¹¶ä¸ºä¸€æ¡é•¿å­—ç¬¦æµ
    content = io.StringIO(uploaded_file.getvalue().decode("utf-8")).read()
    clean_stream = re.sub(r'[\s\n\r\t]+', '', content).strip()
    st.session_state.raw_stream = clean_stream
    
    st.info(f"ğŸ“‹ **æ–‡æ¡ˆæŒ‡çº¹å·²é”å®š**ï¼šåŸæ–‡æ€»è®¡ {len(clean_stream)} å­—ï¼ˆå·²ç‰©ç†è„±æ•ï¼‰")

    if st.button("ğŸš€ å¯åŠ¨å¯¼æ¼”æ€ç»´åˆ†é•œ"):
        if not api_key:
            st.error("è¯·é…ç½® API Key")
        else:
            try:
                client = OpenAI(api_key=api_key, base_url=base_url)
                
                # å¼ºåŒ–â€œé›¶å®¹å¿â€æŒ‡ä»¤ï¼šç¦æ­¢æ·»åŠ ä»»ä½•æ–‡å­—
                director_prompt = f"""ä½ ç°åœ¨æ˜¯ä¸€å°é«˜ç²¾åº¦çš„â€œæ–‡æ¡ˆåˆ‡å‰²å¤å°æœºâ€ã€‚
ä½ çš„å”¯ä¸€ä»»åŠ¡æ˜¯å°†ä»¥ä¸‹æ–‡æ¡ˆæµåˆ‡å‰²æˆå¸¦åºå·çš„åˆ†é•œã€‚

### æ ¸å¿ƒåˆ‡å‰²å‡†åˆ™ï¼š
1. **ç¦æ­¢åŸåˆ›**ï¼šä¸¥ç¦æ·»åŠ ã€åˆ é™¤æˆ–ä¿®æ”¹åŸæ–‡ä¸­çš„ä»»ä½•ä¸€ä¸ªå­—ç¬¦ï¼ˆåŒ…æ‹¬æ ‡ç‚¹ï¼‰ã€‚ä½ åªæ˜¯åœ¨æ–‡å­—ä¹‹é—´æ’å…¥æ¢è¡Œã€‚
2. **å¼ºåˆ¶åºå·**ï¼šæ¯ä¸€è¡Œå¿…é¡»ä»¥â€œæ•°å­—.â€å¼€å¤´ï¼Œä¾‹å¦‚ï¼š1.æ–‡æ¡ˆå†…å®¹
3. **åˆ†é•œå­—æ•°å‡è¡¡ï¼ˆ35å­—åŸåˆ™ï¼‰**ï¼š
   - ç›®æ ‡ï¼šæ¯ä¸ªåˆ†é•œæ–‡æ¡ˆçº¦ 25-35 å­—ç¬¦ï¼ˆ5ç§’éŸ³é¢‘ï¼‰ã€‚
   - ç¦æ­¢å¤ªç¢ï¼šå¦‚æœä¸€å¥è¯åªæœ‰å‡ ä¸ªå­—ï¼Œå¿…é¡»ä¸åæ–‡åˆå¹¶ï¼Œç›´åˆ°æ¥è¿‘30å­—å·¦å³ã€‚
   - ç¦æ­¢æ‹¥æŒ¤ï¼šå•è¡Œä¸¥ç¦è¶…è¿‡ 40 å­—ç¬¦ã€‚
4. **è¯­ä¹‰åˆ‡åˆ†**ï¼šä¼˜å…ˆåœ¨åœºæ™¯åˆ‡æ¢ã€å¯¹è¯åˆ‡æ¢ã€ç‹¬ç«‹åŠ¨ä½œå®Œæˆå¤„åˆ‡åˆ†ã€‚

å¾…å¤„ç†æ–‡æ¡ˆæµï¼š
{clean_stream}"""

                with st.spinner("AI æ­£åœ¨é€å­—æ ¸å¯¹å¹¶è¿›è¡Œå™äº‹åˆ‡åˆ†..."):
                    response = client.chat.completions.create(
                        model=model_id,
                        messages=[
                            {"role": "system", "content": "ä½ åªè´Ÿè´£æ— æŸåˆ‡å‰²ï¼Œä¸å‡†è¯´è¯ï¼Œä¸å‡†æ”¹å­—ï¼Œä¸å‡†é—æ¼ã€‚"},
                            {"role": "user", "content": director_prompt}
                        ],
                        temperature=0 # å¼ºåˆ¶ 0 éšæœºæ€§
                    )
                    st.session_state.storyboard_output = response.choices[0].message.content
                    st.session_state.batch_results = []
                    st.session_state.current_idx = 0
            except Exception as e:
                st.error(f"å¤„ç†å¤±è´¥: {str(e)}")

# å±•ç¤ºé¢„è§ˆä¸ç²¾ä¿®
if st.session_state.storyboard_output:
    # 1. ç»Ÿè®¡è§£æ
    lines = [l.strip() for l in st.session_state.storyboard_output.split('\n') if l.strip()]
    total_shots = len(lines)
    
    # 2. æ ¸å¿ƒæ•°æ®çœ‹æ¿
    st.subheader("ğŸ“Š åˆ†é•œå®¡è®¡ä¸­å¿ƒ")
    c1, c2, c3 = st.columns(3)
    
    # è§£æçº¯æ–‡æ¡ˆç”¨äºå­—æ•°æ ¡éªŒ
    recombined_text = ""
    analysis_data = []
    for i, line in enumerate(lines):
        # ä¸¥æ ¼è¿‡æ»¤æ‰åºå·å’Œç‰¹æ®Šå­—ç¬¦å‰ç¼€
        content = re.sub(r'^[\d\s\.ã€\-:ï¼š]+', '', line)
        recombined_text += content
        char_len = len(content)
        # èŠ‚å¥è¯„ä»·
        if char_len > 38: res = "ğŸ”´ å¤ªæ‹¥æŒ¤"
        elif char_len < 18: res = "ğŸŸ¡ ç•¥ç¢"
        else: res = "ğŸŸ¢ ç†æƒ³"
        analysis_data.append({"åºå·": i+1, "å†…å®¹": content[:15]+"...", "å­—æ•°": char_len, "å»ºè®®": res})

    # çœ‹æ¿æŒ‡æ ‡æ˜¾ç¤º
    c1.metric("ğŸ¬ åˆ†é•œæ€»æ•°", f"{total_shots} ç»„")
    
    orig_len = len(st.session_state.raw_stream)
    curr_len = len(recombined_text)
    diff = orig_len - curr_len
    
    if diff == 0:
        c2.metric("ğŸ“‹ å­—æ•°æ ¡éªŒ", f"{curr_len}/{orig_len}", "âœ… æ— æŸ", delta_color="normal")
    else:
        c2.metric("ğŸ“‹ å­—æ•°æ ¡éªŒ", f"{curr_len}/{orig_len}", f"âš ï¸ åå·® {diff} å­—", delta_color="inverse")
    
    c3.metric("â±ï¸ é¢„ä¼°æ€»æ—¶é•¿", f"{int(total_shots * 5 / 60)}åˆ†{int(total_shots * 5 % 60)}ç§’")

    # 3. ç¼–è¾‘ä¸è¯¦ç»†åˆ—è¡¨
    col_edit, col_table = st.columns([2, 1])
    with col_edit:
        st.session_state.storyboard_output = st.text_area("âœï¸ å¯¼æ¼”ç²¾ä¿®åŒºï¼ˆä¿®æ”¹åä¸Šæ–¹çœ‹æ¿ä¼šè‡ªåŠ¨åˆ·æ–°ï¼‰", 
                                                       value=st.session_state.storyboard_output, 
                                                       height=500)
    with col_table:
        st.dataframe(pd.DataFrame(analysis_data), use_container_width=True, height=500)

    st.divider()

    # ================= Step 2: æ·±åº¦è§†è§‰ç”Ÿæˆ =================
    st.header("Step 2: ç”Ÿæˆ AI ç”»é¢ä¸è§†é¢‘è¿åŠ¨æè¿°")
    char_info = st.text_area("1. å½•å…¥æ ¸å¿ƒè§’è‰²è§†è§‰è®¾å®š", 
                            placeholder="æè¿°å¤–è²Œã€è¡£ç€ç­‰ã€‚ä¾‹å¦‚ï¼šæ—å‡¡ï¼šå‰‘çœ‰æ˜Ÿç›®ï¼Œé»‘è‰²æˆ˜æœ¯èƒŒå¿ƒã€‚", 
                            height=100)
    
    if char_info:
        # è·å–çº¯å‡€æ–‡æ¡ˆåˆ—è¡¨
        pure_lines = [re.sub(r'^[\d\s\.ã€\-:ï¼š]+', '', l.strip()) for l in st.session_state.storyboard_output.split('\n') if l.strip()]
        total_len = len(pure_lines)
        p = st.session_state.current_idx
        batch = 20
        end_p = min(p + batch, total_len)

        if p < total_len:
            if st.button(f"ğŸ¨ ç”Ÿæˆç¬¬ {p+1} - {end_p} ç»„æ·±åº¦æè¿°"):
                try:
                    client = OpenAI(api_key=api_key, base_url=base_url)
                    batch_content = "\n".join([f"åˆ†é•œ{p+i+1}: {t}" for i, t in enumerate(pure_lines[p:end_p])])
                    
                    prompt = f"""ä½ ç°åœ¨æ˜¯è§†è§‰å¯¼æ¼”ï¼Œè´Ÿè´£ç”Ÿæˆæç¤ºè¯ã€‚
è§’è‰²è®¾å®šï¼š{char_info}

è¦æ±‚ï¼š
1. **ç”»é¢æè¿° (MJ)**ï¼šæè¿°é™æ€ã€‚è§†è§’ã€åœºæ™¯ã€äººç‰©ç»†èŠ‚ã€å…‰æ•ˆã€‚ç¦æ­¢æè¿°è¡Œä¸ºã€‚
2. **è§†é¢‘ç”Ÿæˆ (å³æ¢¦AI)**ï¼šæè¿°5ç§’å†…çš„åŠ¨ä½œæµã€‚æè¿°å¾®è¡¨æƒ…å’Œè‚¢ä½“ä½ç§»ã€‚çŸ­å¥å †ç Œã€‚
3. **å•ç„¦åŸåˆ™**ï¼šä¸€åˆ†é•œä¸€æ ¸å¿ƒè§†è§‰ã€‚

åˆ†é•œç»„ï¼š
{batch_content}"""

                    with st.spinner("AIæ­£åœ¨æ·±åº¦æ„æ€ç”»é¢ç»†èŠ‚..."):
                        response = client.chat.completions.create(
                            model=model_id,
                            messages=[{"role": "user", "content": prompt}]
                        )
                        st.session_state.batch_results.append(response.choices[0].message.content)
                        st.session_state.current_idx = end_p
                        st.rerun()
                except Exception as e:
                    st.error(f"å¤±è´¥: {e}")
        else:
            st.success("âœ… å…¨éƒ¨æè¿°ç”Ÿæˆå®Œæ¯•")

        for r in st.session_state.batch_results:
            st.markdown(r)
            st.divider()
