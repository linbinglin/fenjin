import streamlit as st
from openai import OpenAI
import re
import pandas as pd

# ==========================================
# ğŸ› ï¸ æ ¸å¿ƒå·¥å…·å‡½æ•°åº“
# ==========================================

def smart_chunk_text(text, max_chars=1500):
    """
    æ™ºèƒ½åˆ†å—ï¼šåŠ å¤§åˆ†å—é˜ˆå€¼ï¼Œè®©AIçœ‹åˆ°æ›´å®Œæ•´çš„ä¸Šä¸‹æ–‡ï¼Œå‡å°‘ç¢ç‰‡åŒ–ã€‚
    """
    chunks = []
    while len(text) > max_chars:
        split_index = -1
        # ä¼˜å…ˆåœ¨æ®µè½æˆ–å¼ºå¥å·å¤„åˆ‡åˆ†
        for mark in ["\n\n", "ã€‚", "ï¼", "ï¼Ÿ"]:
            pos = text.rfind(mark, 0, max_chars)
            split_index = max(split_index, pos)
        
        if split_index == -1:
            split_index = max_chars
        else:
            split_index += 1 
            
        chunks.append(text[:split_index].strip())
        text = text[split_index:]
    if text.strip():
        chunks.append(text.strip())
    return chunks

def get_pure_text(text):
    """æå–çº¯æ–‡æœ¬ï¼ˆå»é™¤åºå·ï¼‰ï¼Œç”¨äºè®¡ç®—å­—æ•°åå·®"""
    text = re.sub(r'^\d+[\.ã€]\s*', '', text, flags=re.MULTILINE)
    return "".join(text.split())

def renumber_content(text):
    """
    åœºè®°ä¿®æ­£é€»è¾‘ï¼šæ¸…æ´—æ—§åºå·ï¼Œé‡æ–°ç¼–å·
    """
    lines = text.split('\n')
    new_lines = []
    counter = 1
    for line in lines:
        stripped = line.strip()
        if not stripped: continue
        clean_content = re.sub(r'^\d+[\.ã€]\s*', '', stripped)
        new_lines.append(f"{counter}. {clean_content}")
        counter += 1
    return "\n".join(new_lines)

# ==========================================
# ğŸ¨ é¡µé¢é…ç½®
# ==========================================
st.set_page_config(page_title="å¯¼æ¼”å¼•æ“ V13-èšåˆä¿®å¤ç‰ˆ", layout="wide", page_icon="ğŸ¬")

if 'generated_storyboard' not in st.session_state:
    st.session_state.generated_storyboard = ""
if 'original_text_len' not in st.session_state:
    st.session_state.original_text_len = 0

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("âš™ï¸ å¯¼æ¼”å¼•æ“ V13")
    st.caption("è§†è§‰èšåˆä¿®å¤ç‰ˆ")
    
    api_key = st.text_input("API Key", type="password")
    base_url = st.text_input("æ¥å£åœ°å€", value="https://blog.tuiwen.xyz/v1")
    model_id = st.text_input("Model ID", value="gpt-4o") 
    
    st.divider()
    st.markdown("### ğŸ› ï¸ ä¿®å¤æ—¥å¿—")
    st.info("""
    **V13 ä¿®æ­£é€»è¾‘ï¼š**
    1. **æ‹’ç»ç¢é•œ**ï¼šå¼ºåˆ¶åˆå¹¶çŸ­å¥ï¼Œæ¨¡æ‹Ÿé•¿é•œå¤´æ„Ÿã€‚
    2. **æ»¡è½½å¡«å……**ï¼šå•é•œå¤´å°½é‡å¡«æ»¡ 25-35 å­—ã€‚
    3. **ä¸¥æ ¼å¯¹è´¦**ï¼šåå·®å€¼æ§åˆ¶ç®—æ³•ä¼˜åŒ–ã€‚
    """)

# ==========================================
# ğŸ–¥ï¸ ä¸»ç•Œé¢é€»è¾‘
# ==========================================
st.title("ğŸ¬ å…¨èƒ½æ–‡æ¡ˆÂ·ç”µå½±æ„Ÿåˆ†é•œç³»ç»Ÿ (V13)")

uploaded_file = st.file_uploader("ğŸ“‚ é€‰æ‹© TXT æ–‡æ¡ˆ", type=['txt'])

if uploaded_file is not None:
    raw_text = uploaded_file.getvalue().decode("utf-8")
    # é¢„å¤„ç†ï¼šæŠŠåŸæ–‡æœ¬é‡Œçš„æ¢è¡Œå…¨éƒ¨å‹æ‰ï¼Œé˜²æ­¢AIè¢«åŸæ–‡æ ¼å¼è¯¯å¯¼
    flat_raw_text = "".join(raw_text.split()) 
    st.session_state.original_text_len = len(flat_raw_text)

    # çœ‹æ¿
    st.subheader("ğŸ“Š è§†è§‰é€»è¾‘ç¨½æ ¸")
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("åŸæ–‡æ€»å­—æ•°", f"{st.session_state.original_text_len} å­—")

    if st.button("ğŸš€ å¯åŠ¨ V13 èšåˆåˆ†é•œ", type="primary"):
        if not api_key:
            st.error("è¯·å…ˆåœ¨å·¦ä¾§é…ç½® API Key")
        else:
            try:
                actual_base = base_url.split('/chat')[0].strip()
                client = OpenAI(api_key=api_key, base_url=actual_base)
                
                # åˆ†å—å¤„ç†
                chunks = smart_chunk_text(raw_text)
                
                status_text = st.empty()
                status_text.info(f"ğŸ“¦ å·²è¯†åˆ« {len(chunks)} ä¸ªå‰§æƒ…å—ï¼Œæ­£åœ¨æ‰§è¡Œ V13 èšåˆæŒ‡ä»¤...")
                
                full_result_list = []
                current_shot_idx = 1
                progress_bar = st.progress(0)
                
                for idx, chunk in enumerate(chunks):
                    # ==========================================
                    # ğŸ”¥ V13 æ ¸å¿ƒæŒ‡ä»¤ (The Soul)
                    # ==========================================
                    # è¿™é‡Œçš„æŒ‡ä»¤å®Œå…¨æ¨ç¿»äº†ä¸Šä¸€ç‰ˆï¼Œå¼ºè°ƒâ€œåˆå¹¶â€å’Œâ€œå¡«æ»¡â€
                    system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªè¿½æ±‚â€œé•¿é•œå¤´æ„Ÿâ€çš„ç”µå½±å¯¼æ¼”ã€‚è¯·å°†è¾“å…¥çš„æ–‡æ¡ˆå¤„ç†ä¸ºåˆ†é•œè„šæœ¬ã€‚

ã€æ ¸å¿ƒæŒ‡ä»¤ï¼šè§†è§‰èšåˆã€‘
1. **å°½å¯èƒ½åˆå¹¶**ï¼šä¸è¦æŠŠä¸€å¥è¯åˆ‡ç¢ï¼å¦‚æœå‡ ä¸ªè¿ç»­çš„åŠ¨ä½œæˆ–æè¿°å±äºåŒä¸€ä¸ªåœºæ™¯ä¸”æ€»é•¿ä¸è¶…è¿‡ 35 å­—ï¼Œ**å¿…é¡»åˆå¹¶**åœ¨åŒä¸€è¡Œã€‚
   - é”™è¯¯ï¼š1. çš‡ä¸Šç¿»éåå®« \n 2. åªä¸ºæ‰¾å‡º...
   - æ­£ç¡®ï¼š1. çš‡ä¸Šç¿»éåå®«ï¼Œåªä¸ºæ‰¾å‡ºé…’åçˆ¬é¾™åºŠçš„å®«å¥³
2. **æ‹’ç»çŸ­é•œå¤´**ï¼šé™¤éæ˜¯æçŸ­çš„æƒŠè®¶å¯¹ç™½ï¼ˆå¦‚â€œä»€ä¹ˆï¼Ÿâ€ï¼‰ï¼Œå¦åˆ™ç¦æ­¢è¾“å‡ºå°‘äº 10 ä¸ªå­—çš„åˆ†é•œã€‚
3. **å¼ºåˆ¶æ¢è¡Œæ¡ä»¶**ï¼š
   - åªæœ‰å½“ã€å•è¡Œå­—æ•°è¶…è¿‡ 35 å­—ã€‘æ—¶ï¼Œæ‰å…è®¸åœ¨æ ‡ç‚¹å¤„åˆ‡åˆ†ã€‚
   - åªæœ‰å½“ã€æ˜ç¡®çš„è§’è‰²å¯¹è¯åˆ‡æ¢ã€‘æ—¶ï¼Œæ‰å…è®¸æ¢è¡Œã€‚
4. **æ— æŸè¿˜åŸ**ï¼šè¾“å…¥äº†ä»€ä¹ˆå­—ï¼Œè¾“å‡ºå°±å¿…é¡»æ˜¯ä»€ä¹ˆå­—ã€‚ä¸¥ç¦å¢åŠ â€œé•œå¤´1â€ã€â€œç”»é¢ï¼šâ€ç­‰ä»»ä½•åŸæ–‡æ²¡æœ‰çš„è¯ã€‚

ã€è¾“å‡ºæ ¼å¼ã€‘ï¼š
çº¯æ•°å­—åˆ—è¡¨ï¼Œå¦‚ï¼š
{current_shot_idx}. ç¬¬ä¸€å¥å®Œæ•´çš„è¯...
{current_shot_idx+1}. ç¬¬äºŒå¥å®Œæ•´çš„è¯...
"""
                    # æˆ‘ä»¬æŠŠå¤„ç†è¿‡çš„â€œå»æ¢è¡Œç‰ˆâ€æ–‡æœ¬ç»™AIï¼Œé€¼è¿«å®ƒè‡ªå·±æ–­å¥
                    # è¿™ä¸€æ­¥éå¸¸å…³é”®ï¼Œé˜²æ­¢AIç…§æŠ„åŸæ–‡çš„æ¢è¡Œ
                    clean_chunk = "".join(chunk.split()) 

                    response = client.chat.completions.create(
                        model=model_id,
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": f"è¯·å¤„ç†è¿™æ®µæ–‡æœ¬ï¼š\n{clean_chunk}"}
                        ],
                        temperature=0.1 # æä½æ¸©åº¦ï¼Œä¿è¯ä¸¥è°¨
                    )
                    
                    chunk_res = response.choices[0].message.content.strip()
                    full_result_list.append(chunk_res)
                    
                    # åºå·è¡”æ¥é€»è¾‘
                    last_nums = re.findall(r'(\d+)[\.ã€]', chunk_res)
                    if last_nums:
                        current_shot_idx = int(last_nums[-1]) + 1
                    
                    progress_bar.progress((idx + 1) / len(chunks))
                
                # ç»“æœç»„è£…
                raw_combined = "\n".join(full_result_list)
                st.session_state.generated_storyboard = renumber_content(raw_combined)
                status_text.success("âœ… V13 èšåˆåˆ†é•œå®Œæˆï¼ç¢ç‰‡å·²å¤§å¹…å‡å°‘ã€‚")
                st.rerun()

            except Exception as e:
                st.error(f"å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")

    st.divider()

    # ç¼–è¾‘ä¸åˆ†æåŒºåŸŸ
    if st.session_state.generated_storyboard:
        col_edit, col_analyze = st.columns([1.8, 1.2])
        
        with col_edit:
            st.subheader("ğŸ¬ åˆ†é•œç¼–è¾‘å™¨")
            user_edited_text = st.text_area(
                "editor",
                value=st.session_state.generated_storyboard,
                height=600,
                label_visibility="collapsed"
            )
            
            if st.button("ğŸ”„ æ ¼å¼åŒ–å¹¶é‡ç½®åºå·", use_container_width=True):
                formatted_text = renumber_content(user_edited_text)
                st.session_state.generated_storyboard = formatted_text
                st.rerun()

        with col_analyze:
            st.subheader("ğŸ“ˆ æ•°æ®æ ¡éªŒ")
            current_text = st.session_state.generated_storyboard
            
            # è®¡ç®—æŒ‡æ ‡
            lines = [line.strip() for line in current_text.split('\n') if line.strip()]
            output_pure = get_pure_text(current_text)
            output_len = len(output_pure)
            diff = output_len - st.session_state.original_text_len
            
            c1, c2 = st.columns(2)
            c1.metric("å½“å‰é•œå¤´æ•°", f"{len(lines)} ç»„")
            
            # åå·®å€¼é¢œè‰²é€»è¾‘
            if diff == 0:
                c2.metric("åå·®å€¼", "0 å­—", delta="å®Œç¾", delta_color="normal")
            else:
                c2.metric("åå·®å€¼", f"{diff} å­—", delta="å¼‚å¸¸", delta_color="inverse")
                st.warning("æç¤ºï¼šå¦‚æœåå·®å€¼è¿‡å¤§ï¼Œè¯·æ£€æŸ¥ç¼–è¾‘å™¨åº•éƒ¨æ˜¯å¦æœ‰AIç”Ÿæˆçš„æ€»ç»“è¯­æˆ–å¤šä½™ç©ºè¡Œï¼Œæ‰‹åŠ¨åˆ é™¤å³å¯ã€‚")

            # è¡¨æ ¼åˆ†æ
            table_data = []
            for line in lines:
                match = re.match(r'(\d+)[\.ã€]\s*(.*)', line)
                if match:
                    idx = match.group(1)
                    content = match.group(2)
                    length = len(content)
                    # åªæœ‰æçŸ­çš„æ‰è­¦å‘Š
                    status = "ğŸŸ¢ ä¼˜ç§€" if 15 <= length <= 38 else ("ğŸ”´ è¿‡é•¿" if length > 38 else "ğŸŸ¡ è¿‡ç¢")
                    
                    table_data.append({
                        "åºå·": idx,
                        "å†…å®¹": content,
                        "å­—æ•°": length,
                        "è¯„ä»·": status
                    })
            
            if table_data:
                st.dataframe(pd.DataFrame(table_data), use_container_width=True, height=500)
