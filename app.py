import streamlit as st
from openai import OpenAI
import io
import re
import pandas as pd

st.set_page_config(page_title="AIç”µå½±è§£è¯´å¯¼æ¼”ç³»ç»Ÿ Pro", layout="wide")

# --- åˆå§‹åŒ–å…¨å±€çŠ¶æ€ ---
if 'raw_stream' not in st.session_state: st.session_state.raw_stream = "" # ç‰©ç†ç²‰ç¢åçš„åŸæ–‡
if 'storyboard_output' not in st.session_state: st.session_state.storyboard_output = "" # ç¬¬ä¸€æ­¥ç»“æœ
if 'batch_results' not in st.session_state: st.session_state.batch_results = [] # ç¬¬äºŒæ­¥ç»“æœ
if 'current_idx' not in st.session_state: st.session_state.current_idx = 0 # æ‰¹æ¬¡è¿›åº¦

# --- ä¾§è¾¹æ é…ç½® ---
st.sidebar.title("âš™ï¸ å¯¼æ¼”ä¸­å¿ƒé…ç½®")
api_key = st.sidebar.text_input("è¾“å…¥ API Key", type="password")
base_url = st.sidebar.text_input("ä¸­è½¬æ¥å£åœ°å€", value="https://blog.tuiwen.xyz/v1")
model_id = st.sidebar.text_input("æ¨¡å‹ ID", value="gpt-4o")

st.title("ğŸ¬ ç”µå½±è§£è¯´å…¨æµç¨‹å¯¼æ¼”åˆ†é•œç³»ç»Ÿ")
st.markdown("---")

# ================= ç¬¬ä¸€é˜¶æ®µï¼šå¯¼æ¼”æ€ç»´åˆ†é•œ =================
st.header("Step 1: è¯­ä¹‰èšæ‹¢åˆ†é•œï¼ˆå†³å®šèŠ‚å¥ï¼‰")

uploaded_file = st.file_uploader("ä¸Šä¼ æ–‡æ¡ˆ (TXT)", type=['txt'])

if uploaded_file:
    # ã€ç‰©ç†æ“ä½œã€‘ç‰©ç†å‰”é™¤æ‰€æœ‰æ®µè½å’Œæ¢è¡Œï¼Œå½¢æˆæ— ç»“æ„é•¿å­—ç¬¦æµ
    content = io.StringIO(uploaded_file.getvalue().decode("utf-8")).read()
    clean_stream = re.sub(r'[\s\n\r\t]+', '', content).strip()
    st.session_state.raw_stream = clean_stream
    
    st.write(f"ğŸ“ **å­—ç¬¦æŒ‡çº¹å·²é”å®š**ï¼šåŸæ–‡å…± {len(clean_stream)} å­—ã€‚å·²å½»åº•æŠ¹é™¤åŸæ®µè½ç»“æ„ã€‚")

    if st.button("ğŸ“½ï¸ å¯åŠ¨å¯¼æ¼”æ€ç»´åˆ†é•œ"):
        if not api_key:
            st.error("è¯·å…ˆè¾“å…¥ API Key")
        else:
            try:
                client = OpenAI(api_key=api_key, base_url=base_url)
                
                # ã€æ ¸å¿ƒ Prompt å‡çº§ã€‘ï¼šå¼ºåŒ–è¯­ä¹‰èšæ‹¢ï¼Œä¸¥ç¦ä¸¢å­—
                director_logic = f"""ä½ æ˜¯ä¸€åæ‹¥æœ‰10å¹´ç»éªŒçš„ç”µå½±å‰ªè¾‘å¯¼æ¼”ã€‚ç°åœ¨æˆ‘ç»™ä½ ä¸€æ®µç‰©ç†ç²‰ç¢åã€æ²¡æœ‰ä»»ä½•æ ¼å¼çš„æ–‡æ¡ˆé•¿æµã€‚
                
### ä½ çš„åˆ†é•œåŸåˆ™ï¼š
1. **èšåˆä¼˜å…ˆï¼ˆè§£å†³åˆ†é•œå¤ªç¢ï¼‰**ï¼šä¸è¦ä¸€å¥è¯åˆ†ä¸€ä¸ªé•œï¼ä¸€ä¸ªåˆ†é•œä»£è¡¨5ç§’çš„å™äº‹ç©ºé—´ã€‚å¦‚æœè¿ç»­çš„çŸ­å¥åœ¨æè¿°åŒä¸€ä¸ªåœºæ™¯æˆ–è¿è´¯åŠ¨ä½œï¼ˆå¦‚ï¼šä»–ç¿»å¼€ä¹¦ï¼Œçš±èµ·çœ‰å¤´ï¼Œå¹äº†å£æ°”ï¼‰ï¼Œå¿…é¡»èšæ‹¢åœ¨ä¸€ä¸ªåˆ†é•œä¸­ã€‚
2. **å­—æ•°çº¢çº¿ï¼ˆè§£å†³åˆ†é•œæ‹¥æŒ¤ï¼‰**ï¼šæ¯ä¸ªåˆ†é•œæ–‡æ¡ˆçš„ç†æƒ³é•¿åº¦åœ¨ 25-35 å­—ç¬¦ä¹‹é—´ã€‚ç»å¯¹ä¸¥ç¦è¶…è¿‡40ä¸ªå­—ç¬¦ï¼ˆè¶…è¿‡5ç§’ï¼‰ã€‚
3. **å¼ºåˆ¶åºå·**ï¼šæ¯ä¸€è¡Œå¿…é¡»ä»¥â€œæ•°å­—.â€å¼€å¤´ï¼Œå¦‚â€œ1.æ–‡æ¡ˆâ€ã€‚
4. **æ— æŸåˆ‡å‰²ï¼ˆä¸¥ç¦æ”¹å­—ï¼‰**ï¼šåŸæ–‡ä¸€å­—ä¸å·®ï¼Œä¸å‡†æ€»ç»“ï¼Œä¸å‡†æ¼å­—ã€‚ä½ åªæ˜¯åœ¨æ–‡å­—æµä¸­å†³å®šå“ªé‡Œè¯¥å‰ªå¼€ã€‚
5. **åˆ‡å‰²ç‚¹é€»è¾‘**ï¼šä»…åœ¨â€œæ¢äººè¯´è¯â€ã€â€œæ¢åœ°ç‚¹â€ã€â€œæ—¶é—´è·³è·ƒâ€æˆ–â€œåŠ¨ä½œæ„å›¾å½»åº•æ”¹å˜â€ä¸”æ€»å­—æ•°å·²æ¥è¿‘35å­—æ—¶æ‰å‰ªæ–­ã€‚

### å¾…å¤„ç†æ–‡æ¡ˆæµï¼š
{clean_stream}"""

                with st.spinner("å¯¼æ¼”æ­£åœ¨æ·±åº¦æ€è€ƒå™äº‹èŠ‚å¥..."):
                    response = client.chat.completions.create(
                        model=model_id,
                        messages=[
                            {"role": "system", "content": "ä½ åªè´Ÿè´£æ— æŸåˆ†é•œåˆ‡å‰²ã€‚"},
                            {"role": "user", "content": director_logic}
                        ],
                        temperature=0.2 # ä¿è¯ç¨³å®šæ€§
                    )
                    st.session_state.storyboard_output = response.choices[0].message.content
                    st.session_state.batch_results = []
                    st.session_state.current_idx = 0
            except Exception as e:
                st.error(f"åˆ†é•œå¤±è´¥: {str(e)}")

# ç¬¬ä¸€é˜¶æ®µé¢„è§ˆä¸ç²¾ä¿®
if st.session_state.storyboard_output:
    col_edit, col_audit = st.columns([3, 2])
    
    with col_edit:
        st.subheader("âœï¸ åˆ†é•œç¼–è¾‘åŒºï¼ˆå¯æ‰‹åŠ¨æ ¡å¯¹ï¼‰")
        edited_text = st.text_area("åˆ†é•œæ–‡æ¡ˆï¼ˆæ¯è¡Œä¸€ä¸ª5ç§’é•œå¤´ï¼‰", value=st.session_state.storyboard_output, height=500)
        st.session_state.storyboard_output = edited_text

    with col_audit:
        st.subheader("ğŸ“Š å®æ—¶ç›‘æ§ä¸å®¡è®¡")
        lines = [l.strip() for l in edited_text.split('\n') if l.strip()]
        
        # ä¸¢å­—æ£€æµ‹å®¡è®¡
        recombined = "".join([re.sub(r'^\d+[\.ã€\s]+', '', l) for l in lines])
        orig_len = len(st.session_state.raw_stream)
        curr_len = len(recombined)
        
        if orig_len == curr_len:
            st.success(f"âœ… å†…å®¹æ— æŸï¼šå…± {curr_len} å­—")
        else:
            st.error(f"âš ï¸ ä¸¢å­—é¢„è­¦ï¼šåŸæ–‡{orig_len}å­—ï¼Œå½“å‰{curr_len}å­—ï¼ˆå·®é¢{orig_len - curr_len}ï¼‰")

        # èŠ‚å¥è¯„ä¼°è¡¨æ ¼
        analysis = []
        for i, l in enumerate(lines):
            content = re.sub(r'^\d+[\.ã€\s]+', '', l)
            length = len(content)
            # è¿™é‡Œçš„è¯„ä¼°é€»è¾‘æ˜¯æ ¸å¿ƒï¼šå¼•å¯¼ç”¨æˆ·ä¸è¦åˆ†å¾—å¤ªç¢
            if length > 40: status = "ğŸ”´ å¤ªæŒ¤(å»ºè®®æ‹†åˆ†)"
            elif length < 20: status = "ğŸŸ¡ å¤ªç¢(å»ºè®®åˆå¹¶)"
            else: status = "ğŸŸ¢ ç†æƒ³"
            analysis.append({"åºå·": i+1, "å­—æ•°": length, "è¯„ä»·": status})
        
        st.dataframe(pd.DataFrame(analysis), use_container_width=True)

    st.divider()

    # ================= ç¬¬äºŒé˜¶æ®µï¼šåˆ†æ­¥ç”»é¢æè¿°ç”Ÿæˆ =================
    st.header("Step 2: ç”Ÿæˆ AI ç”»é¢ä¸è§†é¢‘è¿åŠ¨æè¿°")
    
    char_desc = st.text_area("1. å½•å…¥æœ¬æ‰¹æ¬¡è§’è‰²è§†è§‰è®¾å®š", 
                            placeholder="æè¿°è§’è‰²çš„å¤–è²Œã€ç©¿ç€ã€é£æ ¼ã€‚å¦‚ï¼šèµµæ¸…æœˆï¼š25å²ï¼Œè‚¤ç™½å¦‚é›ªï¼Œç©¿ç€æœˆç™½è‰²åˆºç»£å¤è£…ã€‚",
                            height=100)
    
    if char_desc:
        final_lines = [re.sub(r'^\d+[\.ã€\s]+', '', l.strip()) for l in st.session_state.storyboard_output.split('\n') if l.strip()]
        total_len = len(final_lines)
        c_idx = st.session_state.current_idx
        batch_size = 20
        e_idx = min(c_idx + batch_size, total_len)

        if c_idx < total_len:
            if st.button(f"ğŸ¬ ç”Ÿæˆæ‰¹æ¬¡æè¿° ({c_idx+1} - {e_idx})"):
                try:
                    client = OpenAI(api_key=api_key, base_url=base_url)
                    batch_text = ""
                    for i, t in enumerate(final_lines[c_idx:e_idx]):
                        batch_text += f"åˆ†é•œ{c_idx+i+1}: {t}\n"
                    
                    desc_prompt = f"""ä½ ç°åœ¨æ˜¯é¡¶çº§è§†è§‰å¯¼æ¼”ã€‚è¯·ä¸ºä»¥ä¸‹åˆ†é•œç”Ÿæˆç”»é¢æç¤ºè¯ã€‚
                    
### è§’è‰²è®¾å®šï¼š
{char_desc}

### ä»»åŠ¡è¦æ±‚ï¼š
1. **ç”»é¢æè¿° (Midjourney)**ï¼šé™æ€è§†è§‰ã€‚æè¿°æ™¯åˆ«ï¼ˆå¦‚ï¼šç‰¹å†™ï¼‰ã€å…·ä½“åœºæ™¯ç»†èŠ‚ã€äººç‰©ç¥æ€ã€ç€è£…æè´¨ã€ç¯å¢ƒå…‰å½±ã€‚**ä¸¥ç¦æè¿°åŠ¨ä½œè¡Œä¸º**ã€‚
2. **è§†é¢‘ç”Ÿæˆ (å³æ¢¦AI)**ï¼šåŠ¨æ€æ¼”å˜ã€‚æè¿°5ç§’å†…çš„åŠ¨ä½œæµã€‚å¦‚â€œäººç‰©å…ˆæ˜¯æƒŠæ„•æŠ¬å¤´ï¼Œéšåæ³ªæ°´å¤ºçœ¶è€Œå‡ºï¼Œé•œå¤´ç¼“æ…¢æ‹‰è¿‘â€ã€‚
3. **é’ˆå¯¹èšæ‹¢æ–‡æ¡ˆçš„ä¼˜åŒ–**ï¼šå› ä¸ºæ¯ä¸ªåˆ†é•œåŒ…å«å¤šå¥åŠ¨ä½œï¼Œè¯·åœ¨è§†é¢‘æè¿°ä¸­ä½“ç°å‡ºåŠ¨ä½œçš„ã€è¿ç»­æ€§ã€‘ã€‚

å¾…å¤„ç†åˆ†é•œç»„ï¼š
{batch_text}"""
                    
                    with st.spinner("AI æ­£åœ¨æ„æ€è§†è§‰åŠ¨æ€..."):
                        response = client.chat.completions.create(
                            model=model_id,
                            messages=[{"role": "user", "content": desc_prompt}]
                        )
                        st.session_state.batch_results.append(response.choices[0].message.content)
                        st.session_state.current_idx = e_idx
                        st.rerun()
                except Exception as e:
                    st.error(f"æè¿°ç”Ÿæˆå¤±è´¥: {e}")
        else:
            st.success("âœ… è„šæœ¬å…¨éƒ¨æè¿°å®Œæˆï¼")

        for r in st.session_state.batch_results:
            st.markdown(r)
            st.divider()
