import streamlit as st
import requests
import json
import pandas as pd
import re

# --- é¡µé¢åŸºç¡€é…ç½® ---
st.set_page_config(page_title="ä¸¥è°¨ç‰ˆ-è‡ªåŠ¨åˆ†é•œç³»ç»Ÿ V4.0", layout="wide")

st.markdown("""
    <style>
    .stDataFrame {border: 1px solid #ff4b4b;}
    .reportview-container .main .block-container{padding-top: 2rem;}
    </style>
    """, unsafe_allow_html=True)

# --- ä¾§è¾¹æ ï¼šé…ç½®å‚æ•° ---
with st.sidebar:
    st.title("âš™ï¸ å¼•æ“é…ç½®")
    api_key = st.text_input("API Key", type="password")
    base_url = st.text_input("æ¥å£åœ°å€", value="https://blog.tuiwen.xyz/v1/chat/completions")
    model_id = st.text_input("Model ID", value="gpt-4o")
    
    st.divider()
    max_len = st.slider("å•åˆ†é•œå­—æ•°ä¸Šé™", 15, 45, 35)
    chunk_size = st.number_input("å¤„ç†å—å¤§å°(å­—æ•°)", value=800, help="ä¸ºäº†é˜²æ­¢AIå¹»è§‰ï¼Œå»ºè®®åˆ†æ®µå¤„ç†")

# --- æ ¸å¿ƒå‡½æ•°ï¼šè°ƒç”¨AIè¿›è¡Œé€»è¾‘åˆ†é•œ ---
def process_text_segment(text, api_key, base_url, model_id, max_char):
    prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„ç”µå½±å¯¼æ¼”ã€‚è¯·å°†ä¸‹æ–‡æ‹†åˆ†ä¸º[è§†è§‰åˆ†é•œå•å…ƒ]ã€‚
ã€ç¡¬æ€§å‡†åˆ™ã€‘:
1. æ— æŸè¿˜åŸï¼šç¦æ­¢ä¿®æ”¹ã€å¢åŠ æˆ–åˆ é™¤åŸæ–‡ä¸­ä»»ä½•ä¸€ä¸ªå­—ã€‚
2. è§†è§‰åˆ‡åˆ†ç‚¹ï¼š
   - è§’è‰²å¯¹è¯åˆ‡æ¢æ—¶ï¼Œå¿…é¡»æ–­å¼€ã€‚
   - åœºæ™¯/æ—¶é—´è½¬ç§»æ—¶ï¼Œå¿…é¡»æ–­å¼€ã€‚
   - æ ¸å¿ƒåŠ¨ä½œå®Œæˆæ—¶ï¼ˆå¦‚ï¼šä»–è½¬èº«èµ°äº†ï¼‰ï¼Œå¿…é¡»æ–­å¼€ã€‚
3. é•¿åº¦æ§åˆ¶ï¼š
   - æ¯ä¸ªåˆ†é•œå¿…é¡»åœ¨15-{max_char}å­—ä¹‹é—´ã€‚
   - å¦‚æœä¸€å¥è¯å¾ˆçŸ­ä½†æ¶‰åŠäººç§°åˆ‡æ¢ï¼Œå¿…é¡»ç‹¬ç«‹æˆè¡Œï¼Œä¸¥ç¦ä¸ºäº†å‡‘å­—æ•°è€Œè·¨è§’è‰²åˆå¹¶ã€‚
   - å¦‚æœä¸€å¥è¯è¶…è¿‡{max_char}å­—ï¼Œè¯·åœ¨ä¸ç ´åè¯­ä¹‰çš„å‰æä¸‹ï¼Œå¯»æ‰¾æ ‡ç‚¹æˆ–åŠ¨è¯å¤„åˆ‡åˆ†ã€‚

ã€è¾“å‡ºæ ¼å¼ã€‘:
ä»…è¾“å‡ºåˆ†é•œå†…å®¹ï¼Œåˆ†é•œä¹‹é—´ç”¨'###'åˆ†éš”ï¼Œä¸¥ç¦è¾“å‡ºåºå·ã€ä¸¥ç¦æ¢è¡Œã€‚

ã€å¾…å¤„ç†æ–‡æœ¬ã€‘:
{text}
"""
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": model_id,
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªåªè¾“å‡ºæ–‡æœ¬åˆ†å‰²ç»“æœçš„æœºå™¨äººã€‚"},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.1
    }
    
    try:
        response = requests.post(base_url, headers=headers, json=payload, timeout=60)
        res_json = response.json()
        return res_json['choices'][0]['message']['content'].strip()
    except Exception as e:
        return f"Error: {str(e)}"

# --- ä¸»ç¨‹åºç•Œé¢ ---
st.title("ğŸ¬ è‡ªåŠ¨åˆ†é•œæ— æŸç³»ç»Ÿ (ä¸¥è°¨åŠ©æ‰‹ç‰ˆ)")

uploaded_file = st.file_uploader("ä¸Šä¼ æ–‡æ¡ˆ (.txt)", type=['txt'])

if uploaded_file:
    # 1. è¯»å–å¹¶å½»åº•æ ¼å¼åŒ–æ–‡æœ¬
    raw_text = uploaded_file.read().decode("utf-8")
    clean_text = "".join(raw_text.split()) # æŠ¹é™¤åŸæ®µè½
    total_chars = len(clean_text)
    
    col1, col2, col3 = st.columns(3)
    col1.metric("åŸæ–‡æ€»å­—æ•°", total_chars)

    if st.button("ğŸ› ï¸ å¼€å§‹æ‰§è¡Œä¸¥è°¨åˆ†é•œä»»åŠ¡"):
        if not api_key:
            st.error("è¯·å…ˆåœ¨ä¾§è¾¹æ è¾“å…¥ API Key")
        else:
            all_shots = []
            # 2. åˆ†å—å¤„ç†é€»è¾‘ï¼šè§£å†³é•¿æ–‡æœ¬AIâ€œè®°ä¸ä½â€å’Œâ€œä¹±åˆ†â€çš„é—®é¢˜
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # å°† 7000+ å­—æŒ‰ chunk_size åˆ‡æ®µ
            text_chunks = [clean_text[i:i+chunk_size] for i in range(0, total_chars, chunk_size)]
            
            for idx, chunk in enumerate(text_chunks):
                status_text.text(f"æ­£åœ¨å¤„ç†ç¬¬ {idx+1}/{len(text_chunks)} å—æ•°æ®...")
                result = process_text_segment(chunk, api_key, base_url, model_id, max_len)
                
                if "Error:" in result:
                    st.error(result)
                    break
                
                # åˆ†éš”å¹¶æ¸…ç†
                split_shots = [s.strip() for s in result.split("###") if s.strip()]
                all_shots.extend(split_shots)
                progress_bar.progress((idx + 1) / len(text_chunks))

            # 3. ç»“æœæ±‡æ€»ä¸æ ¡éªŒ
            processed_text = "".join(all_shots)
            offset = total_chars - len(processed_text)
            
            col2.metric("ç”Ÿæˆåˆ†é•œæ€»æ•°", len(all_shots))
            col3.metric("å­—ç¬¦åç§»(æ ¡éªŒ)", offset, delta="å®Œç¾" if offset == 0 else f"ç¼ºå¤±{offset}å­—", delta_color="normal" if offset == 0 else "inverse")

            # 4. æ„å»ºå±•ç¤ºè¡¨æ ¼
            df_list = []
            for i, shot in enumerate(all_shots):
                c_len = len(shot)
                df_list.append({
                    "åˆ†é•œåºå·": i + 1,
                    "å†…å®¹": shot,
                    "å­—æ•°": c_len,
                    "çŠ¶æ€": "âœ…" if 10 <= c_len <= max_len else "âš ï¸"
                })
            
            df = pd.DataFrame(df_list)

            st.subheader("ğŸ“ è§†è§‰åˆ†é•œç²¾ä¿®è¡¨")
            # ä½¿ç”¨ data_editor å®ç°ç´§å‡‘æ’åˆ—
            edited_df = st.data_editor(
                df,
                column_config={
                    "åˆ†é•œåºå·": st.column_config.NumberColumn(width="small"),
                    "å†…å®¹": st.column_config.TextColumn(width="large"),
                    "å­—æ•°": st.column_config.NumberColumn(width="small"),
                    "çŠ¶æ€": st.column_config.TextColumn(width="small"),
                },
                use_container_width=True,
                num_rows="dynamic",
                hide_index=True
            )

            # 5. ä¸‹è½½ç»“æœ
            csv = df.to_csv(index=False).encode('utf-8-sig')
            st.download_button("ğŸ’¾ å¯¼å‡ºåˆ†é•œè¡¨ (CSV)", csv, "shots_fixed.csv", "text/csv")

            if offset != 0:
                st.warning("âš ï¸ æ£€æµ‹åˆ°å­—æ•°åç§»ï¼Œå¯èƒ½æ˜¯AIåœ¨åˆ‡åˆ†æ—¶åˆå¹¶æˆ–æ¼æ‰äº†æ ‡ç‚¹ã€‚å»ºè®®å¾®è°ƒ chunk å¤§å°é‡æ–°è¿è¡Œã€‚")
