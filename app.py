import streamlit as st
from openai import OpenAI
import re
import time

# ====================
# 1. é¡µé¢é…ç½®ä¸çŠ¶æ€åˆå§‹åŒ– (ä¿®å¤KeyErrorçš„æ ¸å¿ƒ)
# ====================
st.set_page_config(
    page_title="å…¨èƒ½æ–‡æ¡ˆÂ·ç”µå½±æ„Ÿåˆ†é•œç³»ç»Ÿ (V14 é˜²å´©æºƒç‰ˆ)",
    page_icon="ğŸ¬",
    layout="wide"
)

# --- æ ¸å¿ƒä¿®å¤ï¼šåˆå§‹åŒ–æ‰€æœ‰Session Stateå˜é‡ ---
# è¿™ä¸€æ­¥ä¿è¯äº†æ— è®ºæ€ä¹ˆåˆ·æ–°ï¼Œå˜é‡éƒ½å­˜åœ¨ï¼Œç»ä¸ä¼šæŠ¥ KeyError
if 'init' not in st.session_state:
    st.session_state['init'] = True
    st.session_state['result'] = ""
    st.session_state['orig_len'] = 0
    st.session_state['final_len'] = 0
    st.session_state['deviation'] = 0
    st.session_state['shots'] = 0
    st.session_state['chunks'] = 0

st.markdown("""
<style>
    .main-header {font-size: 2rem; font-weight: bold; margin-bottom: 1rem;}
    .stat-box {
        background-color: #f8f9fa;
        padding: 20px;
        border-radius: 8px;
        text-align: center;
        border: 1px solid #e0e0e0;
        box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }
    .stat-value {font-size: 2.2rem; font-weight: bold; color: #333;}
    .stat-label {font-size: 0.9rem; color: #666; margin-top: 5px;}
    textarea {
        font-family: 'Courier New', Courier, monospace; 
        font-size: 16px !important;
    }
    .stProgress > div > div > div > div {
        background-color: #00CC66;
    }
</style>
""", unsafe_allow_html=True)

# ====================
# 2. ä¾§è¾¹æ é…ç½®
# ====================
with st.sidebar:
    st.markdown("### âš™ï¸ å¯¼æ¼”å¼•æ“ V14 è®¾ç½®")
    api_key = st.text_input("API Key", type="password")
    base_url = st.text_input("æ¥å£åœ°å€ (Base URL)", value="https://blog.tuiwen.xyz/v1")
    
    model_options = ["deepseek-chat", "gpt-4o", "claude-3-5-sonnet", "gemini-pro", "grok-beta", "è‡ªå®šä¹‰"]
    selected_model = st.selectbox("Model ID (æ¨¡å‹é€‰æ‹©)", model_options)
    
    if selected_model == "è‡ªå®šä¹‰":
        model_id = st.text_input("è¯·è¾“å…¥è‡ªå®šä¹‰æ¨¡å‹åç§°", value="grok-4.1")
    else:
        model_id = selected_model

# ====================
# 3. å·¥å…·å‡½æ•°
# ====================

def clean_text_for_count(text):
    """çº¯å‡€å­—æ•°ç»Ÿè®¡"""
    if not text: return ""
    pattern = re.compile(r'[^\u4e00-\u9fa5a-zA-Z0-9]')
    return re.sub(pattern, '', text)

def safe_split_text(text, limit=600):
    """å¼ºåˆ¶åˆ†å—ç®—æ³• (ä¿ç•™V13çš„ä¼˜ç§€é€»è¾‘)"""
    chunks = []
    current_chunk = ""
    # ä¿æŠ¤æ€§æ›¿æ¢
    text = text.replace("ã€‚", "ã€‚|").replace("ï¼", "ï¼|").replace("ï¼Ÿ", "ï¼Ÿ|").replace("\n", "|")
    sentences = text.split("|")
    
    for sentence in sentences:
        if not sentence: continue
        if len(current_chunk) + len(sentence) > limit:
            if current_chunk:
                chunks.append(current_chunk)
                current_chunk = ""
            if len(sentence) > limit:
                for i in range(0, len(sentence), limit):
                    chunks.append(sentence[i:i+limit])
            else:
                current_chunk = sentence
        else:
            current_chunk += sentence
    if current_chunk:
        chunks.append(current_chunk)
    return chunks

def process_chunk_with_retry(client, model, text_chunk, chunk_index, total_chunks):
    """å•ä¸ªåˆ†å—å¤„ç†"""
    system_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„æ–‡æ¡ˆåˆ†é•œå‘˜ã€‚
1. **æ— æŸè¿˜åŸ**ï¼šä¸å¾—åˆ å‡åŸæ–‡ï¼Œä¸å¾—æ·»åŠ åŸæ–‡æ²¡æœ‰çš„æè¿°ã€‚
2. **åˆå¹¶çŸ­å¥**ï¼šå°†åŠ¨ä½œè¿è´¯çš„çŸ­å¥åˆå¹¶ï¼Œæ¯è¡Œåˆ†é•œæ§åˆ¶åœ¨ **30-45ä¸ªå­—ç¬¦**ã€‚
3. **æ ¼å¼**ï¼šæ¯è¡Œä»¥æ•°å­—å¼€å¤´ã€‚
è¿™æ˜¯å…¨ç¯‡æ–‡æ¡ˆçš„ç¬¬ {chunk_index + 1} / {total_chunks} éƒ¨åˆ†ã€‚
"""
    max_retries = 3
    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": text_chunk}
                ],
                stream=False,
                temperature=0.3
            )
            content = response.choices[0].message.content
            if content: return content
        except Exception as e:
            if attempt == max_retries - 1: return f"Error: {e}"
            time.sleep(1)
    return "Error: Timeout"

# ====================
# 4. ä¸»é€»è¾‘
# ====================

st.markdown('<div class="main-header">ğŸ¬ å…¨èƒ½æ–‡æ¡ˆÂ·ç”µå½±æ„Ÿåˆ†é•œç³»ç»Ÿ (V14 Stable)</div>', unsafe_allow_html=True)

uploaded_file = st.file_uploader("ğŸ“‚ é€‰æ‹© TXT æ–‡æ¡ˆ", type=['txt'])

if uploaded_file and api_key:
    raw_content = uploaded_file.read().decode("utf-8")
    clean_input = raw_content.replace("\n", "").replace("\r", "").strip()
    
    # ä¸´æ—¶æ˜¾ç¤ºåŸæ–‡ç»Ÿè®¡
    current_orig_len = len(clean_text_for_count(clean_input))
    st.caption(f"ğŸ“„ åŸæ–‡å·²åŠ è½½ï¼Œå…± {current_orig_len} çº¯å‡€å­—ç¬¦ã€‚")

    if st.button("ğŸš€ å¯åŠ¨è§†è§‰æ— æŸåˆ†é•œ", type="primary"):
        chunks = safe_split_text(clean_input, limit=600)
        total_chunks = len(chunks)
        
        progress_bar = st.progress(0)
        status_box = st.empty()
        full_result_lines = []
        
        try:
            client = OpenAI(api_key=api_key, base_url=base_url)
            
            for i, chunk in enumerate(chunks):
                status_box.info(f"ğŸ”„ æ­£åœ¨å¤„ç†ç¬¬ {i+1}/{total_chunks} å‰§æƒ…å—...")
                chunk_result = process_chunk_with_retry(client, model_id, chunk, i, total_chunks)
                
                if "Error" in chunk_result:
                    st.error(f"å¤„ç†ç¬¬ {i+1} å—å¤±è´¥: {chunk_result}")
                    break
                
                lines = chunk_result.split('\n')
                for line in lines:
                    clean_line = re.sub(r'^\d+[.ã€]\s*', '', line).strip()
                    if clean_line:
                        full_result_lines.append(clean_line)
                
                progress_bar.progress((i + 1) / total_chunks)
            
            # æ±‡æ€»ç»“æœå¹¶å†™å…¥ Session State
            if full_result_lines:
                final_output = ""
                final_clean_text = ""
                for idx, line in enumerate(full_result_lines):
                    final_output += f"{idx + 1}.{line}\n"
                    final_clean_text += line
                
                # æ›´æ–°çŠ¶æ€
                st.session_state['result'] = final_output
                st.session_state['orig_len'] = current_orig_len
                st.session_state['final_len'] = len(clean_text_for_count(final_clean_text))
                st.session_state['deviation'] = st.session_state['final_len'] - st.session_state['orig_len']
                st.session_state['shots'] = len(full_result_lines)
                st.session_state['chunks'] = total_chunks
                
                status_box.success("âœ… å¤„ç†å®Œæˆï¼")
                time.sleep(0.5)
                st.rerun() # åˆ·æ–°é¡µé¢ä»¥æ˜¾ç¤ºç»“æœ
                
        except Exception as e:
            st.error(f"å‘ç”Ÿç³»ç»Ÿé”™è¯¯: {e}")

# ====================
# 5. ç»“æœå±•ç¤º (ä» Session State å®‰å…¨è¯»å–)
# ====================

# åªæœ‰å½“ result ä¸ä¸ºç©ºæ—¶æ‰æ˜¾ç¤ºç»“æœé¢æ¿
if st.session_state['result']:
    result = st.session_state['result']
    orig_len = st.session_state['orig_len']
    final_len = st.session_state['final_len']
    deviation = st.session_state['deviation']
    shots = st.session_state['shots']
    chunks = st.session_state['chunks']

    st.markdown("---")
    st.caption(f"âœ… ç³»ç»Ÿå°†åŸæ–‡æ‹†è§£ä¸º {chunks} ä¸ªç‹¬ç«‹å‰§æƒ…å—è¿›è¡Œé«˜ç²¾åº¦å¤„ç†ã€‚")
    st.progress(1.0)

    c1, c2, c3, c4 = st.columns(4)
    with c1:
        st.markdown(f'<div class="stat-box"><div class="stat-label">åŸæ–‡çº¯å­—æ•°</div><div class="stat-value">{orig_len}</div></div>', unsafe_allow_html=True)
    with c2:
        st.markdown(f'<div class="stat-box"><div class="stat-label">ç”Ÿæˆåˆ†é•œæ€»æ•°</div><div class="stat-value">{shots} ç»„</div></div>', unsafe_allow_html=True)
    with c3:
        st.markdown(f'<div class="stat-box"><div class="stat-label">å¤„ç†åçº¯å­—æ•°</div><div class="stat-value">{final_len}</div></div>', unsafe_allow_html=True)
    with c4:
        if deviation == 0:
            color, msg = "#28a745", "å®Œç¾æ— æŸ"
        elif abs(deviation) < 50:
            color, msg = "#ffc107", "è½»å¾®åå·®"
        else:
            color, msg = "#dc3545", "ä¸¥é‡åå·®"
        st.markdown(f'<div class="stat-box"><div class="stat-label">åå·®å€¼ ({msg})</div><div class="stat-value" style="color:{color}">{deviation} å­—</div></div>', unsafe_allow_html=True)

    st.markdown("### ğŸ“ è§†è§‰åˆ†é•œç¼–è¾‘å™¨")
    st.text_area("ç”Ÿæˆç»“æœ", value=result, height=800)
    st.download_button("ğŸ“¥ ä¸‹è½½åˆ†é•œè„šæœ¬", result, "storyboard_v14.txt")
