import streamlit as st
from openai import OpenAI
import re
import pandas as pd

# ==========================================
# ðŸ› ï¸ æ ¸å¿ƒå·¥å…·å‡½æ•°åº“
# ==========================================

def smart_chunk_text(text, max_chars=1200):
    """
    æ™ºèƒ½åˆ†å—ï¼šä¿æŒä¸Šä¸‹æ–‡å®Œæ•´ï¼Œä¸ä»Žå¥å­ä¸­é—´åˆ‡æ–­ã€‚
    """
    chunks = []
    while len(text) > max_chars:
        split_index = -1
        # ä¼˜å…ˆåœ¨æ®µè½æˆ–å¼ºå¥å·å¤„åˆ‡åˆ†
        for mark in ["\n\n", "ã€‚", "ï¼", "ï¼Ÿ"]:
            pos = text.rfind(mark, 0, max_chars)
            split_index = max(split_index, pos)
        
        if split_index == -1:
            split_index = max_chars
        else:
            split_index += 1 
        chunks.append(text[:split_index].strip())
        text = text[split_index:]
    if text.strip():
        chunks.append(text.strip())
    return chunks

def get_pure_text(text):
    """ç”¨äºŽæ ¸å¯¹å­—æ•°ï¼šåªä¿ç•™æ±‰å­—æ•°å­—"""
    text = re.sub(r'^\d+[\.ã€]\s*', '', text, flags=re.MULTILINE)
    return re.sub(r'[^\u4e00-\u9fa50-9]', '', text)

def renumber_content(text):
    """æ¸…æ´—æ—§åºå·ï¼Œé‡æ–°ç¼–å·"""
    lines = text.split('\n')
    new_lines = []
    counter = 1
    for line in lines:
        stripped = line.strip()
        if not stripped: continue
        clean_content = re.sub(r'^\d+[\.ã€]\s*', '', stripped)
        new_lines.append(f"{counter}. {clean_content}")
        counter += 1
    return "\n".join(new_lines)

# ==========================================
# ðŸŽ¨ é¡µé¢é…ç½®
# ==========================================
st.set_page_config(page_title="å¯¼æ¼”å¼•æ“Ž V16-è¯­ä¹‰é€»è¾‘ç‰ˆ", layout="wide", page_icon="ðŸŽ¬")

if 'generated_storyboard' not in st.session_state:
    st.session_state.generated_storyboard = ""
if 'original_text_pure_len' not in st.session_state:
    st.session_state.original_text_pure_len = 0

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("âš™ï¸ å¯¼æ¼”å¼•æ“Ž V16")
    st.caption("Semantic Logic Core")
    
    api_key = st.text_input("API Key", type="password")
    base_url = st.text_input("æŽ¥å£åœ°å€", value="https://blog.tuiwen.xyz/v1")
    model_id = st.text_input("Model ID", value="gpt-4o") 
    
    st.divider()
    st.info("ðŸ’¡ V16 æ›´æ–°ï¼šç§»é™¤äº†æš´åŠ›åˆ‡åˆ†ã€‚ä½¿ç”¨ã€å°‘æ ·æœ¬å­¦ä¹ ã€‘æ•™ AI ç†è§£è¯­ä¹‰æ°”å£ã€‚")

# ==========================================
# ðŸ–¥ï¸ ä¸»ç•Œé¢é€»è¾‘
# ==========================================
st.title("ðŸŽ¬ å…¨èƒ½æ–‡æ¡ˆÂ·ç”µå½±æ„Ÿåˆ†é•œç³»ç»Ÿ (V16)")

uploaded_file = st.file_uploader("ðŸ“‚ é€‰æ‹© TXT æ–‡æ¡ˆ", type=['txt'])

if uploaded_file is not None:
    raw_text = uploaded_file.getvalue().decode("utf-8")
    pure_raw = get_pure_text(raw_text)
    st.session_state.original_text_pure_len = len(pure_raw)

    st.subheader("ðŸ“Š è§†è§‰é€»è¾‘ç¨½æ ¸")
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("åŽŸæ–‡æ±‰å­—æ•°", f"{len(pure_raw)} å­—")

    if st.button("ðŸš€ å¯åŠ¨ V16 è¯­ä¹‰åˆ†é•œ", type="primary"):
        if not api_key:
            st.error("è¯·é…ç½® API Key")
        else:
            try:
                actual_base = base_url.split('/chat')[0].strip()
                client = OpenAI(api_key=api_key, base_url=actual_base)
                
                chunks = smart_chunk_text(raw_text)
                status_text = st.empty()
                status_text.info(f"ðŸ“¦ åˆ†æžè¯­ä¹‰ä¸­... V16 æ­£åœ¨å¯»æ‰¾ç”»é¢çš„ã€æ°”å£ã€‘...")
                
                full_result_list = []
                current_shot_idx = 1
                progress_bar = st.progress(0)
                
                for idx, chunk in enumerate(chunks):
                    # ==========================================
                    # ðŸ”¥ V16 Prompt: Few-Shot Learning (å°‘æ ·æœ¬æ•™å­¦)
                    # ==========================================
                    # æˆ‘ä»¬ä¸æ•™æ•°å­¦ï¼Œæˆ‘ä»¬ç»™å®ƒçœ‹â€œæ­£ç¡®ç­”æ¡ˆâ€é•¿ä»€ä¹ˆæ ·ã€‚
                    system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å½±è§†åˆ†é•œå¯¼æ¼”ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®â€œè¯­ä¹‰æ°”å£â€å’Œâ€œè§†è§‰èŠ‚å¥â€å°†æ–‡æ¡ˆæ‹†åˆ†ä¸ºåˆ†é•œåˆ—è¡¨ã€‚

ã€æ ¸å¿ƒå¿ƒæ³•ã€‘ï¼š
ä¸è¦åŽ»æ•°å¤šå°‘ä¸ªå­—ï¼Œè€Œæ˜¯åŽ»è¯»è¿™å¥è¯çš„**è¯­ä¹‰é‡å¿ƒ**ã€‚
1. **ä¸€ä¸ªé•œå¤´=ä¸€ä¸ªå®Œæ•´çš„è§†è§‰ä¿¡æ¯**ã€‚
2. **é•¿å¥å¿…åˆ‡**ï¼šå¦‚æžœä¸€å¥è¯åŒ…å«ä¸¤ä¸ªè¿žç»­çš„åŠ¨ä½œï¼Œæˆ–è€…åŒ…å«â€œè½¬æŠ˜/å› æžœâ€å…³ç³»ï¼ˆé€šå¸¸ç”±é€—å·è¿žæŽ¥ï¼‰ï¼Œä¸”æ•´ä½“è¾ƒé•¿ï¼Œ**å¿…é¡»**åœ¨é€—å·å¤„åˆ‡åˆ†ã€‚
3. **çŸ­å¥åˆå¹¶**ï¼šå¦‚æžœä¸¤å¥çŸ­è¯æ˜¯ç´§å¯†ç›¸è¿žçš„åŠ¨ä½œï¼ˆå¦‚ï¼šä»–ç«™èµ·èº«ï¼Œèµ°äº†å‡ºåŽ»ï¼‰ï¼Œè¯·åˆå¹¶ã€‚

ã€å­¦ä¹ ä»¥ä¸‹æ¡ˆä¾‹ï¼ˆCase Studyï¼‰ã€‘ï¼š

âŒ **é”™è¯¯ç¤ºèŒƒï¼ˆå¤ªé•¿ï¼Œä¿¡æ¯æ‹¥æŒ¤ï¼‰**ï¼š
1. ç¬¬ä¸‰ä¸–å¾—çŸ¥çš‡å¸åˆè¦æ‰¾äººæ—¶æˆ‘ä¿©è·ªåœ¨è´µå¦ƒæ—è¾¹å†ä¸æ•¢å‡ºå£°ï¼Œæ²¡å¤šä¹…å¤ªç›‘å´ä¼ å‡ºæ—¨æ„

âœ… **æ­£ç¡®ç¤ºèŒƒï¼ˆè¯­ä¹‰åˆ‡åˆ†ï¼Œæœ‰å‘¼å¸æ„Ÿï¼‰**ï¼š
1. ç¬¬ä¸‰ä¸–å¾—çŸ¥çš‡å¸åˆè¦æ‰¾äººæ—¶ï¼Œæˆ‘ä¿©è·ªåœ¨è´µå¦ƒæ—è¾¹
2. å†ä¸æ•¢å‡ºå£°ï¼Œæ²¡å¤šä¹…å¤ªç›‘å´ä¼ å‡ºæ—¨æ„

âŒ **é”™è¯¯ç¤ºèŒƒï¼ˆå¤ªç¢Žï¼Œè¯­ä¹‰æ–­è£‚ï¼‰**ï¼š
1. æˆ‘çœ‹ç€
2. æ¯äº²åœ¨å¯’é£Žä¸­
3. ç‘Ÿç‘Ÿå‘æŠ–

âœ… **æ­£ç¡®ç¤ºèŒƒï¼ˆå®Œæ•´ç”»é¢ï¼‰**ï¼š
1. æˆ‘çœ‹ç€æ¯äº²åœ¨å¯’é£Žä¸­ç‘Ÿç‘Ÿå‘æŠ–

ã€æ‰§è¡Œè§„åˆ™ã€‘ï¼š
- ä¸¥æ ¼ä¿ç•™åŽŸæ–‡æ‰€æœ‰æ±‰å­—ï¼Œ**åå·®å€¼å¿…é¡»ä¸º0**ã€‚
- ä»…é€šè¿‡**æ¢è¡Œ**æ¥è°ƒæ•´èŠ‚å¥ï¼Œä¸è¦åˆ æ”¹æ ‡ç‚¹ã€‚
- è¾“å‡ºæ ¼å¼ï¼šæ•°å­—åºå· + å†…å®¹ã€‚

èµ·å§‹ç¼–å·ï¼š{current_shot_idx}
"""
                    # é¢„å¤„ç†ï¼šåŽ»é™¤æ¢è¡Œï¼ŒæŠŠæ–‡æœ¬åŽ‹å¹³ï¼Œè®©AIè‡ªå·±å†³å®šå“ªé‡Œæ¢è¡Œ
                    clean_chunk = re.sub(r'\s+', '', chunk)

                    response = client.chat.completions.create(
                        model=model_id,
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": f"è¯·å¤„ç†è¿™æ®µæ–‡æ¡ˆï¼š\n{clean_chunk}"}
                        ],
                        temperature=0.1 # ä¿æŒä½Žæ¸©ï¼Œç¡®ä¿ä¸ä¹±å‘æŒ¥
                    )
                    
                    chunk_res = response.choices[0].message.content.strip()
                    full_result_list.append(chunk_res)
                    
                    last_nums = re.findall(r'(\d+)[\.ã€]', chunk_res)
                    if last_nums:
                        current_shot_idx = int(last_nums[-1]) + 1
                    
                    progress_bar.progress((idx + 1) / len(chunks))
                
                raw_combined = "\n".join(full_result_list)
                st.session_state.generated_storyboard = renumber_content(raw_combined)
                status_text.success("âœ… V16 è¯­ä¹‰åˆ†é•œå®Œæˆï¼")
                st.rerun()

            except Exception as e:
                st.error(f"Error: {str(e)}")

    st.divider()

    # ==========================================
    # ðŸ“ äº¤äº’åŒº
    # ==========================================
    if st.session_state.generated_storyboard:
        col_edit, col_analyze = st.columns([1.8, 1.2])
        
        with col_edit:
            st.subheader("ðŸŽ¬ åˆ†é•œç¼–è¾‘å™¨")
            
            # æˆ‘ä»¬ç§»é™¤é‚£ä¸ªæš´åŠ›çš„â€œè‡ªåŠ¨åˆ‡åˆ†â€æŒ‰é’®ï¼Œ
            # åªä¿ç•™â€œé‡ç½®åºå·â€ï¼ŒæŠŠæŽ§åˆ¶æƒè¿˜ç»™ç”¨æˆ·ã€‚
            if st.button("ðŸ”„ æ ¼å¼åŒ–å¹¶é‡ç½®åºå·", use_container_width=True):
                formatted = renumber_content(st.session_state.widget_text_area)
                st.session_state.generated_storyboard = formatted
                st.rerun()

            def update_text():
                st.session_state.generated_storyboard = st.session_state.widget_text_area

            user_edited_text = st.text_area(
                "editor",
                value=st.session_state.generated_storyboard,
                height=600,
                key="widget_text_area",
                on_change=update_text,
                label_visibility="collapsed"
            )

        with col_analyze:
            st.subheader("ðŸ“ˆ èŠ‚å¥åˆ†æž")
            current_text = st.session_state.generated_storyboard
            lines = [line.strip() for line in current_text.split('\n') if line.strip()]
            
            # åå·®æ ¸å¯¹
            output_pure = get_pure_text(current_text)
            diff = len(output_pure) - st.session_state.original_text_pure_len
            
            c1, c2 = st.columns(2)
            c1.metric("åˆ†é•œç»„æ•°", f"{len(lines)} ç»„")
            
            if diff == 0:
                c2.metric("åå·®å€¼", "0", delta="å®Œç¾Ž", delta_color="normal")
            else:
                c2.metric("åå·®å€¼", f"{diff}", delta="éœ€æ£€æŸ¥", delta_color="inverse")

            # è¡¨æ ¼å±•ç¤º
            table_data = []
            for line in lines:
                match = re.match(r'(\d+)[\.ã€]\s*(.*)', line)
                if match:
                    idx = match.group(1)
                    content = match.group(2)
                    length = len(content)
                    
                    # è¯„ä»·é€»è¾‘ï¼šæ›´å®½å®¹ï¼ŒåŸºäºŽè¯­ä¹‰
                    # åªè¦ä¸è¶…è¿‡ 40 å­—ï¼Œä¸”ä¸çŸ­äºŽ 5 å­—ï¼Œéƒ½ç®—æ­£å¸¸
                    if length > 40:
                        status = "ðŸ”´ è¾ƒé•¿ (å»ºè®®æ£€æŸ¥)"
                    elif length > 30:
                        status = "ðŸŸ¡ é¥±æ»¡"
                    elif length < 6:
                         # æžçŸ­å¥å¦‚æžœæ˜¯æ„Ÿå¹è¯æ˜¯å¯ä»¥çš„
                        status = "âšª çŸ­ä¿ƒ"
                    else:
                        status = "ðŸŸ¢ é€‚ä¸­"
                    
                    table_data.append({
                        "åºå·": idx,
                        "å†…å®¹": content,
                        "å­—æ•°": length,
                        "çŠ¶æ€": status
                    })
            
            if table_data:
                st.dataframe(
                    pd.DataFrame(table_data), 
                    use_container_width=True, 
                    height=500,
                    column_config={
                        "åºå·": st.column_config.TextColumn("No.", width="small"),
                        "å†…å®¹": st.column_config.TextColumn("å†…å®¹", width="medium"),
                        "
