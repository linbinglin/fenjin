import streamlit as st
from openai import OpenAI
import re
import httpx

# é¡µé¢é…ç½®
st.set_page_config(page_title="é€»è¾‘å®¡è®¡åˆ†é•œåŠ©æ‰‹", page_icon="âš–ï¸", layout="wide")

st.title("âš–ï¸ é€»è¾‘å®¡è®¡åˆ†é•œåŠ©æ‰‹ (ç¨³å®šç‰ˆ)")

# --- ä¾§è¾¹æ é…ç½® ---
st.sidebar.header("âš™ï¸ é…ç½®ä¸­å¿ƒ")
api_key = st.sidebar.text_input("è¯·è¾“å…¥ API Key", type="password")
raw_url = st.sidebar.text_input("ä¸­è½¬æ¥å£åœ°å€", value="https://blog.tuiwen.xyz/v1")

# è‡ªåŠ¨å¤„ç† URL æ ¼å¼
base_url = raw_url.split("/chat/completions")[0] 

model_options = ["gpt-4o", "claude-3-5-sonnet-20240620", "deepseek-chat", "gemini-1.5-pro", "doubao-pro-128k"]
selected_model = st.sidebar.selectbox("é€‰æ‹©æ¨¡å‹ ID", model_options + ["æ‰‹åŠ¨è¾“å…¥"])
model_id = st.sidebar.text_input("è‡ªå®šä¹‰ Model ID", value="deepseek-chat") if selected_model == "æ‰‹åŠ¨è¾“å…¥" else selected_model

# --- æ ¸å¿ƒ Prompt ---
PROMPT_STAGE_1 = "ä½ æ˜¯ä¸€ä¸ªç”µå½±å¯¼æ¼”ã€‚ä»»åŠ¡ï¼šè¯·å°†ä»¥ä¸‹è¿ç»­æ–‡æœ¬æ‹†åˆ†ä¸ºé€»è¾‘åˆ†é•œã€‚æ ‡å‡†ï¼šæ¯å½“å‡ºç°ã€æ–°åœºæ™¯ã€æ–°è§’è‰²ã€æ–°åŠ¨ä½œè½¬æŠ˜ã€‘æ—¶å¼€å¯æ–°åˆ†é•œã€‚ä¸¥ç¦æ”¹åŠ¨åŸæ–‡ã€‚æ ¼å¼ï¼šåºå·.å†…å®¹"

PROMPT_STAGE_2 = """ä½ æ˜¯ä¸€ä¸ªç»†èŠ‚æ§ã€åˆ†é•œé€»è¾‘å®¡è®¡å¸ˆã€‘ã€‚
ç¬¬ä¸€éåˆ†é•œå­˜åœ¨ç»†èŠ‚ç–å¿½ï¼Œè¯·æ‰§è¡Œå®¡è®¡ä¿®æ­£ï¼š
1. **é•¿é•œæ‹†åˆ†**ï¼šæ£€æŸ¥å­—æ•°è¶…35å­—çš„åˆ†é•œï¼Œå³ä¾¿æ²¡æ ‡ç‚¹ï¼Œåªè¦ä¸­é—´æœ‰å¾®å°åŠ¨ä½œ/è§’è‰²å˜åŒ–ï¼Œå¿…é¡»æ‰§è¡Œæ‹†åˆ†ã€‚
2. **ç¢é•œåˆå¹¶**ï¼šæ£€æŸ¥è¿ç»­10å­—ä»¥å†…çš„ç¢é•œï¼Œå¦‚åŒå±ä¸€åœºæ™¯/åŠ¨ä½œä¸”åˆå¹¶åä¸è¶…35å­—ï¼Œå¿…é¡»åˆå¹¶ã€‚
3. **æ–‡æœ¬æº¯æº**ï¼šæ ¸å¯¹å…¨æ–‡ï¼Œç¡®ä¿ä¸æ¼ä¸€ä¸ªå­—ï¼Œä¸å°‘ä¸€ä¸ªç¬¦å·ã€‚
è¾“å‡ºè¦æ±‚ï¼šä»…è¾“å‡ºâ€œåºå·.å†…å®¹â€ï¼Œç¦æ­¢åºŸè¯ã€‚"""

# --- ä¸»ç•Œé¢ ---
uploaded_file = st.file_uploader("ä¸Šä¼  TXT æ–‡æ¡ˆ", type=['txt'])

if uploaded_file is not None:
    raw_content = uploaded_file.getvalue().decode("utf-8")
    cleaned_content = "".join(raw_content.split())
    
    col_in, col_s1, col_s2 = st.columns([1, 1, 1.2])
    with col_in:
        st.subheader("1. åŸå§‹æ–‡æœ¬")
        st.text_area("Original", cleaned_content, height=300)

    if st.button("ğŸš€ å¼€å§‹åŒé‡å®¡è®¡"):
        if not api_key:
            st.error("âŒ è¯·è¾“å…¥ API Key")
        else:
            # ä½¿ç”¨å¸¦æœ‰è¶…æ—¶çš„ http å®¢æˆ·ç«¯
            http_client = httpx.Client(timeout=100.0) # è®¾ç½® 100 ç§’è¶…æ—¶
            client = OpenAI(api_key=api_key, base_url=base_url, http_client=http_client)
            
            try:
                # --- ç¬¬ä¸€é˜¶æ®µ ---
                container1 = st.status("æ­£åœ¨æ‰§è¡Œé˜¶æ®µä¸€ï¼šé€»è¾‘åˆåˆ†...", expanded=True)
                with container1:
                    st.write("æ­£åœ¨è¿æ¥æ¥å£å¹¶å‘é€è¯·æ±‚...")
                    res1 = client.chat.completions.create(
                        model=model_id,
                        messages=[
                            {"role": "system", "content": PROMPT_STAGE_1},
                            {"role": "user", "content": cleaned_content}
                        ],
                        temperature=0.3
                    )
                    stage1_out = res1.choices[0].message.content
                    st.write("âœ… é˜¶æ®µä¸€å®Œæˆï¼")
                    with col_s1:
                        st.subheader("2. é€»è¾‘åˆç¨¿")
                        st.text_area("Stage 1", stage1_out, height=400)

                # --- ç¬¬äºŒé˜¶æ®µ ---
                container2 = st.status("æ­£åœ¨æ‰§è¡Œé˜¶æ®µäºŒï¼šé€»è¾‘å®¡è®¡çº å...", expanded=True)
                with container2:
                    st.write("æ­£åœ¨æ¯”å¯¹åŸæ–‡è¿›è¡Œåˆå¹¶ä¸æ‹†åˆ†æ‰‹æœ¯...")
                    res2 = client.chat.completions.create(
                        model=model_id,
                        messages=[
                            {"role": "system", "content": PROMPT_STAGE_2},
                            {"role": "user", "content": f"ã€åŸæ–‡ã€‘ï¼š{cleaned_content}\n\nã€è‰ç¨¿ã€‘ï¼š{stage1_out}"}
                        ],
                        temperature=0.1
                    )
                    final_out = res2.choices[0].message.content
                    st.write("âœ… é˜¶æ®µäºŒå®Œæˆï¼")
                
                with col_s2:
                    st.subheader("3. æœ€ç»ˆå®¡è®¡å¯¹é½ç‰ˆ")
                    st.text_area("Final Output", final_out, height=400)
                    st.download_button("ğŸ“¥ ä¸‹è½½ç»“æœ", final_out, file_name="final_storyboard.txt")
                    st.success("å¤„ç†æˆåŠŸï¼")

            except httpx.ReadTimeout:
                st.error("ğŸš¨ æ¥å£å“åº”è¶…æ—¶ï¼šç”±äºåŒé‡åˆ†é•œè®¡ç®—é‡å¤§ï¼Œä¸­è½¬æ¥å£æ²¡èƒ½åœ¨è§„å®šæ—¶é—´å†…è¿”å›ç»“æœï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–æ›´æ¢æ¨¡å‹ï¼ˆå¦‚ DeepSeek æˆ– GPT-4o-mini å“åº”è¾ƒå¿«ï¼‰ã€‚")
            except Exception as e:
                st.error(f"âŒ è¿è¡Œå‡ºé”™ï¼š{str(e)}")
                st.info("æç¤ºï¼šè¯·æ£€æŸ¥æ¥å£åœ°å€æ˜¯å¦æ­£ç¡®ï¼Œæˆ– Model ID æ˜¯å¦å¡«å†™é”™è¯¯ã€‚")

st.markdown("---")
st.caption("æç¤ºï¼šå¦‚æœç‚¹å‡»åæ²¡ååº”ï¼Œè¯·æ£€æŸ¥æµè§ˆå™¨æ§åˆ¶å°æˆ–åˆ·æ–°é¡µé¢é‡è¯•ã€‚æ¨èä½¿ç”¨å“åº”æé€Ÿçš„æ¨¡å‹ï¼ˆå¦‚ DeepSeek V3ï¼‰ã€‚")
